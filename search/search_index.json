{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Hello world. It's Rammus, yo!","title":"\ud83d\udc4b Welcome"},{"location":"#welcome","text":"Hello world. It's Rammus, yo!","title":"Welcome"},{"location":"help/","text":"Help \u00b6 Tips about writing in mkdocs. mkdocs.org mkdocs-material codehilite admonition - note block Pymdown Writing in Visual Studio Code Tabs \u00b6 This need pymdownx.tabbed === \"bash\" ``` echo hi ``` === \"python\" ``` print('hi') ``` bash echo hi python print ( 'hi' ) Hightlight \u00b6 This need pymdownx.mark This is a ==highlight==. This is a highlight . Hightlight code changes \u00b6 This need pymdownx.critic location = @gcsfiles { location @gcsfiles { Highlight Code \u00b6 This need pymdownx.superfences ```yaml hl_lines=\"9 10 11 17\" kind: Service apiVersion: v1 metadata: name: dnsmasq spec: selector: name: dnsmasq type: LoadBalancer externalIPs: - a.a.a.a - a.a.a.b ports: - name: dnsmasq-udp port: 53 protocol: UDP targetPort: dnsmasq-udp # loadBalancerIP: a.a.a.a ``` kind : Service apiVersion : v1 metadata : name : dnsmasq spec : selector : name : dnsmasq type : LoadBalancer externalIPs : - a.a.a.a - a.a.a.b ports : - name : dnsmasq-udp port : 53 protocol : UDP targetPort : dnsmasq-udp # loadBalancerIP: a.a.a.a Escape ``` in markdown \u00b6 Wrap it by one more ` ```` ```yaml kind : Service apiVersion : v1 metadata : name : dnsmasq ``` ```` ```yaml kind : Service apiVersion : v1 metadata : name : dnsmasq ``` Link(reference) to internal documents \u00b6 [Writing in Visual Studio Code](snippets/visual-studio.md) [Mac Setup](mac-setup.md) [Help](../help.md)","title":"\ud83c\udf08 Help"},{"location":"help/#help","text":"Tips about writing in mkdocs. mkdocs.org mkdocs-material codehilite admonition - note block Pymdown Writing in Visual Studio Code","title":"Help"},{"location":"help/#tabs","text":"This need pymdownx.tabbed === \"bash\" ``` echo hi ``` === \"python\" ``` print('hi') ``` bash echo hi python print ( 'hi' )","title":"Tabs"},{"location":"help/#hightlight","text":"This need pymdownx.mark This is a ==highlight==. This is a highlight .","title":"Hightlight"},{"location":"help/#hightlight-code-changes","text":"This need pymdownx.critic location = @gcsfiles { location @gcsfiles {","title":"Hightlight code changes"},{"location":"help/#highlight-code","text":"This need pymdownx.superfences ```yaml hl_lines=\"9 10 11 17\" kind: Service apiVersion: v1 metadata: name: dnsmasq spec: selector: name: dnsmasq type: LoadBalancer externalIPs: - a.a.a.a - a.a.a.b ports: - name: dnsmasq-udp port: 53 protocol: UDP targetPort: dnsmasq-udp # loadBalancerIP: a.a.a.a ``` kind : Service apiVersion : v1 metadata : name : dnsmasq spec : selector : name : dnsmasq type : LoadBalancer externalIPs : - a.a.a.a - a.a.a.b ports : - name : dnsmasq-udp port : 53 protocol : UDP targetPort : dnsmasq-udp # loadBalancerIP: a.a.a.a","title":"Highlight Code"},{"location":"help/#escape-in-markdown","text":"Wrap it by one more ` ```` ```yaml kind : Service apiVersion : v1 metadata : name : dnsmasq ``` ```` ```yaml kind : Service apiVersion : v1 metadata : name : dnsmasq ```","title":"Escape ``` in markdown"},{"location":"help/#linkreference-to-internal-documents","text":"[Writing in Visual Studio Code](snippets/visual-studio.md) [Mac Setup](mac-setup.md) [Help](../help.md)","title":"Link(reference) to internal documents"},{"location":"writing-tools/","text":"\u6574\u7406\u4e00\u4e9b\u5e38\u7528\u7684\u5beb\u4f5c\u5de5\u5177\uff0c\u5e6b\u52a9\u500b\u4eba\u5b78\u7fd2\u6216\u662f\u89e3\u91cb\u6587\u7ae0\u3002 xmind : \u5fc3\u667a\u5716 (Mind Map)\u3002 hatchful : logo \u7522\u751f\u5668\u3002 imagemagick : \u7522\u751f\u6d6e\u6c34\u5370\u3002 docker run --rm -it -v /Users/rammus/workspace/toolkit/docs/Today-I-Learned/img:/workdir avitase/docker-imagemagick:latest /bin/bash -c \" composite -gravity east -dissolve 40 logo.png source.png out.jpg \" \u5c08\u6848\u7ba1\u7406 \u00b6 clockify : \u7ba1\u7406\u6642\u7a0b\u3001\u82b1\u8cbb\u591a\u5c11\u6642\u9593\u3002","title":"\u5beb\u4f5c\u5de5\u5177"},{"location":"writing-tools/#_1","text":"clockify : \u7ba1\u7406\u6642\u7a0b\u3001\u82b1\u8cbb\u591a\u5c11\u6642\u9593\u3002","title":"\u5c08\u6848\u7ba1\u7406"},{"location":"Today-I-Learned/2019/","text":"What I learned in 2019. 2019-12-05 \u00b6 \u5728 local \u958b\u767c https application, service, webhook \u00b6 ref: https://ngrok.com/ brew cask install ngrok ngrok authtoken xxxx ngrok http 4000 2019-08-28 \u00b6 CTF - Hacker Game \u00b6 https://github.com/samsheff/docker-xsser https://github.com/apsdehal/awesome-ctf 2019-05-21 \u00b6 MongoDB Production Configuration \u00b6 ref: https://docs.mongodb.com/manual/core/sharded-cluster-components/ Deploy Config Servers as a 3 member replica set Deploy each Shard as a 3 member replica set Deploy one or more mongos routers","title":"2019"},{"location":"Today-I-Learned/2019/#2019-12-05","text":"","title":"2019-12-05"},{"location":"Today-I-Learned/2019/#local-https-application-service-webhook","text":"ref: https://ngrok.com/ brew cask install ngrok ngrok authtoken xxxx ngrok http 4000","title":"\u5728 local \u958b\u767c https application, service, webhook"},{"location":"Today-I-Learned/2019/#2019-08-28","text":"","title":"2019-08-28"},{"location":"Today-I-Learned/2019/#ctf-hacker-game","text":"https://github.com/samsheff/docker-xsser https://github.com/apsdehal/awesome-ctf","title":"CTF - Hacker Game"},{"location":"Today-I-Learned/2019/#2019-05-21","text":"","title":"2019-05-21"},{"location":"Today-I-Learned/2019/#mongodb-production-configuration","text":"ref: https://docs.mongodb.com/manual/core/sharded-cluster-components/ Deploy Config Servers as a 3 member replica set Deploy each Shard as a 3 member replica set Deploy one or more mongos routers","title":"MongoDB Production Configuration"},{"location":"Today-I-Learned/2020/","text":"What I learned in 2020. 2020-12-17 \u00b6 Nginx - brotli behavior \u00b6 gzip_vary on; will affect brotli_static . brotli_static will look this config. 2020-12-04 \u00b6 GCP - Internal Load Balancer Behavior \u00b6 Internal Load Balancer 192.168.0.101 have a Instance Group contains 192.168.0.3 192.168.0.4 in 192.168.0.3 curl 192.168.0.101, will always request to 192.168.0.3 in 192.168.0.4 curl 192.168.0.101, will always request to 192.168.0.4 2020-12-03 \u00b6 \bCN2 network - go out from China \u00b6 59.43. . is CN2 GIA better 202.97. . is CN2 GT Traceroute from China: https://tools.ipip.net/traceroute.php curl - get current ip and geo location in China \u00b6 curl https://myip.ipip.net\\?json \u5f53\u524d IP\uff1a183.240.8.10 \u6765\u81ea\u4e8e\uff1a\u4e2d\u56fd \u5e7f\u4e1c \u5e7f\u5dde \u79fb\u52a8 Kubernetes - resource.memory Mi vs M \u00b6 Mi = 1024*1024 = 1048576 M = 1000*1000 = 1000000 2020-11-20 \u00b6 k9s - Install k9s on Ubuntu Linux \u00b6 /bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh ) \" # brew install derailed/k9s/k9s brew install k9s ref: https://brew.sh/ https://k9scli.io/topics/install/ k3sup \u00b6 https://github.com/alexellis/k3sup curl -sLS https://get.k3sup.dev | sh sudo install k3sup /usr/local/bin/ k3sup --help ssh-keygen -f ~/.ssh/k3s -N \"\" Add ssh-rsa.pub https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys#block-project-keys https://console.cloud.google.com/compute/metadata/sshKeys export SSH_USER=rammus export MASTER_IP=10.0.0.2 k3sup install --ip $MASTER_IP --user $SSH_USER --ssh-key ~/.ssh/k3s export KUBECONFIG=/home/rammus_xu/kubeconfig kubectl get node -o wide export AGENT_IP=10.0.0.3 k3sup join --ip $AGENT_IP --server-ip $MASTER_IP --user $SSH_USER --ssh-key ~/.ssh/k3s 2020-11-12 \u00b6 Kuberntes - Pod inject/hijack/debug \u00b6 command : [ \"/bin/sh\" , \"-c\" ] args : - | tail -f /dev/null 2020-11-10 \u00b6 MongoDB - not master and slaveOk=false \u00b6 rs0:SECONDARY> show dbs ... \"errmsg\" : \"not master and slaveOk=false\", \"code\" : 13435, \"codeName\" : \"NotMasterNoSlaveOk\", ... rs0:SECONDARY> rs.slaveOk() rs0:SECONDARY> show dbs admin 0.000GB config 0.000GB demo 0.000GB local 0.000GB MongoDB - Could not find host matching read preference { mode: \\\"primary\\\" } for set rs0 \u00b6 mo n gos> sh.addShard( \"rs0/mongo-rs0-0.mongo-rs0.testing-mongo.svc.cluster.local:27017,mongo-rs0-1.mongo-rs0.testing-mongo.svc.cluster.local:27017,mongo-rs0-2.mongo-rs0.testing-mongo.svc.cluster.local:27017\" ) { \"ok\" : 0 , \"errmsg\" : \"Could not find host matching read preference { mode: \\\"primary\\\" } for set rs0\" , \"code\" : 133 , \"codeName\" : \"FailedToSatisfyReadPreference\" , \"operationTime\" : Times ta mp( 1604989375 , 2 ) , \"$clusterTime\" : { \"clusterTime\" : Times ta mp( 1604989377 , 1 ) , \"signature\" : { \"hash\" : Bi n Da ta ( 0 , \"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\" ) , \"keyId\" : NumberLo n g( 0 ) } } } Debug: config rs seems ok. not error log on mongos mongo mongo-rs0-0.mongo-rs0.testing-mongo.svc.cluster.local:27017 rs0-0, rs0-1 rs0-2 are ok rs0-0 is primary, read/write ok Solution mongos version and replica set version should be same. This error occurs when: shardsvr 4.0.20 + mongos 4.0.20 + configsvr 4.0.20 shardsvr 4.0.20 + mongos 4.0.20 + configsvr 4.4 shardsvr 4.0.20 + mongos 4.4 + configsvr 4.4 shardsvr 4.0.20, 3.6.6 mixed + mongos 4.0.20 + configsvr 4.0.20 2020-11-08 \u00b6 GKE - Node auto repair \u00b6 https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-repair GKE \u6703\u5b9a\u671f\u6aa2\u67e5 nodes\uff0c\u5982\u679c\u767c\u751f\u6301\u7e8c\u6027\u7684\u4e0d\u5065\u5eb7\uff0c GKE \u5c07\u6703\u958b\u59cb\u9032\u884c\u4fee\u5fa9\u7684\u7a0b\u5e8f\u3002 \u4ee5 Status: Ready \u7576\u4f5c\u57fa\u6e96\uff0c\u4ee5\u4e0b\u60c5\u6cc1\u6703\u8996\u70ba\u4e0d\u5065\u5eb7: - \u9023\u7e8c 10 \u5206\u9418 Status: NotReady - \u9023\u7e8c 10 \u5206\u9418\u6c92\u6709\u4efb\u4f55\u72c0\u614b - boot disk \u7528\u5b8c\u786c\u789f\u7a7a\u9593\uff0c\u8d85\u904e 30 \u5206\u9418 \u6aa2\u67e5\u6700\u8fd1\u7684 operations\uff0c\u53ef\u4ee5\u770b\u5230\u6709\u6c92\u6709 auto repair \u3002 gcloud container operations list 2020-11-06 \u00b6 Kubernetes - Cusotmize a hostname \u00b6 apiVersion : v1 kind : Pod metadata : namespace : testing-mongo name : rammus-cf labels : name : rammus-cf spec : hostname : rammus subdomain : cf containers : - name : nginx image : nginx --- apiVersion : v1 kind : Service metadata : name : cf spec : selector : name : rammus-cf clusterIP : None \u5728 cluster \u88e1\u9762\u53ef\u4ee5\u7528 curl rammus.cf 2020-11-03 \u00b6 GKE node auto repair notes \u00b6 https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-repair GKE \u6703\u5b9a\u671f\u6aa2\u67e5 nodes\uff0c\u5982\u679c\u767c\u751f\u6301\u7e8c\u6027\u7684\u4e0d\u5065\u5eb7\uff0c GKE \u5c07\u6703\u958b\u59cb\u9032\u884c\u4fee\u5fa9\u7684\u7a0b\u5e8f\u3002 \u4ee5 Status: Ready \u7576\u4f5c\u57fa\u6e96\uff0c\u4ee5\u4e0b\u60c5\u6cc1\u6703\u8996\u70ba\u4e0d\u5065\u5eb7: - \u9023\u7e8c 10 \u5206\u9418 Status: NotReady - \u9023\u7e8c 10 \u5206\u9418\u6c92\u6709\u4efb\u4f55\u72c0\u614b - boot disk \u7528\u5b8c\u786c\u789f\u7a7a\u9593\uff0c\u8d85\u904e 30 \u5206\u9418 Checking command: gcloud container operations list 2020-10-30 \u00b6 Sign a GCS object \u00b6 This will use gcs-service.json to generate a URL with expired time -d 1m . You can give someone the URL to access gs://rammus.cf/a-file.txt . gsutil signurl -d 1m gcs-service.json gs://rammus.cf/a-file.txt 2020-10-22 \u00b6 Kubernetes - Install godaddy ssl certificate into secrets kubernetes.io/tls \u00b6 cat 9faxxxxxxxxxxxxx.crt gd_bundle-g2-g1.crt > chain.crt kubectl create secret tls --cert chain.crt --key generated-private-key.txt rammusxu.tw-tls Test it on local: Add domain in /etc/hosts. Test it with CLI. \u274c curl -kv https://localhost/ -H 'Host: rammusxu.tw' \ud83d\udc4d curl -kv https://rammusxu.tw \u274c openssl s_client -showcerts -connect rammusxu.tw:443 \ud83d\udc4d openssl s_client -showcerts -connect rammusxu.tw:443 -servername rammusxu.tw 2020-10-19 \u00b6 Nginx - Cache static with Cache-Control \u00b6 expires max; add_header Cache-Control \"public\"; Nginx - React app serve SPA htmls \u00b6 ref: https://stackoverflow.com/questions/51367160/nginx-tries-to-find-index-html-in-a-directory-according-to-the-uri root /app; index index.html; location / { try_files $uri $uri/ /index.html; } 2020-10-16 \u00b6 Nginx - automatical content type \u00b6 include mime.types ; path: - /usr/local/openresty/nginx/conf/mime.types; - conf/mime.types; 2020-10-07 \u00b6 MongoDB - Install mongo cli on Mac \u00b6 ref: https://dba.stackexchange.com/questions/196330/is-it-possible-to-install-just-the-mongo-shell brew tap mongodb/brew brew install mongodb-community-shell MongoDB - dump and restore \u00b6 mongodump --gzip --db = test # mongorestore <target> <folder> mongorestore mongodb://localhost:27017 dump 2020-09-30 \u00b6 1 node(s) had volume node affinity conflict. \u00b6 ref: https://cloud.google.com/kubernetes-engine/docs/concepts/persistent-volumes#pd-zones Solution apiVersion : storage.k8s.io/v1 kind : StorageClass metadata : name : slow provisioner : kubernetes.io/gce-pd parameters : type : pd-standard fstype : ext4 volumeBindingMode : WaitForFirstConsumer 2020-09-29 \u00b6 GKE don\u2019t enable podpreset \u00b6 no matches for kind \"PodPreset\" in version \"settings.k8s.io/v1alpha1 kubectl apply -f podpreset.yaml error: unable to recognize \"podpreset.yaml\": no matches for kind \"PodPreset\" in version \"settings.k8s.io/v1alpha1\" no settings.k8s.io API $ kubectl api-resources|grep settings.k8s.io $ kubectl api-versions|grep settings.k8s.io kubernetes - Taint and Tolerations \u00b6 ref: https://godleon.github.io/blog/Kubernetes/k8s-Taints-and-Tolerations/ kubectl taint nodes gke-edge-tw-reserved-4c3f498d-068s preemptible=false:NoSchedule kubectl taint nodes gke-edge-tw-reserved-4c3f498d-068s preemptible=false:NoExecute preemptible=false:NoExecute will evicts all pod immediately this means the pod can tolerate a taint node, so it can be deploy nodeSelector : cloud.google.com/gke-nodepool : reserved tolerations : - key : \"preemptible\" operator : \"Equal\" value : \"false\" This can\u2019t deploy nodeSelector : cloud.google.com/gke-nodepool : reserved tolerations : - key : \"preemptible\" operator : \"Equal\" value : \"false\" effect : \"NoSchedule\" Error Message conditions : - lastProbeTime : null lastTransitionTime : \"2020-09-29T07:37:03Z\" message : '0/4 nodes are available: 1 node(s) had taint {preemptible: false}, that the pod didn '' t tolerate, 3 node(s) didn '' t match node selector.' reason : Unschedulable status : \"False\" type : PodScheduled 2020-09-17 \u00b6 Give a set of files a hash key \u00b6 ~ # md5sum a b d41d8cd98f00b204e9800998ecf8427e a d41d8cd98f00b204e9800998ecf8427e b ~ # md5sum a b | md5sum fe84858e5913eaed7bf248d8b25a77d7 - ~ # md5sum a b | md5sum | cut -b-32 fe84858e5913eaed7bf248d8b25a77d7 ~ # echo a > a ~ # md5sum a b | md5sum | cut -b-32 e849952f425275e21c0d5c46ba2549f5 2020-09-10 \u00b6 Kubernetes - VerticalPodAutoscaler \u00b6 https://cloud.google.com/kubernetes-engine/docs/how-to/vertical-pod-autoscaling Limitations https://cloud.google.com/kubernetes-engine/docs/concepts/verticalpodautoscaler#limitations_for_vertical_pod_autoscaling Can\u2019t use with HPA updatePolicy : updateMode : \"Off\" $ kubectl get vpa my-vpa --output yaml ... recommendation: containerRecommendations: - containerName: my-container lowerBound: cpu: 536m memory: 262144k target: cpu: 587m memory: 262144k upperBound: cpu: 27854m memory: \"545693548\" 2020-09-09 \u00b6 Disable GKE release channel \u00b6 ref: https://cloud.google.com/kubernetes-engine/docs/concepts/release-channels#updating_the_cluster_release_channel It's not possible to exit RAPID channel for now. $ gcloud container clusters update edge-tw --release-channel None --region asia-east1 ERROR: ( gcloud.container.clusters.update ) INVALID_ARGUMENT: Migrating off of releaseChannel RAPID is not supported. fatal error: linux/version.h: No such file or directory \u00b6 In file included from config.h:21, from ae.c:45: redis_config.h:38:10: fatal error: linux/version.h: No such file or directory 38 | #include <linux/version.h> | ^~~~~~~~~~~~~~~~~ compilation terminated. make [ 1 ] : *** [ Makefile:190: ae.o ] Error 1 make [ 1 ] : Leaving directory '/redis-cluster-proxy/src' make: *** [ Makefile:4: all ] Error 2 Solution apk add linux-headers 2020-09-06 \u00b6 Upgrade buildx version on Mac \u00b6 https://gist.github.com/RammusXu/8eb867e2a2dedd3c07149016829da5c3 docker buildx version mkdir -p ~/.docker/cli-plugins BUILDX_VERSION = \"v0.4.2\" wget https://github.com/docker/buildx/releases/download/ ${ BUILDX_VERSION } /buildx- ${ BUILDX_VERSION } .darwin-amd64 -O ~/.docker/cli-plugins/docker-buildx chmod a+x ~/.docker/cli-plugins/docker-buildx docker buildx version 2020-09-03 \u00b6 Nginx - Change host not found response status and content \u00b6 curl localhost:8001/host \"host:backend\" location /host { resolver 127 .0.0.11 ; proxy_pass http:// $http_host$uri ; proxy_cache_key $http_host$uri ; proxy_cache_valid 200 60s ; proxy_intercept_errors on ; error_page 502 503 = 404 / ; } location @host_not_found { echo \"not found\" ; } Host not found frontend_1 | 172 .18.0.1 - - - MISS [ 03 /Sep/2020:09:01:52 +0000 ] \"GET /host HTTP/1.1\" 404 20 \"-\" \"HTTPie/1.0.2\" \"-\" frontend_1 | 2020 /09/03 09 :01:52 [ error ] 6 #6: *12 backend2 could not be resolved (3: Host not found), client: 172.18.0.1, server: , request: \"GET /host HTTP/1.1\", host: \"backend2\" frontend_1 | 2020 /09/03 09 :01:53 [ error ] 6 #6: *13 backend2 could not be resolved (3: Host not found), client: 172.18.0.1, server: , request: \"GET /host HTTP/1.1\", host: \"backend2\" frontend_1 | 172 .18.0.1 - - - MISS [ 03 /Sep/2020:09:01:53 +0000 ] \"GET /host HTTP/1.1\" 404 20 \"-\" \"HTTPie/1.0.2\" \"-\" Host found backend_1 | 172 .18.0.3 - - [ 03 /Sep/2020:09:02:30 +0000 ] \"GET /host HTTP/1.0\" 200 6 \"-\" \"HTTPie/1.0.2\" \"-\" frontend_1 | 172 .18.0.1 - - - MISS [ 03 /Sep/2020:09:02:30 +0000 ] \"GET /host HTTP/1.1\" 200 16 \"-\" \"HTTPie/1.0.2\" \"-\" frontend_1 | 172 .18.0.1 - - - HIT [ 03 /Sep/2020:09:02:38 +0000 ] \"GET /host HTTP/1.1\" 200 16 \"-\" \"HTTPie/1.0.2\" \"-\" 2020-08-27 \u00b6 2020 cert-manager request a certificate with ingress in place \u00b6 ref: https://kosyfrances.github.io/ingress-gce-letsencrypt/ Environment kuberentes: v1.17.9-gke cert-manager: v0.15.0 apiVersion : cert-manager.io/v1alpha2 kind : ClusterIssuer metadata : name : ci-http01 spec : acme : email : rammus.xu@gmail.com server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : issuer-account-key-rammus solvers : - http01 : ingress : class : ingress-gce --- apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : namespace : web name : china-landing annotations : kubernetes.io/ingress.class : \"gce\" cert-manager.io/cluster-issuer : ci-http01 acme.cert-manager.io/http01-edit-in-place : \"true\" spec : tls : - hosts : - rammus.dev secretName : rammus-dev-tls rules : - host : rammus.dev http : paths : - backend : serviceName : http-service-np servicePort : http --- apiVersion : v1 kind : Service metadata : name : http-service-np namespace : web spec : type : NodePort ports : - name : http port : 80 targetPort : http selector : app : http-app 2020-08-21 \u00b6 Copy docker image to another registry \u00b6 ref: https://cloud.google.com/artifact-registry/docs/docker/copy-from-gcr#copy-gcloud gcloud container images add-tag GCR-IMAGE AR-IMAGE Nginx - CORS with map example \u00b6 ref: https://blog.51cto.com/tchuairen/2175525 https://github.com/openresty/headers-more-nginx-module map $http_origin $cors_origin { default https://rammus.dev; \"~rammus2020.dev\" $http_origin; } server { listen 80; location / { more_set_headers Access-Control-Allow-Origin $cors_origin; } } Docker Registry - Gitlab Registry \u00b6 docker pull registry.gitlab.com/rammus.xu/docker-alpine:3.12.0 Public git repo = Public docker registry No need to login to pull Gitlab public registry image 10GB storage, as part of the repository size limit docker login registry.gitlab.com -u rammus.xu -p docker pull nginx:1.19.2-alpine docker tag nginx:1.19.2-alpine registry.gitlab.com/rammus.xu/docker-alpine:nginx-1.19.2 docker push registry.gitlab.com/rammus.xu/docker-alpine:nginx-1.19.2 docker pull registry.gitlab.com/rammus.xu/docker-alpine:nginx-1.19.2 Docker Registry - Github Registry \u00b6 Can't pull without docker credential docker login https://docker.pkg.github.com -u rammusxu -p docker login https://docker.pkg.github.com -u rammusxu -p docker pull nginx:1.19.2-alpine docker tag nginx:1.19.2-alpine docker.pkg.github.com/rammusxu/docker-alpine/nginx:1.19.2-alpine docker push docker.pkg.github.com/rammusxu/docker-alpine/nginx:1.19.2-alpine docker pull docker.pkg.github.com/rammusxu/docker-alpine/nginx:1.19.2-alpine Error response from daemon: Get https://docker.pkg.github.com/v2/rammusxu/docker-alpine/nginx/manifests/1.19.2-alpine: no basic auth credentials 2020-08-19 \u00b6 Dockerhub is rate limiting download layers \u00b6 https://www.docker.com/pricing https://docs.docker.com/docker-hub/download-rate-limit/ https://www.docker.com/pricing/retentionfaq https://github.com/testcontainers/testcontainers-java/issues/3099 As of 2020-08-13, Docker have updated their terms of service and pricing page, indicating that: unauthenticated pulls will be rate limited to 100 per 6h authenticated pulls will be rate limited to 200 per 6h Community - https://www.reddit.com/r/docker/comments/i93bui/docker_terms_of_service_change/ - https://www.reddit.com/r/docker/comments/i9lxq3/docker_reduces_image_retaining_to_6_months_for/ Where's disk storage location(path) of GKE emptyDir \u00b6 # docker container inspect k8s_packager-public_stream-5ad4d9decc14623f43ed1325_default_247be3c5-227d-46cc-9f9c-7aad8cfaeb47_0 | grep Source \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/volumes/kubernetes.io~empty-dir/dist\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/volume-subpaths/workdir/packager-public/1\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/volumes/kubernetes.io~secret/default-token-vvrzk\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/etc-hosts\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/containers/packager-public/0fa5ef38\" , # df /var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47 -h Filesystem Size Used Avail Use% Mounted on /dev/sda1 2 .0T 173G 1 .8T 9 % /var/lib/kubelet 2020-08-12 \u00b6 markdown \u6587\u4ef6\u88fd\u4f5c \u00b6 https://docsify.js.org/#/ 2020-08-10 \u00b6 istio on k3d \u00b6 curl -L https://istio.io/downloadIstio | sh - cp istio-1.6.7/bin/istioctl $HOME /bin/ # ~/.zshrc export PATH = $HOME /bin:/usr/local/bin: $PATH ~ istioctl version no running Istio pods in \"istio-system\" 1 .6.7 brew install k3d k3d cluster create dc0 --k3s-server-arg --disable = traefik --publish 8080 :80 k3d cluster create dc1 --port 8081 :80 --no-lb --k3s-server-arg --disable = traefik kubectl create namespace istio-system kubectl create secret generic cacerts -n istio-system \\ --from-file = samples/certs/ca-cert.pem \\ --from-file = samples/certs/ca-key.pem \\ --from-file = samples/certs/root-cert.pem \\ --from-file = samples/certs/cert-chain.pem # Install istio istioctl install \\ -f manifests/examples/multicluster/values-istio-multicluster-gateways.yaml # Update coreDNS kubectl apply -f - <<EOF apiVersion: v1 kind: ConfigMap metadata: name: coredns namespace: kube-system data: Corefile: | .:53 { errors health ready kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa } prometheus :9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance } global:53 { errors cache 30 forward . $(kubectl get svc -n istio-system istiocoredns -o jsonpath={.spec.clusterIP}):53 } EOF ref: https://dev.to/bufferings/tried-k8s-istio-in-my-local-machine-with-k3d-52gg Configure k3d on Mac zsh \u00b6 brew instsall k3d mkdir -p ~/.oh-my-zsh/custom/plugins/k3d/_k3d k3d completion zsh > ~/.oh-my-zsh/custom/plugins/k3d/_k3d vi ~/.zshrc plugins =( ... k3d ) 2020-08-07 \u00b6 Testing websocket \u00b6 npm install -g wscat docker run -it --rm -p 10000:8080 jmalloc/echo-server wscat -c ws://localhost:10000 2020-08-06 \u00b6 GCP Monitoring - Response Throughput is including CDN hit \u00b6 Miss 0 Hit 21688/s Nginx - add_header is not working on index.html \u00b6 location / { add_header \"Cache-Control\" \"public, max-age=600000\"; index index.html; } location / { add_header \"Cache-Control\" \"public, max-age=600000\"; index index.html; } CC 4.0 \u8457\u4f5c\u6b0a\u61f6\u4eba\u5305 \u00b6 ref: https://xie.infoq.cn/copyright <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License . \u57fa\u65bc CC 4.0 \u5354\u8b70\u9032\u884c\u5982\u4e0b\u985e\u578b\u6388\u6b0a\uff1a CC BY\uff08\u7f72\u540d\uff09\uff1a\u53ea\u8981\u5728\u4f7f\u7528\u6642\u7f72\u540d\uff0c\u90a3\u9ebc\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\u4ee5\u53ca\u5546\u696d\u76ee\u7684\u4f7f\u7528\u3002 CC BY-NC\uff08\u7f72\u540d+ \u975e\u76c8\u5229\uff09\uff1a\u53ea\u8981\u5728\u4f7f\u7528\u3001\u516c\u958b\u6642\u9032\u884c\u7f72\u540d\uff0c\u90a3\u9ebc\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\uff0c\u4f46\u4e0d\u5f97\u5c07\u672c\u5275\u4f5c\u6216\u7531\u672c\u5275\u4f5c\u884d\u751f\u7684\u5275\u4f5c\u904b\u7528\u65bc\u5546\u696d\u76ee\u7684\u3002 CC BY-ND\uff08\u7f72\u540d + \u7981\u6b62\u6f14\u7e79\uff09\uff1a\u53ea\u8981\u5728\u4f7f\u7528\u3001\u516c\u958b\u6642\u9032\u884c\u7f72\u540d\uff0c\u4e26\u4e14\u5c0d\u5275\u4f5c\u4e0d\u52a0\u4efb\u4f55\u6539\u52d5\uff0c\u90a3\u9ebc\u4f7f\u7528\u8005\u53ef\u4ee5\u4f7f\u7528\u672c\u5275\u4f5c\uff0c\u5305\u62ec\u5c07\u5176\u904b\u7528\u65bc\u5546\u696d\u76ee\u7684\u3002 CC BY-NC-ND \uff08\u7f72\u540d + \u975e\u76c8\u5229 + \u7981\u6b62\u6f14\u7e79\uff09\uff1a\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\uff0c\u4f46\u4e0d\u5f97\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u4fee\u6539\uff0c\u4ea6\u4e0d\u5f97\u4f9d\u64da\u672c\u5275\u4f5c\u9032\u884c\u518d\u5275\u4f5c\uff0c\u4e0d\u5f97\u5c07\u672c\u5275\u4f5c\u904b\u7528\u65bc\u5546\u696d\u7528\u9014\u3002 CC BY-SA\uff08\u7f72\u540d+ \u7e7c\u627f\uff09\uff1a\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\uff0c\u53ef\u4ee5\u5c07\u5176\u904b\u7528\u65bc\u5546\u696d\u7528\u9014\uff0c\u552f\u9808\u7f72\u540d\u4f5c\u8005\uff0c\u4e26\u4e14\u63a1\u7528\u672c\u5275\u4f5c\u7684\u5167\u5bb9\u5fc5\u9808\u540c\u6a23\u63a1\u7528\u672c\u5354\u8b70\u9032\u884c\u6388\u6b0a\u3002 CC BY-NC-SA\uff08\u7f72\u540d+ \u975e\u76c8\u5229+ \u7e7c\u627f\uff09\uff1a\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\uff0c\u4f46\u4e0d\u5f97\u904b\u7528\u65bc\u5546\u696d\u76ee\u7684\uff0c\u4e14\u4f7f\u7528\u6642\u9808\u9032\u884c\u7f72\u540d\uff0c\u63a1\u7528\u672c\u5275\u4f5c\u7684\u5167\u5bb9\u5fc5\u9808\u540c\u6a23\u63a1\u7528\u672c\u5354\u8b70\u9032\u884c\u6388\u6b0a\u3002 2020-08-05 \u00b6 No more google - Google alternatives \u00b6 https://nomoregoogle.com/ Privacy-friendly alternatives to Google that don't track you 2020-08-03 \u00b6 Service mesh \u00b6 https://www.youtube.com/watch?v=-KWvlW9CSn8 Istio Linkerd Kuma Mosn 2020-07-30 \u00b6 \u88fd\u4f5c grouped bar chart online \u00b6 https://codepen.io/pen/?&editable=true=https%3A%2F%2Fwww.highcharts.com%2Fsamples%2Fhighcharts%2Fdemo%2Fcolumn-basic%3Fcodepen https://www.highcharts.com/demo 2020-07-24 \u00b6 AB load testing in Alpine Linux \u00b6 apk add apache2-utils ab -n1000 -c10 -k http://localhost/ To generate ECDSA P-256 certificate with step-cli \u00b6 step-cli: https://smallstep.com/cli/ brew install step ref: https://linkerd.io/2/tasks/generate-certificates/#trust-anchor-certificate step certificate create identity.linkerd.cluster.local ca.crt ca.key \\ --profile root-ca --no-password --insecure Import ssl cert to kubernetes secret \u00b6 cat 34_120_61_244.crt IntermediateCA.crt > ip.crt kubectl create secret tls web-ip1 \\ --cert 34_120_61_244.crt \\ --key 34_120_61_244.key \\ -n web update cert kubectl create secret tls web-ip1 \\ --cert 34_120_61_244.crt \\ --key 34_120_61_244.key \\ -n web --dry-run -o yaml \\ | kubectl apply -f - 2020-07-22 \u00b6 Nginx - Access-Control-Allow-Origin: * \u00b6 Good more_set_headers \"Access-Control-Allow-Origin: $http_origin\"; Bad more_set_headers \"Access-Control-Allow-Origin: *\"; 2020-07-14 \u00b6 Is possible to use ip address in ManagedCertificate in GKE? \u00b6 No. Error The ManagedCertificate \"my-ip1\" is invalid: spec.domains: Invalid value: \"\": spec.domains in body should match '^(([a-zA-Z0-9]+|[a-zA-Z0-9][-a-zA-Z0-9]*[a-zA-Z0-9])\\.)+[a-zA-Z][-a-zA-Z0-9]*[a-zA-Z0-9]\\.?$' apiVersion : networking.gke.io/v1beta2 kind : ManagedCertificate metadata : name : my-ip1 spec : domains : - \"34.120.100.100\" 2020-07-06 \u00b6 Nginx - as an forward proxy server \u00b6 https://www.alibabacloud.com/blog/how-to-use-nginx-as-an-https-forward-proxy-server_595799 server { listen 443; # dns resolver used by forward proxying resolver 114.114.114.114; # forward proxy for CONNECT request proxy_connect; proxy_connect_allow 443; proxy_connect_connect_timeout 10s; proxy_connect_read_timeout 10s; proxy_connect_send_timeout 10s; # forward proxy for non-CONNECT request location / { proxy_pass http://$host; proxy_set_header Host $host; } } curl https://www.baidu.com -svo /dev/null -x 39 .105.196.164:443 2020-06-30 \u00b6 Github API - Delete branch with Personal Access Token \u00b6 export INPUT_AUTH_TOKEN = export GITHUB_REPOSITORY = export GITHUB_HEAD_REF = http DELETE \"https://api.github.com/repos/ $GITHUB_REPOSITORY /git/refs/heads/ $GITHUB_HEAD_REF \" \\ \"Authorization: token $INPUT_AUTH_TOKEN \" 2020-06-24 \u00b6 Linux - Get Geo infomation in curl \u00b6 curl https://ipinfo.io/ { \"ip\" : \"59.124.114.73\" , \"hostname\" : \"59-124-114-73.hinet-ip.hinet.net\" , \"city\" : \"Taipei\" , \"region\" : \"Taiwan\" , \"country\" : \"TW\" , \"loc\" : \"25.0478,121.5319\" , \"org\" : \"AS3462 Data Communication Business Group\" , \"timezone\" : \"Asia/Taipei\" , \"readme\" : \"https://ipinfo.io/missingauth\" } curl ifconfig.co/json { \"asn\" : \"AS3462\" , \"asn_org\" : \"Data Communication Business Group\" , \"city\" : \"Taipei\" , \"country\" : \"Taiwan\" , \"country_eu\" : false, \"country_iso\" : \"TW\" , \"hostname\" : \"59-124-114-73.HINET-IP.hinet.net\" , \"ip\" : \"59.124.114.73\" , \"ip_decimal\" : 998011465 , \"latitude\" : 25 .0478, \"longitude\" : 121 .5318, \"region_code\" : \"TPE\" , \"region_name\" : \"Taipei City\" , \"time_zone\" : \"Asia/Taipei\" , \"user_agent\" : { \"product\" : \"HTTPie\" , \"raw_value\" : \"HTTPie/1.0.2\" , \"version\" : \"1.0.2\" } } curl -s https://ipvigilante.com/ $( curl -s https://ipinfo.io/ip ) { \"status\" : \"success\" , \"data\" : { \"ipv4\" : \"59.124.114.73\" , \"continent_name\" : \"Asia\" , \"country_name\" : \"Taiwan\" , \"subdivision_1_name\" :null, \"subdivision_2_name\" :null, \"city_name\" :null, \"latitude\" : \"23.50000\" , \"longitude\" : \"121.00000\" }} Nginx Ingress will use default fake certificate \u00b6 apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : namespace : staging name : demo annotations : kubernetes.io/ingress.class : \"nginx\" nginx.ingress.kubernetes.io/ssl-redirect : \"false\" # Default:true spec : tls : - secretName : staging-tls rules : - http : paths : - backend : serviceName : demo-web servicePort : http curl -kvL https://api.r-live.swaggg.dev * Server certificate: * subject: O = Acme Co ; CN = Kubernetes Ingress Controller Fake Certificate * start date: Jun 24 04 :25:00 2020 GMT * expire date: Jun 24 04 :25:00 2021 GMT * issuer: O = Acme Co ; CN = Kubernetes Ingress Controller Fake Certificate * SSL certificate verify result: unable to get local issuer certificate ( 20 ) , continuing anyway. 2020-06-23 \u00b6 Intall Google Cloud SDK in docker image \u00b6 FROM docker:stable RUN \\ apk add curl bash python git && \\ curl https://sdk.cloud.google.com | bash -s -- --disable-prompts ENV PATH $PATH :/root/google-cloud-sdk/bin Linux - Get external ip in curl cli \u00b6 ref: https://www.tecmint.com/find-linux-server-public-ip-address/ $ curl ifconfig.co $ curl ifconfig.me $ curl icanhazip.com $ curl https://ipinfo.io/ip Kubernetes - GKE/GCP proxy to internal load balancer \u00b6 https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing#global_access Internal load balancer apiVersion : v1 kind : Service metadata : namespace : default name : ilb-api annotations : cloud.google.com/load-balancer-type : \"Internal\" # This is beta. So it needs to follow this: https://stackoverflow.com/a/59658742/3854890 # gcloud beta compute forwarding-rules update xxxxx --region us-central1 --allow-global-access # networking.gke.io/internal-load-balancer-allow-global-access: \"true\" # This is for same VPC different region. spec : externalTrafficPolicy : Local type : LoadBalancer selector : role : api ports : - port : 80 targetPort : http protocol : TCP Proxy service to internal load balancer apiVersion : v1 kind : Service metadata : namespace : web name : api-proxy spec : ports : - protocol : TCP port : 80 targetPort : 80 --- kind : Endpoints apiVersion : v1 metadata : namespace : web name : api-proxy subsets : - addresses : - ip : 10.100.0.100 ports : - port : 80 GKE - Internal Load Balancer don't need extra firewalls \u00b6 ref: https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing#global_access no need to add additional firewalls. Default can access same region+project Internal Load Balancer. Without global access, traffic originating from clients in your VPC network must be in the same region as the load balancer. Global access is enabled per-Service using the following annotation: networking.gke.io/internal-load-balancer-allow-global-access: \"true\". Global access is available in Beta on GKE clusters 1.16 and up. 2020-06-18 \u00b6 Linux - adduser without prompts \u00b6 adduser runner --disabled-password --gecos \"\" Linux - Add sudoer group to user \u00b6 echo \"runner ALL=(ALL) NOPASSWD: ALL\" >> /etc/sudoers && \\ usermod -aG sudo runner Github Action Runner - Fix gifsicle: Command failed \u00b6 Solution ref: https://github.com/imagemin/imagemin-gifsicle/issues/37#issuecomment-577889854 apt-get install -y --no-install-recommends autoconf automake libtool dh-autoreconf error /home/runner/_work/runner-demo/node_modules/gifsicle: Command failed. Exit code: 1 Command: node lib/install.js info Visit https://yarnpkg.com/en/docs/cli/install for documentation about this command. Arguments: Directory: /home/runner/_work/runner-demo/node_modules/gifsicle Output: \u26a0 Response code 404 (Not Found) \u26a0 gifsicle pre-build test failed \u2139 compiling from source \u2716 Error: Command failed: /bin/sh -c ./configure --disable-gifview --disable-gifdiff --prefix=\"/home/runner/_work/runner-demo/node_modules/gifsicle/vendor\" --bindir=\"/home/runner/_work/runner-demo/node_modules/gifsicle/vendor\" config.status: error: in `/tmp/ee647f58-0c5e-49d4-995d-bf84ec21ed4e': config.status: error: Something went wrong bootstrapping makefile fragments 2020-06-11 \u00b6 Failed to determine a valid solver configuration for the set of domains on the Order: no configured challenge solvers can be used for this challenge \u00b6 That's because Let's encrypt HTTP01 doesn't support wildcard(*) domains. So, we can't use *.rammus.cf in apiVersion : cert-manager.io/v1alpha2 kind : Issuer metadata : namespace : web name : rammus spec : acme : email : rammus@rammus.cf server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : rammus solvers : - http01: ingress : class : nginx --- apiVersion : cert-manager.io/v1alpha2 kind : Certificate metadata : namespace : web name : rammus spec : secretName : rammus-tls issuerRef : # The issuer created previously kind : Issuer name : rammus dnsNames : - 'rammus.cf' - '*.rammus.cf' - 'api.rammus.cf' 2020-06-05 \u00b6 gsutil - Verify a google service account with docker and a environment variable \u00b6 docker run -it --rm --entrypoint bash gcr.io/cloud-builders/gsutil sa = '{key.json,....}' gcloud auth activate-service-account --key-file = < ( echo $sa ) gsutil ls gs://rammus.dev 2020-06-02 \u00b6 Kubernetes - Get client ip from Google Network Load Balancer \u00b6 https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer spec : externalTrafficPolicy : Local type : LoadBalancer kubernetes issue: https://github.com/kubernetes/kubernetes/issues/10921 Direct server return (DSR) \u00b6 https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236 2020-05-26 \u00b6 Nginx - get request connection id \u00b6 ref: - https://stackoverflow.com/questions/17748735/setting-a-trace-id-in-nginx-load-balancer - http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive server { listen 80 default_server deferred; set $trace_id $connection-$connection_requests; location / { proxy_set_header Host 'api.swag.live'; proxy_pass https://api$request_uri; proxy_cache_key api$request_uri; proxy_set_header X-Request-Id $trace_id; } } Nginx - proxy_set_header will diable persistent connection \u00b6 proxy_set_header upstream swaglive { server swaglive.web; keepalive 16; keepalive_requests 100000; } proxy_http_version 1.1; proxy_set_header Connection \"\"; HTML - Expires and Cache-Control \u00b6 Cache-Control > Expires Expires: HTTP 1.0 Cache-Control: HTTP 1.1 ref: https://blog.techbridge.cc/2017/06/17/cache-introduction/ 2020-05-22 \u00b6 Nginx - use http header as variable \u00b6 $http_name ex: $http_referer $http_user_agent $http_x_forwarded_for Nginx - SSL_do_handshake() failed (SSL: error:1408F10B:SSL routines:SSL3_GET_RECORD:wrong version number) while SSL handshaking to upstream \u00b6 proxy_ssl_session_reuse off; Nginx - server listen 80 default deferred \u00b6 server { listen 80 default deferred; ... } ref: https://stackoverflow.com/questions/8449058/what-does-the-deferred-option-mean-in-nginxs-listen-directive TCP_DEFER_ACCEPT can help boost performance by reducing the amount of preliminary formalities that happen between the server and client. \"deferred\" is Linux-only. For example on FreeBSD it won't work Nginx - Print cache status log \u00b6 log_format main '$remote_addr - $remote_user - $upstream_cache_status [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; 2020-05-20 \u00b6 Nginx - proxy_pass cache prority \u00b6 proxy_cache_path inactive=10m Cache-Control: s-maxage Cache-Control: max-age proxy_cache_valid 200 2s; https://github.com/RammusXu/toolkit/tree/master/docker/two-layer-nginx 2020-05-13 \u00b6 Probot - update file and create pull request \u00b6 https://github.com/octokit/rest.js/issues/845#issuecomment-386108187 2020-05-05 \u00b6 Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/json: dial unix /var/run/docker.sock: connect: permission denied \u00b6 Solution sudo chmod 777 /var/run/docker.sock Install docker on Debian Linux \u00b6 apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common sudo apt-key fingerprint 0EBFCD88 sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian \\ $( lsb_release -cs ) \\ stable\" sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker run hello-world ab benchmark is using 1 core \u00b6 docker run --rm russmckendrick/ab ab -k -n 20000 -c 2000 https://rammus.cf/ Better to use multi-thread benchmark tool docker run --rm williamyeh/wrk -t10 -c500 -d30 --latency https://rammus.cf apk add wrk wrk -t10 -c500 -d30 --latency http://localhost:3000 Can monitor this behavior with: docker stats ab will never over 100%, also need to care about how much resource you give it to docker machine. 2020-05-04 \u00b6 Pemission denied when volumeMounts configmap as file \u00b6 https://github.com/kubernetes/kubernetes/issues/71356 subprocess.call(['./demo.sh']) File \"/usr/local/lib/python3.8/subprocess.py\", line 340, in call with Popen(*popenargs, **kwargs) as p: File \"/usr/local/lib/python3.8/subprocess.py\", line 854, in __init__ self._execute_child(args, executable, preexec_fn, close_fds, File \"/usr/local/lib/python3.8/subprocess.py\", line 1702, in _execute_child raise child_exception_type(errno_num, err_msg, err_filename) PermissionError: [Errno 13] Permission denied: './demo.sh' kind : ConfigMap metadata : name : tls-watch-config data : app.py : | import subprocess subprocess.call(['./update-cert.sh', filename, target_proxy]) update-cert.sh : | echo 'update' volumes : - name : workspace configMap : name : tls-watcher-config defaultMode : 0555 containers : - name : tls-watcher image : python:3.8-alpine3.11 volumeMounts : - name : workspace mountPath : /workspace workingDir : /workspace command : [ \"sh\" , \"-c\" ] args : - | python -u app.py 2020-04-30 \u00b6 Generate an unique sha from multiple file in Mac \u00b6 shasum *.json| shasum | cut -d' ' -f1 2020-04-24 \u00b6 Nginx: could not find named location \u00b6 2020/04/24 09:34:31 [error] 7#7: *58 could not find named location \"@gcsfiles\" while sending to client, client: 10.4.4.2, server: location ~* '^/(js|img|locale)/' { proxy_pass http://backend/$uri; proxy_cache_key rammus.cf$uri; add_header \"Cache-Control\" \"public, max-age=3600\"; add_header Strict-Transport-Security \"max-age=86400; includeSubDomains\" always; proxy_intercept_errors on; error_page 404 = @gcsfiles; } location = @gcsfiles { proxy_pass http://gcs/rammus.cf$uri; proxy_cache_key $http_host$uri; # Enabled HSTS add_header Strict-Transport-Security \"max-age=86400; includeSubDomains\" always; add_header \"Cache-Control\" \"public, max-age=2592300\"; } It should be location = @gcsfiles { location @gcsfiles { without = 2020-04-17 \u00b6 GKE ingress with managed-certificates \u00b6 apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : web namespace : default annotations : # gcloud compute addresses create gclb-web --global # gcloud compute addresses list networking.gke.io/static-ip : 1.1.1.1 # kubectl apply -f certificate.yaml # gcloud compute ssl-certificates list networking.gke.io/managed-certificates : rammus-cf spec : rules : - host : rammus.cf http : paths : - backend : serviceName : my-svc servicePort : http - http : paths : - backend : serviceName : my-svc servicePort : http apiVersion : networking.gke.io/v1beta1 kind : ManagedCertificate metadata : name : rammus-cf spec : domains : - \"rammus.cf\" 2020-04-07 \u00b6 Test a website speed \u00b6 docker run --rm -v \"$(pwd)\":/sitespeed.io sitespeedio/sitespeed.io:12.3.1 https://app.swag.live 2020-03-14 \u00b6 Find other LAN user's IP \u00b6 arp -a 2020-03-13 \u00b6 \u4e2d\u570b\u7684\u6e2c\u901f\u7db2\u7ad9 https://www.17ce.com/ \u00b6 \u53ef\u4ee5\u6e2c\u8a66 CDN \u6548\u679c benchmark warm up 2020-03-12 \u00b6 dnsmasq: unsupported option (check that dnsmasq was compiled with DHCP/TFTP/DNSSEC/DBus support) \u00b6 Solution apk --no-cache add dnsmasq-dnssec \u9019\u500b\u932f\u8aa4\u767c\u751f\u5728: \u4f7f\u7528 alpine linux apk add dnsmasq Enable dnssec # /etc/dnsmasq.conf dnssec conf-file = /usr/share/dnsmasq/trust-anchors.conf dnssec-check-unsigned or # /etc/dnsmasq.conf dnssec trust-anchor=.,19036,8,2,49AAC11D7B6F6446702E54A1607371607A1A41855200FD2CE1CDDE32F24E8FB5 trust-anchor=.,20326,8,2,E06D44B80B8F1D39A95C0B0D7C65D08458E880409BBC683457104237C7F8EC8D dnssec-check-unsigned Success nsmasq_1 | dnsmasq: started, version 2 .80 cachesize 150 dnsmasq_1 | dnsmasq: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN DHCP DHCPv6 no-Lua TFTP no-conntrack ipset auth DNSSEC loop-detect inotify dumpfile dnsmasq_1 | dnsmasq: DNSSEC validation enabled dnsmasq_1 | dnsmasq: configured with trust anchor for <root> keytag 20326 dnsmasq_1 | dnsmasq: configured with trust anchor for <root> keytag 19036 Parsing dnssec anchors in shell script(bash) \u00b6 ref: https://stackoverflow.com/questions/19908777/curl-and-xmllint-pipe https://data.iana.org/root-anchors/root-anchors.xml curl -s https://data.iana.org/root-anchors/root-anchors.xml | \\ xmllint --format --xpath 'concat(\"trust-anchor=.,\", /TrustAnchor/KeyDigest[1]/KeyTag, \",\", /TrustAnchor/KeyDigest[1]/Algorithm, \",\",/TrustAnchor/KeyDigest[1]//DigestType, \",\", /TrustAnchor/KeyDigest[1]/Digest)' - curl -s https://data.iana.org/root-anchors/root-anchors.xml | \\ xmllint --format --xpath 'concat(\"trust-anchor=.,\", /TrustAnchor/KeyDigest[2]/KeyTag, \",\", /TrustAnchor/KeyDigest[2]/Algorithm, \",\",/TrustAnchor/KeyDigest[2]//DigestType, \",\", /TrustAnchor/KeyDigest[2]/Digest)' - Commands of testing domain \u00b6 apk add bind-tools nslookup swag.live localhost nslookup swag.live 127 .0.0.1 dig @localhost swag.live dig @127.0.0.1 swag.live dig @8.8.8.8 swag.live dig +trace swag.live dig +short swag.live ns dig @dnsmasq +dnssec swag.live dig @dnsmasq +dnssec google.com 2020-03-11 \u00b6 Check multiple variables are not None in Python \u00b6 ref: https://stackoverflow.com/questions/42360956/what-is-the-most-pythonic-way-to-check-if-multiple-variables-are-not-none params = os . getenv ( 'PARAMS' ) sid = os . getenv ( 'SID' ) skey = os . getenv ( 'SKEY' ) if None in ( params , sid , skey ): print ( \"Must have SID, SKEY, PARAMS\" ) exit ( 1 ) 2020-03-10 \u00b6 GCS roles \u00b6 Storage Object Admin resourcemanager.projects.get resourcemanager.projects.list storage.objects.create storage.objects.delete storage.objects.get storage.objects.getIamPolicy storage.objects.list storage.objects.setIamPolicy storage.objects.update Storage Object Creator resourcemanager.projects.get resourcemanager.projects.list storage.objects.create Storage Object Viewer resourcemanager.projects.get resourcemanager.projects.list storage.objects.get storage.objects.list 2020-03-09 \u00b6 Get nth line of stdout on linux \u00b6 ref: https://stackoverflow.com/questions/1429556/command-to-get-nth-line-of-stdout ls -l | sed -n 2p ls -l | head -2 | tail -1 Sort GCS (google cloud storage) objects by date \u00b6 ref: https://stackoverflow.com/a/51709554/3854890 gsutil ls -l gs:// [ bucket-name ] / | sort -r -k 2 Example: ~ gsutil ls -l gs://rammus.cf/download | sort -r -k 2 62786148 2020 -03-06T05:52:53Z gs://rammus.cf/download/3.0.2.8087.086886.apk 62732280 2020 -03-04T03:07:33Z gs://rammus.cf/download/3.0.1-8070.apk 62729059 2020 -03-02T16:25:22Z gs://rammus.cf/download/3_0_1_8ca354.apk 11 2020 -03-02T16:25:03Z gs://rammus.cf/download/ Measuring kubernetes dns \u00b6 bash-5.0# time ( for i in { 1 ..100 } ; do host -U echoserver.ops > /dev/null ; done ) real 0m1.150s user 0m0.445s sys 0m0.278s bash-5.0# time ( for i in { 1 ..100 } ; do host -U echoserver.ops.svc.cluster.local > /dev/null ; done ) real 0m1.762s user 0m0.463s sys 0m0.362s bash-5.0# host -v echoserver.ops Trying \"echoserver.ops.ops.svc.cluster.local\" Trying \"echoserver.ops.svc.cluster.local\" bash-5.0# host -v echoserver.ops.svc.cluster.local Trying \"echoserver.ops.svc.cluster.local.ops.svc.cluster.local\" Trying \"echoserver.ops.svc.cluster.local.svc.cluster.local\" Trying \"echoserver.ops.svc.cluster.local.cluster.local\" Trying \"echoserver.ops.svc.cluster.local.google.internal\" Trying \"echoserver.ops.svc.cluster.local\" bash-5.0# cat /etc/resolv.conf nameserver 10 .24.0.10 search ops.svc.cluster.local svc.cluster.local cluster.local google.internal options ndots:5 2020-03-06 \u00b6 How does UDP request receiving responses. \u00b6 SOCK_STREAM: TCP SOCK_DGRAM: UDP https://stackoverflow.com/questions/1815030/receiving-a-response-through-udp Client emits UDP packet. Router passes UDP packet to the Internet. Router remembers that client sent a UDP packet to server, and establishes a mapping in its memory. Server sends a UDP packet, probably on the same port. Router receives packet, and checks mapping to find client talked to server recently. Router passes packet to client. https://ns1.com/resources/dns-protocol DNS communication occurs via two types of messages: queries and replies. Both DNS query format and reply format consist of the following sections: The header section contains Identification; Flags; Number of questions; Number of answers; Number of authority resource records (RRs); and Number of additional resource records. The flag field contains sections of one or four bits, indicating type of message, whether the name server is authoritative; whether the query is recursive or not, whether request was truncated, and status. The question section contains the domain name and type of record (A, AAAA, MX, TXT, etc.) being resolved. Each label in the domain name is prefixed by its length. The answer section has the resource records of the queried name. http://www-inf.int-evry.fr/~hennequi/CoursDNS/NOTES-COURS_eng/msg.html Weave Scope - \u76e3\u63a7 kubernetes \u7684\u5de5\u5177 \u00b6 ref: https://www.weave.works/docs/scope/latest/installing/#kubernetes \u5b89\u88dd Weave Scope kubectl apply -f \"https://cloud.weave.works/k8s/scope.yaml?k8s-version= $( kubectl version | base64 | tr -d '\\n' ) \" Expose \u670d\u52d9\u5230 localhost kubectl port-forward -n weave service/weave-scope-app 4040:80 open -a \"Google Chrome\" \"http://localhost:4040\" 2020-03-05 \u00b6 Try to resolve a domain in kubernetes \u00b6 Default /etc/resolv.conf is like: nameserver 10.24.0.10 search default.svc.cluster.local svc.cluster.local cluster.local google.internal options ndots:5 \u5c11\u65bc 5 \u500b dot (.) \u5c07\u6703\u5148\u641c\u5c0b search default.svc.cluster.local svc.cluster.local cluster.local google.internal > host -v a.a.a.www.google.com Trying \"a.a.a.www.google.com\" > host -v a.a.www.google.com Trying \"a.a.www.google.com.ops.svc.cluster.local\" Trying \"a.a.www.google.com.svc.cluster.local\" Trying \"a.a.www.google.com.cluster.local\" Trying \"a.a.www.google.com.google.internal\" Trying \"a.a.www.google.com\" > host -v www.google.com Trying \"www.google.com.ops.svc.cluster.local\" Trying \"www.google.com.svc.cluster.local\" Trying \"www.google.com.cluster.local\" Trying \"www.google.com.google.internal\" Trying \"www.google.com\" 2020-03-04 \u00b6 how-to-perform-ddos-test-as-a-pentester \u00b6 https://pentest.blog/how-to-perform-ddos-test-as-a-pentester/ Install netstress on kali linux \u00b6 apt-get update apt-get install netstress Run kali linux on Kubernetes \u00b6 apiVersion : v1 kind : Pod metadata : name : kali labels : app : kali spec : ## Select node pool in GKE # affinity: # nodeAffinity: # requiredDuringSchedulingIgnoredDuringExecution: # nodeSelectorTerms: # - matchExpressions: # - key: cloud.google.com/gke-nodepool # operator: In # values: # - \"pool-1\" containers : - image : kalilinux/kali command : [ \"/bin/sh\" , \"-c\" ] args : - | tail -f /dev/null imagePullPolicy : IfNotPresent name : kali restartPolicy : Never GKE NodeLocal DNSCache \u00b6 https://cloud.google.com/kubernetes-engine/docs/how-to/nodelocal-dns-cache Base on CoreDNS Install dnsperf on alpine \u00b6 ref: - https://github.com/ssro/dnsperf/blob/master/Dockerfile - https://github.com/guessi/docker-dnsperf/blob/master/bench/k8s-dnsperf-bench.yaml DNSPERF = dnsperf-2.3.2 apk add --update --no-cache --virtual deps wget g++ make bind-dev openssl-dev libxml2-dev libcap-dev json-c-dev krb5-dev protobuf-c-dev fstrm-dev \\ && apk add --update --no-cache bind libcrypto1.1 \\ && wget https://www.dns-oarc.net/files/dnsperf/ $DNSPERF .tar.gz \\ && tar zxvf $DNSPERF .tar.gz \\ && cd $DNSPERF \\ && sh configure \\ && make \\ && strip ./src/dnsperf ./src/resperf \\ && make install echo \"kube-dns.kube-system.svc.cluster.local A\" > records.txt echo \"echoserver.ops.svc.cluster.local A\" > records.txt dnsperf -l 10 \\ -s 10 .140.0.53 \\ -T 20 \\ -c 20 \\ -q 10000 \\ -Q 10000 \\ -S 5 \\ -d records.txt dnsperf -l 10 \\ -T 20 \\ -c 20 \\ -q 10000 \\ -Q 10000 \\ -S 5 \\ -d records.txt -l run for at most this many seconds -s the server -T the number of threads to run -c the number of clients to act as to query (default: 127.0.0.1) -q the maximum number of queries outstanding (default: 100) -Q limit the number of queries per second -S print qps statistics every N seconds -d the input data file (default: stdin) 2020-03-03 \u00b6 Open Google Chrome browser in Mac terminal \u00b6 open -a \"Google Chrome\" \"http://localhost:5601\" 2020-03-02 \u00b6 Create a temporary pod to debug and kill itself after an hour \u00b6 apiVersion : v1 kind : Pod metadata : name : busybox1 labels : app : busybox1 spec : containers : # - image: busybox - image : alpine:3.11 command : - sleep - \"3600\" imagePullPolicy : IfNotPresent name : busybox restartPolicy : Never DNS load testing in Alpine \u00b6 apk add gcc g++ make libffi-dev openssl-dev git git clone https://github.com/jedisct1/dnsblast.git cd dnsblast && make #./dnsblast [host] [times] [request per second] ./dnsblast kube-dns.kube-system 10000 1000 ./dnsblast 127 .0.0.1 10000 1000 The command above will break kube-dns. There are 5 kube-dns pods, but only one is receiving request. Caused by iptable and UDP. dnsmasq I0302 08 :47:01.002440 1 nanny.go:146 [] dnsmasq [ 23 ] : Maximum number of concurrent DNS queries reached ( max: 1500 ) sidecar W0302 08 :47:01.248582 1 server.go:64 [] Error getting metrics from dnsmasq: read udp 127 .0.0.1:37986->127.0.0.1:53: i/o timeout GKE v1.13.x uses kube-dns rather than core-dns. \u00b6 ref: https://cloud.google.com/kubernetes-engine/docs/release-notes#new_features_6 GKE is using kube- rather than core-dns. No idea why they are doing this. Install gcc compiler in Alpine \u00b6 ref: https://github.com/nange/blog/issues/3 apk add gcc g++ make libffi-dev openssl-dev echo -n \u00b6 https://linux.die.net/man/1/echo -n do not output the trailing newline 2020-02-27 \u00b6 Get GitHub user info \u00b6 https://developer.github.com/v3/#authentication curl -u \"username\" https://api.github.com/user curl -H \"Authorization: token $PAT \" https://api.github.com/user 2020-02-26 \u00b6 Use CloudFlare WARP as VPN on Mac/PC \u00b6 https://community.cloudflare.com/t/tutorial-how-to-use-cloudflare-warp-on-your-mac/129919?fbclid=IwAR3OlvJrv2EW3KoH3GlDA-gURM5BgPKiaP5RDjjlgBHyYpKWbryZzbrPDGw WARP (CloudFlare VPN) is made from Wireguard. Therefore we can generate a Wirrguard config from CloudFlare and use it on PC. Refresh/Clean CDN cache on Tencent Cloud \u00b6 https://console.cloud.tencent.com/cdn/refresh Just type what url you want to refresh. You might have to verify by doing a request from a location with a Cloudflare edge \u00b6 I tested it on https://tools.pingdom.com/ test in Tokyo CloudFlare/Google CDN both have edges GCS hosting need more DNS time: 40 ms 2020-02-24 \u00b6 CloudFlare worker - Can't resovle/find domain \u00b6 Need to manully add this record to route worker. ref: https://community.cloudflare.com/t/a-record-name-for-worker/98841 Solution Add an A record to 192.0.2.1 CloudFlare worker - how to handle SPA \u00b6 I found there's 404 when I tried to refresh in other page like /faq. ref: https://stackoverflow.com/questions/58432345/cloudflare-workers-spa-with-vuejs options . mapRequestToAsset = req => { // First let's apply the default handler, which we imported from // '@cloudflare/kv-asset-handler' at the top of the file. We do // this because the default handler already has logic to detect // paths that should map to HTML files, for which it appends // `/index.html` to the path. req = mapRequestToAsset ( req ) // Now we can detect if the default handler decided to map to // index.html in some specific directory. if ( req . url . endsWith ( '/index.html' )) { // Indeed. Let's change it to instead map to the root `/index.html`. // This avoids the need to do a redundant lookup that we know will // fail. return new Request ( ` ${ new URL ( req . url ). origin } /index.html` , req ) } else { // The default handler decided this is not an HTML page. It's probably // an image, CSS, or JS file. Leave it as-is. return req } } 2020-02-21 \u00b6 Multiple static IP in a load balancer \u00b6 Steps: Manual create ip addresses. Assign ip addresses to load balancer frontend Use externalIPs instead of loadBalancerIP kind : Service apiVersion : v1 metadata : name : dnsmasq spec : selector : name : dnsmasq type : LoadBalancer externalIPs : - a.a.a.a - a.a.a.b ports : - name : dnsmasq-udp port : 53 protocol : UDP targetPort : dnsmasq-udp # loadBalancerIP: a.a.a.a Testing HPA high memory \u00b6 ref: https://github.com/feiskyer/kubernetes-handbook/blob/master/examples/hpa-memory.yaml apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler metadata : name : nginx-hpa spec : scaleTargetRef : apiVersion : extensions/v1beta1 kind : Deployment name : dnsmasq minReplicas : 1 maxReplicas : 5 metrics : - type : Resource resource : name : memory targetAverageUtilization : 60 and get in a container $ kubectl exec -it dnsmasq-5964d6fdc-2ktt8 sh generate high memory usage $ yes | tr \\\\ n x | head -c 100m | grep n About Kubernetes HPA(Horizontal Pod Autoscaler) \u00b6 ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )] \u6bcf 15 \u79d2\u6aa2\u67e5\u4e00\u6b21 \u9810\u8a2d downscale: 5m 2020-02-19 \u00b6 Use environment from parent process in Nginx(OpenResty) \u00b6 \u5728 nginx \u8b80\u53d6\u74b0\u5883\u8b8a\u6578\u7684\u6b63\u78ba\u65b9\u6cd5: \u5148\u5728 root block export \u8b8a\u6578 \u4f7f\u7528 lua os.getenv(\"MY_ENV\")) env MY_ENV; env PATH; http { server { location / { content_by_lua_block { ngx.say(os.getenv(\"MY_ENV\")); ngx.say(os.getenv(\"PATH\")); } } } } cannot create an external load balancer with mix protocols \u00b6 The Service \"dnsmasq\" is invalid: spec.ports: Invalid value: [] core.ServicePort { core.ServicePort { Name: \"dnsmasq\" , Protocol: \"TCP\" , Port:53, TargetPort:intstr.IntOrString { Type:1, IntVal:0, StrVal: \"dnsmasq\" } , NodePort:0 } , core.ServicePort { Name: \"dnsmasq-udp\" , Protocol: \"UDP\" , Port:53, TargetPort:intstr.IntOrString { Type:1, IntVal:0, StrVal: \"dnsmasq-udp\" } , NodePort:0 }} : cannot create an external load balancer with mix protocols 2020-02-18 \u00b6 Try docker-compose health check \u00b6 https://github.com/peter-evans/docker-compose-healthcheck healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U postgres\"] interval: 10s timeout: 5s retries: 5 Docker \u66f4\u65b0\u5f8c\u8df3\u51fa docker-credential-osxkeychain \u60f3\u4f7f\u7528\u9470\u5319\u5708 ci-db \u00b6 https://github.com/docker/for-mac/issues/3805#issuecomment-518619953 Solution Open ~/.docker/config.json Set \"credsStore\":\"\" How to use cc-by-sa license \u00b6 Plain text: https://creativecommons.org/licenses/by-sa/4.0/legalcode.txt Image: <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a> [![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/) Print a colorful text in terminal \u00b6 ANSI - \u8f38\u51fa\u6587\u5b57\u8b8a\u8272 echo -e \"\\e[1;31mHello\\e[0m World\" Render a chart inside markdown with canvasjs \u00b6 window.onload = function () { var limit = 50000; var y = 100; var data = []; var dataSeries = { type: \"line\" }; var dataPoints = []; for (var i = 0; i < limit; i += 1) { y += Math.round(Math.random() * 10 - 5); dataPoints.push({ x: i, y: y }); } dataSeries.dataPoints = dataPoints; data.push(dataSeries); //Better to construct options first and then pass it as a parameter var options = { zoomEnabled: true, animationEnabled: true, title: { text: \"Try Zooming - Panning\" }, axisY: { includeZero: false, lineThickness: 1 }, data: data // random data }; var chart = new CanvasJS.Chart(\"chartContainer\", options); chart.render(); } 2020-02-15 \u00b6 Restart a kubernetes resource without down time and using same config(yaml) \u00b6 Kubernetes >= 1.15 ref: https://github.com/kubernetes/kubernetes/issues/33664#issuecomment-497242094 Gracefully rolling restart deployment. kubectl rollout restart deployment/my-sites --namespace = default \bRun commnad without(ignoring) output \u00b6 https://askubuntu.com/questions/474556/hiding-output-of-a-command command > /dev/null 2 > & 1 command > & /dev/null Example: Still show errors when command failed. $ edho hi > /dev/null zsh: command not found: edho Don't show error even when command failed. $ edho hi > & /dev/null 2020-02-13 \u00b6 \u5728 docker-compose \u4e2d\u7684\u5bb9\u5668\u4e92\u76f8\u6e9d\u901a \u00b6 service name \u6703\u88ab\u7d81\u5230 DNS\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 service name \u7576\u4f5c host version : '3' services : redis : image : \"redis:alpine\" ports : - \"6379:6379\" celery : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis celery-2 : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis $ docker network ls NETWORK ID NAME DRIVER SCOPE 01681ec52fea celery_default bridge local $ docker exec -it celery_celery_1 bash user@dcd8cf4a9d04:~$ ping celery-2 PING celery-2 ( 192 .168.0.4 ) : 56 data bytes 64 bytes from 192 .168.0.4: icmp_seq = 0 ttl = 64 time = 0 .162 ms 64 bytes from 192 .168.0.4: icmp_seq = 1 ttl = 64 time = 0 .223 ms ^C--- celery-2 ping statistics --- 2 packets transmitted, 2 packets received, 0 % packet loss round-trip min/avg/max/stddev = 0 .162/0.193/0.223/0.031 ms user@dcd8cf4a9d04:~$ ping celery-3 ping: unknown host mkdocs minify html got error \u00b6 mkdocs.yaml plugins : - minify : minify_html : true Bug print \"htmlmin option \" + key + \" not recognized\" ^ SyntaxError: Missing parentheses in call to 'print' . Did you mean print ( \"htmlmin option \" + key + \" not recognized\" ) ? Solution ref: https://github.com/byrnereese/mkdocs-minify-plugin/issues/8 Upgrade mkdocs-minify-plugin>= 0.2.3","title":"2020"},{"location":"Today-I-Learned/2020/#2020-12-17","text":"","title":"2020-12-17"},{"location":"Today-I-Learned/2020/#nginx-brotli-behavior","text":"gzip_vary on; will affect brotli_static . brotli_static will look this config.","title":"Nginx - brotli behavior"},{"location":"Today-I-Learned/2020/#2020-12-04","text":"","title":"2020-12-04"},{"location":"Today-I-Learned/2020/#gcp-internal-load-balancer-behavior","text":"Internal Load Balancer 192.168.0.101 have a Instance Group contains 192.168.0.3 192.168.0.4 in 192.168.0.3 curl 192.168.0.101, will always request to 192.168.0.3 in 192.168.0.4 curl 192.168.0.101, will always request to 192.168.0.4","title":"GCP - Internal Load Balancer Behavior"},{"location":"Today-I-Learned/2020/#2020-12-03","text":"","title":"2020-12-03"},{"location":"Today-I-Learned/2020/#cn2-network-go-out-from-china","text":"59.43. . is CN2 GIA better 202.97. . is CN2 GT Traceroute from China: https://tools.ipip.net/traceroute.php","title":"\bCN2 network - go out from China"},{"location":"Today-I-Learned/2020/#curl-get-current-ip-and-geo-location-in-china","text":"curl https://myip.ipip.net\\?json \u5f53\u524d IP\uff1a183.240.8.10 \u6765\u81ea\u4e8e\uff1a\u4e2d\u56fd \u5e7f\u4e1c \u5e7f\u5dde \u79fb\u52a8","title":"curl - get current ip and geo location in China"},{"location":"Today-I-Learned/2020/#kubernetes-resourcememory-mi-vs-m","text":"Mi = 1024*1024 = 1048576 M = 1000*1000 = 1000000","title":"Kubernetes - resource.memory Mi vs M"},{"location":"Today-I-Learned/2020/#2020-11-20","text":"","title":"2020-11-20"},{"location":"Today-I-Learned/2020/#k9s-install-k9s-on-ubuntu-linux","text":"/bin/bash -c \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh ) \" # brew install derailed/k9s/k9s brew install k9s ref: https://brew.sh/ https://k9scli.io/topics/install/","title":"k9s - Install k9s on Ubuntu Linux"},{"location":"Today-I-Learned/2020/#k3sup","text":"https://github.com/alexellis/k3sup curl -sLS https://get.k3sup.dev | sh sudo install k3sup /usr/local/bin/ k3sup --help ssh-keygen -f ~/.ssh/k3s -N \"\" Add ssh-rsa.pub https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys#block-project-keys https://console.cloud.google.com/compute/metadata/sshKeys export SSH_USER=rammus export MASTER_IP=10.0.0.2 k3sup install --ip $MASTER_IP --user $SSH_USER --ssh-key ~/.ssh/k3s export KUBECONFIG=/home/rammus_xu/kubeconfig kubectl get node -o wide export AGENT_IP=10.0.0.3 k3sup join --ip $AGENT_IP --server-ip $MASTER_IP --user $SSH_USER --ssh-key ~/.ssh/k3s","title":"k3sup"},{"location":"Today-I-Learned/2020/#2020-11-12","text":"","title":"2020-11-12"},{"location":"Today-I-Learned/2020/#kuberntes-pod-injecthijackdebug","text":"command : [ \"/bin/sh\" , \"-c\" ] args : - | tail -f /dev/null","title":"Kuberntes - Pod inject/hijack/debug"},{"location":"Today-I-Learned/2020/#2020-11-10","text":"","title":"2020-11-10"},{"location":"Today-I-Learned/2020/#mongodb-not-master-and-slaveokfalse","text":"rs0:SECONDARY> show dbs ... \"errmsg\" : \"not master and slaveOk=false\", \"code\" : 13435, \"codeName\" : \"NotMasterNoSlaveOk\", ... rs0:SECONDARY> rs.slaveOk() rs0:SECONDARY> show dbs admin 0.000GB config 0.000GB demo 0.000GB local 0.000GB","title":"MongoDB - not master and slaveOk=false"},{"location":"Today-I-Learned/2020/#mongodb-could-not-find-host-matching-read-preference-mode-primary-for-set-rs0","text":"mo n gos> sh.addShard( \"rs0/mongo-rs0-0.mongo-rs0.testing-mongo.svc.cluster.local:27017,mongo-rs0-1.mongo-rs0.testing-mongo.svc.cluster.local:27017,mongo-rs0-2.mongo-rs0.testing-mongo.svc.cluster.local:27017\" ) { \"ok\" : 0 , \"errmsg\" : \"Could not find host matching read preference { mode: \\\"primary\\\" } for set rs0\" , \"code\" : 133 , \"codeName\" : \"FailedToSatisfyReadPreference\" , \"operationTime\" : Times ta mp( 1604989375 , 2 ) , \"$clusterTime\" : { \"clusterTime\" : Times ta mp( 1604989377 , 1 ) , \"signature\" : { \"hash\" : Bi n Da ta ( 0 , \"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\" ) , \"keyId\" : NumberLo n g( 0 ) } } } Debug: config rs seems ok. not error log on mongos mongo mongo-rs0-0.mongo-rs0.testing-mongo.svc.cluster.local:27017 rs0-0, rs0-1 rs0-2 are ok rs0-0 is primary, read/write ok Solution mongos version and replica set version should be same. This error occurs when: shardsvr 4.0.20 + mongos 4.0.20 + configsvr 4.0.20 shardsvr 4.0.20 + mongos 4.0.20 + configsvr 4.4 shardsvr 4.0.20 + mongos 4.4 + configsvr 4.4 shardsvr 4.0.20, 3.6.6 mixed + mongos 4.0.20 + configsvr 4.0.20","title":"MongoDB - Could not find host matching read preference { mode: \\\"primary\\\" } for set rs0"},{"location":"Today-I-Learned/2020/#2020-11-08","text":"","title":"2020-11-08"},{"location":"Today-I-Learned/2020/#gke-node-auto-repair","text":"https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-repair GKE \u6703\u5b9a\u671f\u6aa2\u67e5 nodes\uff0c\u5982\u679c\u767c\u751f\u6301\u7e8c\u6027\u7684\u4e0d\u5065\u5eb7\uff0c GKE \u5c07\u6703\u958b\u59cb\u9032\u884c\u4fee\u5fa9\u7684\u7a0b\u5e8f\u3002 \u4ee5 Status: Ready \u7576\u4f5c\u57fa\u6e96\uff0c\u4ee5\u4e0b\u60c5\u6cc1\u6703\u8996\u70ba\u4e0d\u5065\u5eb7: - \u9023\u7e8c 10 \u5206\u9418 Status: NotReady - \u9023\u7e8c 10 \u5206\u9418\u6c92\u6709\u4efb\u4f55\u72c0\u614b - boot disk \u7528\u5b8c\u786c\u789f\u7a7a\u9593\uff0c\u8d85\u904e 30 \u5206\u9418 \u6aa2\u67e5\u6700\u8fd1\u7684 operations\uff0c\u53ef\u4ee5\u770b\u5230\u6709\u6c92\u6709 auto repair \u3002 gcloud container operations list","title":"GKE - Node auto repair"},{"location":"Today-I-Learned/2020/#2020-11-06","text":"","title":"2020-11-06"},{"location":"Today-I-Learned/2020/#kubernetes-cusotmize-a-hostname","text":"apiVersion : v1 kind : Pod metadata : namespace : testing-mongo name : rammus-cf labels : name : rammus-cf spec : hostname : rammus subdomain : cf containers : - name : nginx image : nginx --- apiVersion : v1 kind : Service metadata : name : cf spec : selector : name : rammus-cf clusterIP : None \u5728 cluster \u88e1\u9762\u53ef\u4ee5\u7528 curl rammus.cf","title":"Kubernetes - Cusotmize a hostname"},{"location":"Today-I-Learned/2020/#2020-11-03","text":"","title":"2020-11-03"},{"location":"Today-I-Learned/2020/#gke-node-auto-repair-notes","text":"https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-repair GKE \u6703\u5b9a\u671f\u6aa2\u67e5 nodes\uff0c\u5982\u679c\u767c\u751f\u6301\u7e8c\u6027\u7684\u4e0d\u5065\u5eb7\uff0c GKE \u5c07\u6703\u958b\u59cb\u9032\u884c\u4fee\u5fa9\u7684\u7a0b\u5e8f\u3002 \u4ee5 Status: Ready \u7576\u4f5c\u57fa\u6e96\uff0c\u4ee5\u4e0b\u60c5\u6cc1\u6703\u8996\u70ba\u4e0d\u5065\u5eb7: - \u9023\u7e8c 10 \u5206\u9418 Status: NotReady - \u9023\u7e8c 10 \u5206\u9418\u6c92\u6709\u4efb\u4f55\u72c0\u614b - boot disk \u7528\u5b8c\u786c\u789f\u7a7a\u9593\uff0c\u8d85\u904e 30 \u5206\u9418 Checking command: gcloud container operations list","title":"GKE node auto repair notes"},{"location":"Today-I-Learned/2020/#2020-10-30","text":"","title":"2020-10-30"},{"location":"Today-I-Learned/2020/#sign-a-gcs-object","text":"This will use gcs-service.json to generate a URL with expired time -d 1m . You can give someone the URL to access gs://rammus.cf/a-file.txt . gsutil signurl -d 1m gcs-service.json gs://rammus.cf/a-file.txt","title":"Sign a GCS object"},{"location":"Today-I-Learned/2020/#2020-10-22","text":"","title":"2020-10-22"},{"location":"Today-I-Learned/2020/#kubernetes-install-godaddy-ssl-certificate-into-secrets-kubernetesiotls","text":"cat 9faxxxxxxxxxxxxx.crt gd_bundle-g2-g1.crt > chain.crt kubectl create secret tls --cert chain.crt --key generated-private-key.txt rammusxu.tw-tls Test it on local: Add domain in /etc/hosts. Test it with CLI. \u274c curl -kv https://localhost/ -H 'Host: rammusxu.tw' \ud83d\udc4d curl -kv https://rammusxu.tw \u274c openssl s_client -showcerts -connect rammusxu.tw:443 \ud83d\udc4d openssl s_client -showcerts -connect rammusxu.tw:443 -servername rammusxu.tw","title":"Kubernetes - Install godaddy ssl certificate into secrets kubernetes.io/tls"},{"location":"Today-I-Learned/2020/#2020-10-19","text":"","title":"2020-10-19"},{"location":"Today-I-Learned/2020/#nginx-cache-static-with-cache-control","text":"expires max; add_header Cache-Control \"public\";","title":"Nginx - Cache static with Cache-Control"},{"location":"Today-I-Learned/2020/#nginx-react-app-serve-spa-htmls","text":"ref: https://stackoverflow.com/questions/51367160/nginx-tries-to-find-index-html-in-a-directory-according-to-the-uri root /app; index index.html; location / { try_files $uri $uri/ /index.html; }","title":"Nginx - React app serve SPA htmls"},{"location":"Today-I-Learned/2020/#2020-10-16","text":"","title":"2020-10-16"},{"location":"Today-I-Learned/2020/#nginx-automatical-content-type","text":"include mime.types ; path: - /usr/local/openresty/nginx/conf/mime.types; - conf/mime.types;","title":"Nginx - automatical content type"},{"location":"Today-I-Learned/2020/#2020-10-07","text":"","title":"2020-10-07"},{"location":"Today-I-Learned/2020/#mongodb-install-mongo-cli-on-mac","text":"ref: https://dba.stackexchange.com/questions/196330/is-it-possible-to-install-just-the-mongo-shell brew tap mongodb/brew brew install mongodb-community-shell","title":"MongoDB - Install mongo cli on Mac"},{"location":"Today-I-Learned/2020/#mongodb-dump-and-restore","text":"mongodump --gzip --db = test # mongorestore <target> <folder> mongorestore mongodb://localhost:27017 dump","title":"MongoDB - dump and restore"},{"location":"Today-I-Learned/2020/#2020-09-30","text":"","title":"2020-09-30"},{"location":"Today-I-Learned/2020/#1-nodes-had-volume-node-affinity-conflict","text":"ref: https://cloud.google.com/kubernetes-engine/docs/concepts/persistent-volumes#pd-zones Solution apiVersion : storage.k8s.io/v1 kind : StorageClass metadata : name : slow provisioner : kubernetes.io/gce-pd parameters : type : pd-standard fstype : ext4 volumeBindingMode : WaitForFirstConsumer","title":"1 node(s) had volume node affinity conflict."},{"location":"Today-I-Learned/2020/#2020-09-29","text":"","title":"2020-09-29"},{"location":"Today-I-Learned/2020/#gke-dont-enable-podpreset","text":"no matches for kind \"PodPreset\" in version \"settings.k8s.io/v1alpha1 kubectl apply -f podpreset.yaml error: unable to recognize \"podpreset.yaml\": no matches for kind \"PodPreset\" in version \"settings.k8s.io/v1alpha1\" no settings.k8s.io API $ kubectl api-resources|grep settings.k8s.io $ kubectl api-versions|grep settings.k8s.io","title":"GKE don\u2019t enable podpreset"},{"location":"Today-I-Learned/2020/#kubernetes-taint-and-tolerations","text":"ref: https://godleon.github.io/blog/Kubernetes/k8s-Taints-and-Tolerations/ kubectl taint nodes gke-edge-tw-reserved-4c3f498d-068s preemptible=false:NoSchedule kubectl taint nodes gke-edge-tw-reserved-4c3f498d-068s preemptible=false:NoExecute preemptible=false:NoExecute will evicts all pod immediately this means the pod can tolerate a taint node, so it can be deploy nodeSelector : cloud.google.com/gke-nodepool : reserved tolerations : - key : \"preemptible\" operator : \"Equal\" value : \"false\" This can\u2019t deploy nodeSelector : cloud.google.com/gke-nodepool : reserved tolerations : - key : \"preemptible\" operator : \"Equal\" value : \"false\" effect : \"NoSchedule\" Error Message conditions : - lastProbeTime : null lastTransitionTime : \"2020-09-29T07:37:03Z\" message : '0/4 nodes are available: 1 node(s) had taint {preemptible: false}, that the pod didn '' t tolerate, 3 node(s) didn '' t match node selector.' reason : Unschedulable status : \"False\" type : PodScheduled","title":"kubernetes - Taint and Tolerations"},{"location":"Today-I-Learned/2020/#2020-09-17","text":"","title":"2020-09-17"},{"location":"Today-I-Learned/2020/#give-a-set-of-files-a-hash-key","text":"~ # md5sum a b d41d8cd98f00b204e9800998ecf8427e a d41d8cd98f00b204e9800998ecf8427e b ~ # md5sum a b | md5sum fe84858e5913eaed7bf248d8b25a77d7 - ~ # md5sum a b | md5sum | cut -b-32 fe84858e5913eaed7bf248d8b25a77d7 ~ # echo a > a ~ # md5sum a b | md5sum | cut -b-32 e849952f425275e21c0d5c46ba2549f5","title":"Give a set of files a hash key"},{"location":"Today-I-Learned/2020/#2020-09-10","text":"","title":"2020-09-10"},{"location":"Today-I-Learned/2020/#kubernetes-verticalpodautoscaler","text":"https://cloud.google.com/kubernetes-engine/docs/how-to/vertical-pod-autoscaling Limitations https://cloud.google.com/kubernetes-engine/docs/concepts/verticalpodautoscaler#limitations_for_vertical_pod_autoscaling Can\u2019t use with HPA updatePolicy : updateMode : \"Off\" $ kubectl get vpa my-vpa --output yaml ... recommendation: containerRecommendations: - containerName: my-container lowerBound: cpu: 536m memory: 262144k target: cpu: 587m memory: 262144k upperBound: cpu: 27854m memory: \"545693548\"","title":"Kubernetes - VerticalPodAutoscaler"},{"location":"Today-I-Learned/2020/#2020-09-09","text":"","title":"2020-09-09"},{"location":"Today-I-Learned/2020/#disable-gke-release-channel","text":"ref: https://cloud.google.com/kubernetes-engine/docs/concepts/release-channels#updating_the_cluster_release_channel It's not possible to exit RAPID channel for now. $ gcloud container clusters update edge-tw --release-channel None --region asia-east1 ERROR: ( gcloud.container.clusters.update ) INVALID_ARGUMENT: Migrating off of releaseChannel RAPID is not supported.","title":"Disable GKE release channel"},{"location":"Today-I-Learned/2020/#fatal-error-linuxversionh-no-such-file-or-directory","text":"In file included from config.h:21, from ae.c:45: redis_config.h:38:10: fatal error: linux/version.h: No such file or directory 38 | #include <linux/version.h> | ^~~~~~~~~~~~~~~~~ compilation terminated. make [ 1 ] : *** [ Makefile:190: ae.o ] Error 1 make [ 1 ] : Leaving directory '/redis-cluster-proxy/src' make: *** [ Makefile:4: all ] Error 2 Solution apk add linux-headers","title":"fatal error: linux/version.h: No such file or directory"},{"location":"Today-I-Learned/2020/#2020-09-06","text":"","title":"2020-09-06"},{"location":"Today-I-Learned/2020/#upgrade-buildx-version-on-mac","text":"https://gist.github.com/RammusXu/8eb867e2a2dedd3c07149016829da5c3 docker buildx version mkdir -p ~/.docker/cli-plugins BUILDX_VERSION = \"v0.4.2\" wget https://github.com/docker/buildx/releases/download/ ${ BUILDX_VERSION } /buildx- ${ BUILDX_VERSION } .darwin-amd64 -O ~/.docker/cli-plugins/docker-buildx chmod a+x ~/.docker/cli-plugins/docker-buildx docker buildx version","title":"Upgrade buildx version on Mac"},{"location":"Today-I-Learned/2020/#2020-09-03","text":"","title":"2020-09-03"},{"location":"Today-I-Learned/2020/#nginx-change-host-not-found-response-status-and-content","text":"curl localhost:8001/host \"host:backend\" location /host { resolver 127 .0.0.11 ; proxy_pass http:// $http_host$uri ; proxy_cache_key $http_host$uri ; proxy_cache_valid 200 60s ; proxy_intercept_errors on ; error_page 502 503 = 404 / ; } location @host_not_found { echo \"not found\" ; } Host not found frontend_1 | 172 .18.0.1 - - - MISS [ 03 /Sep/2020:09:01:52 +0000 ] \"GET /host HTTP/1.1\" 404 20 \"-\" \"HTTPie/1.0.2\" \"-\" frontend_1 | 2020 /09/03 09 :01:52 [ error ] 6 #6: *12 backend2 could not be resolved (3: Host not found), client: 172.18.0.1, server: , request: \"GET /host HTTP/1.1\", host: \"backend2\" frontend_1 | 2020 /09/03 09 :01:53 [ error ] 6 #6: *13 backend2 could not be resolved (3: Host not found), client: 172.18.0.1, server: , request: \"GET /host HTTP/1.1\", host: \"backend2\" frontend_1 | 172 .18.0.1 - - - MISS [ 03 /Sep/2020:09:01:53 +0000 ] \"GET /host HTTP/1.1\" 404 20 \"-\" \"HTTPie/1.0.2\" \"-\" Host found backend_1 | 172 .18.0.3 - - [ 03 /Sep/2020:09:02:30 +0000 ] \"GET /host HTTP/1.0\" 200 6 \"-\" \"HTTPie/1.0.2\" \"-\" frontend_1 | 172 .18.0.1 - - - MISS [ 03 /Sep/2020:09:02:30 +0000 ] \"GET /host HTTP/1.1\" 200 16 \"-\" \"HTTPie/1.0.2\" \"-\" frontend_1 | 172 .18.0.1 - - - HIT [ 03 /Sep/2020:09:02:38 +0000 ] \"GET /host HTTP/1.1\" 200 16 \"-\" \"HTTPie/1.0.2\" \"-\"","title":"Nginx - Change host not found response status and content"},{"location":"Today-I-Learned/2020/#2020-08-27","text":"","title":"2020-08-27"},{"location":"Today-I-Learned/2020/#2020-cert-manager-request-a-certificate-with-ingress-in-place","text":"ref: https://kosyfrances.github.io/ingress-gce-letsencrypt/ Environment kuberentes: v1.17.9-gke cert-manager: v0.15.0 apiVersion : cert-manager.io/v1alpha2 kind : ClusterIssuer metadata : name : ci-http01 spec : acme : email : rammus.xu@gmail.com server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : issuer-account-key-rammus solvers : - http01 : ingress : class : ingress-gce --- apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : namespace : web name : china-landing annotations : kubernetes.io/ingress.class : \"gce\" cert-manager.io/cluster-issuer : ci-http01 acme.cert-manager.io/http01-edit-in-place : \"true\" spec : tls : - hosts : - rammus.dev secretName : rammus-dev-tls rules : - host : rammus.dev http : paths : - backend : serviceName : http-service-np servicePort : http --- apiVersion : v1 kind : Service metadata : name : http-service-np namespace : web spec : type : NodePort ports : - name : http port : 80 targetPort : http selector : app : http-app","title":"2020 cert-manager request a certificate with ingress in place"},{"location":"Today-I-Learned/2020/#2020-08-21","text":"","title":"2020-08-21"},{"location":"Today-I-Learned/2020/#copy-docker-image-to-another-registry","text":"ref: https://cloud.google.com/artifact-registry/docs/docker/copy-from-gcr#copy-gcloud gcloud container images add-tag GCR-IMAGE AR-IMAGE","title":"Copy docker image to another registry"},{"location":"Today-I-Learned/2020/#nginx-cors-with-map-example","text":"ref: https://blog.51cto.com/tchuairen/2175525 https://github.com/openresty/headers-more-nginx-module map $http_origin $cors_origin { default https://rammus.dev; \"~rammus2020.dev\" $http_origin; } server { listen 80; location / { more_set_headers Access-Control-Allow-Origin $cors_origin; } }","title":"Nginx - CORS with map example"},{"location":"Today-I-Learned/2020/#docker-registry-gitlab-registry","text":"docker pull registry.gitlab.com/rammus.xu/docker-alpine:3.12.0 Public git repo = Public docker registry No need to login to pull Gitlab public registry image 10GB storage, as part of the repository size limit docker login registry.gitlab.com -u rammus.xu -p docker pull nginx:1.19.2-alpine docker tag nginx:1.19.2-alpine registry.gitlab.com/rammus.xu/docker-alpine:nginx-1.19.2 docker push registry.gitlab.com/rammus.xu/docker-alpine:nginx-1.19.2 docker pull registry.gitlab.com/rammus.xu/docker-alpine:nginx-1.19.2","title":"Docker Registry - Gitlab Registry"},{"location":"Today-I-Learned/2020/#docker-registry-github-registry","text":"Can't pull without docker credential docker login https://docker.pkg.github.com -u rammusxu -p docker login https://docker.pkg.github.com -u rammusxu -p docker pull nginx:1.19.2-alpine docker tag nginx:1.19.2-alpine docker.pkg.github.com/rammusxu/docker-alpine/nginx:1.19.2-alpine docker push docker.pkg.github.com/rammusxu/docker-alpine/nginx:1.19.2-alpine docker pull docker.pkg.github.com/rammusxu/docker-alpine/nginx:1.19.2-alpine Error response from daemon: Get https://docker.pkg.github.com/v2/rammusxu/docker-alpine/nginx/manifests/1.19.2-alpine: no basic auth credentials","title":"Docker Registry - Github Registry"},{"location":"Today-I-Learned/2020/#2020-08-19","text":"","title":"2020-08-19"},{"location":"Today-I-Learned/2020/#dockerhub-is-rate-limiting-download-layers","text":"https://www.docker.com/pricing https://docs.docker.com/docker-hub/download-rate-limit/ https://www.docker.com/pricing/retentionfaq https://github.com/testcontainers/testcontainers-java/issues/3099 As of 2020-08-13, Docker have updated their terms of service and pricing page, indicating that: unauthenticated pulls will be rate limited to 100 per 6h authenticated pulls will be rate limited to 200 per 6h Community - https://www.reddit.com/r/docker/comments/i93bui/docker_terms_of_service_change/ - https://www.reddit.com/r/docker/comments/i9lxq3/docker_reduces_image_retaining_to_6_months_for/","title":"Dockerhub is rate limiting download layers"},{"location":"Today-I-Learned/2020/#wheres-disk-storage-locationpath-of-gke-emptydir","text":"# docker container inspect k8s_packager-public_stream-5ad4d9decc14623f43ed1325_default_247be3c5-227d-46cc-9f9c-7aad8cfaeb47_0 | grep Source \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/volumes/kubernetes.io~empty-dir/dist\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/volume-subpaths/workdir/packager-public/1\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/volumes/kubernetes.io~secret/default-token-vvrzk\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/etc-hosts\" , \"Source\" : \"/var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47/containers/packager-public/0fa5ef38\" , # df /var/lib/kubelet/pods/247be3c5-227d-46cc-9f9c-7aad8cfaeb47 -h Filesystem Size Used Avail Use% Mounted on /dev/sda1 2 .0T 173G 1 .8T 9 % /var/lib/kubelet","title":"Where's disk storage location(path) of GKE emptyDir"},{"location":"Today-I-Learned/2020/#2020-08-12","text":"","title":"2020-08-12"},{"location":"Today-I-Learned/2020/#markdown","text":"https://docsify.js.org/#/","title":"markdown \u6587\u4ef6\u88fd\u4f5c"},{"location":"Today-I-Learned/2020/#2020-08-10","text":"","title":"2020-08-10"},{"location":"Today-I-Learned/2020/#istio-on-k3d","text":"curl -L https://istio.io/downloadIstio | sh - cp istio-1.6.7/bin/istioctl $HOME /bin/ # ~/.zshrc export PATH = $HOME /bin:/usr/local/bin: $PATH ~ istioctl version no running Istio pods in \"istio-system\" 1 .6.7 brew install k3d k3d cluster create dc0 --k3s-server-arg --disable = traefik --publish 8080 :80 k3d cluster create dc1 --port 8081 :80 --no-lb --k3s-server-arg --disable = traefik kubectl create namespace istio-system kubectl create secret generic cacerts -n istio-system \\ --from-file = samples/certs/ca-cert.pem \\ --from-file = samples/certs/ca-key.pem \\ --from-file = samples/certs/root-cert.pem \\ --from-file = samples/certs/cert-chain.pem # Install istio istioctl install \\ -f manifests/examples/multicluster/values-istio-multicluster-gateways.yaml # Update coreDNS kubectl apply -f - <<EOF apiVersion: v1 kind: ConfigMap metadata: name: coredns namespace: kube-system data: Corefile: | .:53 { errors health ready kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa } prometheus :9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance } global:53 { errors cache 30 forward . $(kubectl get svc -n istio-system istiocoredns -o jsonpath={.spec.clusterIP}):53 } EOF ref: https://dev.to/bufferings/tried-k8s-istio-in-my-local-machine-with-k3d-52gg","title":"istio on k3d"},{"location":"Today-I-Learned/2020/#configure-k3d-on-mac-zsh","text":"brew instsall k3d mkdir -p ~/.oh-my-zsh/custom/plugins/k3d/_k3d k3d completion zsh > ~/.oh-my-zsh/custom/plugins/k3d/_k3d vi ~/.zshrc plugins =( ... k3d )","title":"Configure k3d on Mac zsh"},{"location":"Today-I-Learned/2020/#2020-08-07","text":"","title":"2020-08-07"},{"location":"Today-I-Learned/2020/#testing-websocket","text":"npm install -g wscat docker run -it --rm -p 10000:8080 jmalloc/echo-server wscat -c ws://localhost:10000","title":"Testing websocket"},{"location":"Today-I-Learned/2020/#2020-08-06","text":"","title":"2020-08-06"},{"location":"Today-I-Learned/2020/#gcp-monitoring-response-throughput-is-including-cdn-hit","text":"Miss 0 Hit 21688/s","title":"GCP Monitoring - Response Throughput is including CDN hit"},{"location":"Today-I-Learned/2020/#nginx-add_header-is-not-working-on-indexhtml","text":"location / { add_header \"Cache-Control\" \"public, max-age=600000\"; index index.html; } location / { add_header \"Cache-Control\" \"public, max-age=600000\"; index index.html; }","title":"Nginx - add_header is not working on index.html"},{"location":"Today-I-Learned/2020/#cc-40","text":"ref: https://xie.infoq.cn/copyright <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License . \u57fa\u65bc CC 4.0 \u5354\u8b70\u9032\u884c\u5982\u4e0b\u985e\u578b\u6388\u6b0a\uff1a CC BY\uff08\u7f72\u540d\uff09\uff1a\u53ea\u8981\u5728\u4f7f\u7528\u6642\u7f72\u540d\uff0c\u90a3\u9ebc\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\u4ee5\u53ca\u5546\u696d\u76ee\u7684\u4f7f\u7528\u3002 CC BY-NC\uff08\u7f72\u540d+ \u975e\u76c8\u5229\uff09\uff1a\u53ea\u8981\u5728\u4f7f\u7528\u3001\u516c\u958b\u6642\u9032\u884c\u7f72\u540d\uff0c\u90a3\u9ebc\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\uff0c\u4f46\u4e0d\u5f97\u5c07\u672c\u5275\u4f5c\u6216\u7531\u672c\u5275\u4f5c\u884d\u751f\u7684\u5275\u4f5c\u904b\u7528\u65bc\u5546\u696d\u76ee\u7684\u3002 CC BY-ND\uff08\u7f72\u540d + \u7981\u6b62\u6f14\u7e79\uff09\uff1a\u53ea\u8981\u5728\u4f7f\u7528\u3001\u516c\u958b\u6642\u9032\u884c\u7f72\u540d\uff0c\u4e26\u4e14\u5c0d\u5275\u4f5c\u4e0d\u52a0\u4efb\u4f55\u6539\u52d5\uff0c\u90a3\u9ebc\u4f7f\u7528\u8005\u53ef\u4ee5\u4f7f\u7528\u672c\u5275\u4f5c\uff0c\u5305\u62ec\u5c07\u5176\u904b\u7528\u65bc\u5546\u696d\u76ee\u7684\u3002 CC BY-NC-ND \uff08\u7f72\u540d + \u975e\u76c8\u5229 + \u7981\u6b62\u6f14\u7e79\uff09\uff1a\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\uff0c\u4f46\u4e0d\u5f97\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u4fee\u6539\uff0c\u4ea6\u4e0d\u5f97\u4f9d\u64da\u672c\u5275\u4f5c\u9032\u884c\u518d\u5275\u4f5c\uff0c\u4e0d\u5f97\u5c07\u672c\u5275\u4f5c\u904b\u7528\u65bc\u5546\u696d\u7528\u9014\u3002 CC BY-SA\uff08\u7f72\u540d+ \u7e7c\u627f\uff09\uff1a\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\uff0c\u53ef\u4ee5\u5c07\u5176\u904b\u7528\u65bc\u5546\u696d\u7528\u9014\uff0c\u552f\u9808\u7f72\u540d\u4f5c\u8005\uff0c\u4e26\u4e14\u63a1\u7528\u672c\u5275\u4f5c\u7684\u5167\u5bb9\u5fc5\u9808\u540c\u6a23\u63a1\u7528\u672c\u5354\u8b70\u9032\u884c\u6388\u6b0a\u3002 CC BY-NC-SA\uff08\u7f72\u540d+ \u975e\u76c8\u5229+ \u7e7c\u627f\uff09\uff1a\u4f7f\u7528\u8005\u53ef\u4ee5\u5c0d\u672c\u5275\u4f5c\u9032\u884c\u8f49\u8f09\u3001\u7bc0\u9078\u3001\u6df7\u7de8\u3001\u4e8c\u6b21\u5275\u4f5c\uff0c\u4f46\u4e0d\u5f97\u904b\u7528\u65bc\u5546\u696d\u76ee\u7684\uff0c\u4e14\u4f7f\u7528\u6642\u9808\u9032\u884c\u7f72\u540d\uff0c\u63a1\u7528\u672c\u5275\u4f5c\u7684\u5167\u5bb9\u5fc5\u9808\u540c\u6a23\u63a1\u7528\u672c\u5354\u8b70\u9032\u884c\u6388\u6b0a\u3002","title":"CC 4.0 \u8457\u4f5c\u6b0a\u61f6\u4eba\u5305"},{"location":"Today-I-Learned/2020/#2020-08-05","text":"","title":"2020-08-05"},{"location":"Today-I-Learned/2020/#no-more-google-google-alternatives","text":"https://nomoregoogle.com/ Privacy-friendly alternatives to Google that don't track you","title":"No more google - Google alternatives"},{"location":"Today-I-Learned/2020/#2020-08-03","text":"","title":"2020-08-03"},{"location":"Today-I-Learned/2020/#service-mesh","text":"https://www.youtube.com/watch?v=-KWvlW9CSn8 Istio Linkerd Kuma Mosn","title":"Service mesh"},{"location":"Today-I-Learned/2020/#2020-07-30","text":"","title":"2020-07-30"},{"location":"Today-I-Learned/2020/#grouped-bar-chart-online","text":"https://codepen.io/pen/?&editable=true=https%3A%2F%2Fwww.highcharts.com%2Fsamples%2Fhighcharts%2Fdemo%2Fcolumn-basic%3Fcodepen https://www.highcharts.com/demo","title":"\u88fd\u4f5c grouped bar chart online"},{"location":"Today-I-Learned/2020/#2020-07-24","text":"","title":"2020-07-24"},{"location":"Today-I-Learned/2020/#ab-load-testing-in-alpine-linux","text":"apk add apache2-utils ab -n1000 -c10 -k http://localhost/","title":"AB load testing in Alpine Linux"},{"location":"Today-I-Learned/2020/#to-generate-ecdsa-p-256-certificate-with-step-cli","text":"step-cli: https://smallstep.com/cli/ brew install step ref: https://linkerd.io/2/tasks/generate-certificates/#trust-anchor-certificate step certificate create identity.linkerd.cluster.local ca.crt ca.key \\ --profile root-ca --no-password --insecure","title":"To generate ECDSA P-256 certificate with step-cli"},{"location":"Today-I-Learned/2020/#import-ssl-cert-to-kubernetes-secret","text":"cat 34_120_61_244.crt IntermediateCA.crt > ip.crt kubectl create secret tls web-ip1 \\ --cert 34_120_61_244.crt \\ --key 34_120_61_244.key \\ -n web update cert kubectl create secret tls web-ip1 \\ --cert 34_120_61_244.crt \\ --key 34_120_61_244.key \\ -n web --dry-run -o yaml \\ | kubectl apply -f -","title":"Import ssl cert to kubernetes secret"},{"location":"Today-I-Learned/2020/#2020-07-22","text":"","title":"2020-07-22"},{"location":"Today-I-Learned/2020/#nginx-access-control-allow-origin","text":"Good more_set_headers \"Access-Control-Allow-Origin: $http_origin\"; Bad more_set_headers \"Access-Control-Allow-Origin: *\";","title":"Nginx - Access-Control-Allow-Origin: *"},{"location":"Today-I-Learned/2020/#2020-07-14","text":"","title":"2020-07-14"},{"location":"Today-I-Learned/2020/#is-possible-to-use-ip-address-in-managedcertificate-in-gke","text":"No. Error The ManagedCertificate \"my-ip1\" is invalid: spec.domains: Invalid value: \"\": spec.domains in body should match '^(([a-zA-Z0-9]+|[a-zA-Z0-9][-a-zA-Z0-9]*[a-zA-Z0-9])\\.)+[a-zA-Z][-a-zA-Z0-9]*[a-zA-Z0-9]\\.?$' apiVersion : networking.gke.io/v1beta2 kind : ManagedCertificate metadata : name : my-ip1 spec : domains : - \"34.120.100.100\"","title":"Is possible to use ip address in ManagedCertificate in GKE?"},{"location":"Today-I-Learned/2020/#2020-07-06","text":"","title":"2020-07-06"},{"location":"Today-I-Learned/2020/#nginx-as-an-forward-proxy-server","text":"https://www.alibabacloud.com/blog/how-to-use-nginx-as-an-https-forward-proxy-server_595799 server { listen 443; # dns resolver used by forward proxying resolver 114.114.114.114; # forward proxy for CONNECT request proxy_connect; proxy_connect_allow 443; proxy_connect_connect_timeout 10s; proxy_connect_read_timeout 10s; proxy_connect_send_timeout 10s; # forward proxy for non-CONNECT request location / { proxy_pass http://$host; proxy_set_header Host $host; } } curl https://www.baidu.com -svo /dev/null -x 39 .105.196.164:443","title":"Nginx - as an forward proxy server"},{"location":"Today-I-Learned/2020/#2020-06-30","text":"","title":"2020-06-30"},{"location":"Today-I-Learned/2020/#github-api-delete-branch-with-personal-access-token","text":"export INPUT_AUTH_TOKEN = export GITHUB_REPOSITORY = export GITHUB_HEAD_REF = http DELETE \"https://api.github.com/repos/ $GITHUB_REPOSITORY /git/refs/heads/ $GITHUB_HEAD_REF \" \\ \"Authorization: token $INPUT_AUTH_TOKEN \"","title":"Github API - Delete branch with Personal Access Token"},{"location":"Today-I-Learned/2020/#2020-06-24","text":"","title":"2020-06-24"},{"location":"Today-I-Learned/2020/#linux-get-geo-infomation-in-curl","text":"curl https://ipinfo.io/ { \"ip\" : \"59.124.114.73\" , \"hostname\" : \"59-124-114-73.hinet-ip.hinet.net\" , \"city\" : \"Taipei\" , \"region\" : \"Taiwan\" , \"country\" : \"TW\" , \"loc\" : \"25.0478,121.5319\" , \"org\" : \"AS3462 Data Communication Business Group\" , \"timezone\" : \"Asia/Taipei\" , \"readme\" : \"https://ipinfo.io/missingauth\" } curl ifconfig.co/json { \"asn\" : \"AS3462\" , \"asn_org\" : \"Data Communication Business Group\" , \"city\" : \"Taipei\" , \"country\" : \"Taiwan\" , \"country_eu\" : false, \"country_iso\" : \"TW\" , \"hostname\" : \"59-124-114-73.HINET-IP.hinet.net\" , \"ip\" : \"59.124.114.73\" , \"ip_decimal\" : 998011465 , \"latitude\" : 25 .0478, \"longitude\" : 121 .5318, \"region_code\" : \"TPE\" , \"region_name\" : \"Taipei City\" , \"time_zone\" : \"Asia/Taipei\" , \"user_agent\" : { \"product\" : \"HTTPie\" , \"raw_value\" : \"HTTPie/1.0.2\" , \"version\" : \"1.0.2\" } } curl -s https://ipvigilante.com/ $( curl -s https://ipinfo.io/ip ) { \"status\" : \"success\" , \"data\" : { \"ipv4\" : \"59.124.114.73\" , \"continent_name\" : \"Asia\" , \"country_name\" : \"Taiwan\" , \"subdivision_1_name\" :null, \"subdivision_2_name\" :null, \"city_name\" :null, \"latitude\" : \"23.50000\" , \"longitude\" : \"121.00000\" }}","title":"Linux - Get Geo infomation in curl"},{"location":"Today-I-Learned/2020/#nginx-ingress-will-use-default-fake-certificate","text":"apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : namespace : staging name : demo annotations : kubernetes.io/ingress.class : \"nginx\" nginx.ingress.kubernetes.io/ssl-redirect : \"false\" # Default:true spec : tls : - secretName : staging-tls rules : - http : paths : - backend : serviceName : demo-web servicePort : http curl -kvL https://api.r-live.swaggg.dev * Server certificate: * subject: O = Acme Co ; CN = Kubernetes Ingress Controller Fake Certificate * start date: Jun 24 04 :25:00 2020 GMT * expire date: Jun 24 04 :25:00 2021 GMT * issuer: O = Acme Co ; CN = Kubernetes Ingress Controller Fake Certificate * SSL certificate verify result: unable to get local issuer certificate ( 20 ) , continuing anyway.","title":"Nginx Ingress will use default fake certificate"},{"location":"Today-I-Learned/2020/#2020-06-23","text":"","title":"2020-06-23"},{"location":"Today-I-Learned/2020/#intall-google-cloud-sdk-in-docker-image","text":"FROM docker:stable RUN \\ apk add curl bash python git && \\ curl https://sdk.cloud.google.com | bash -s -- --disable-prompts ENV PATH $PATH :/root/google-cloud-sdk/bin","title":"Intall Google Cloud SDK in docker image"},{"location":"Today-I-Learned/2020/#linux-get-external-ip-in-curl-cli","text":"ref: https://www.tecmint.com/find-linux-server-public-ip-address/ $ curl ifconfig.co $ curl ifconfig.me $ curl icanhazip.com $ curl https://ipinfo.io/ip","title":"Linux - Get external ip in curl cli"},{"location":"Today-I-Learned/2020/#kubernetes-gkegcp-proxy-to-internal-load-balancer","text":"https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing#global_access Internal load balancer apiVersion : v1 kind : Service metadata : namespace : default name : ilb-api annotations : cloud.google.com/load-balancer-type : \"Internal\" # This is beta. So it needs to follow this: https://stackoverflow.com/a/59658742/3854890 # gcloud beta compute forwarding-rules update xxxxx --region us-central1 --allow-global-access # networking.gke.io/internal-load-balancer-allow-global-access: \"true\" # This is for same VPC different region. spec : externalTrafficPolicy : Local type : LoadBalancer selector : role : api ports : - port : 80 targetPort : http protocol : TCP Proxy service to internal load balancer apiVersion : v1 kind : Service metadata : namespace : web name : api-proxy spec : ports : - protocol : TCP port : 80 targetPort : 80 --- kind : Endpoints apiVersion : v1 metadata : namespace : web name : api-proxy subsets : - addresses : - ip : 10.100.0.100 ports : - port : 80","title":"Kubernetes - GKE/GCP proxy to internal load balancer"},{"location":"Today-I-Learned/2020/#gke-internal-load-balancer-dont-need-extra-firewalls","text":"ref: https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balancing#global_access no need to add additional firewalls. Default can access same region+project Internal Load Balancer. Without global access, traffic originating from clients in your VPC network must be in the same region as the load balancer. Global access is enabled per-Service using the following annotation: networking.gke.io/internal-load-balancer-allow-global-access: \"true\". Global access is available in Beta on GKE clusters 1.16 and up.","title":"GKE - Internal Load Balancer don't need extra firewalls"},{"location":"Today-I-Learned/2020/#2020-06-18","text":"","title":"2020-06-18"},{"location":"Today-I-Learned/2020/#linux-adduser-without-prompts","text":"adduser runner --disabled-password --gecos \"\"","title":"Linux - adduser without prompts"},{"location":"Today-I-Learned/2020/#linux-add-sudoer-group-to-user","text":"echo \"runner ALL=(ALL) NOPASSWD: ALL\" >> /etc/sudoers && \\ usermod -aG sudo runner","title":"Linux - Add sudoer group to user"},{"location":"Today-I-Learned/2020/#github-action-runner-fix-gifsicle-command-failed","text":"Solution ref: https://github.com/imagemin/imagemin-gifsicle/issues/37#issuecomment-577889854 apt-get install -y --no-install-recommends autoconf automake libtool dh-autoreconf error /home/runner/_work/runner-demo/node_modules/gifsicle: Command failed. Exit code: 1 Command: node lib/install.js info Visit https://yarnpkg.com/en/docs/cli/install for documentation about this command. Arguments: Directory: /home/runner/_work/runner-demo/node_modules/gifsicle Output: \u26a0 Response code 404 (Not Found) \u26a0 gifsicle pre-build test failed \u2139 compiling from source \u2716 Error: Command failed: /bin/sh -c ./configure --disable-gifview --disable-gifdiff --prefix=\"/home/runner/_work/runner-demo/node_modules/gifsicle/vendor\" --bindir=\"/home/runner/_work/runner-demo/node_modules/gifsicle/vendor\" config.status: error: in `/tmp/ee647f58-0c5e-49d4-995d-bf84ec21ed4e': config.status: error: Something went wrong bootstrapping makefile fragments","title":"Github Action Runner - Fix gifsicle: Command failed"},{"location":"Today-I-Learned/2020/#2020-06-11","text":"","title":"2020-06-11"},{"location":"Today-I-Learned/2020/#failed-to-determine-a-valid-solver-configuration-for-the-set-of-domains-on-the-order-no-configured-challenge-solvers-can-be-used-for-this-challenge","text":"That's because Let's encrypt HTTP01 doesn't support wildcard(*) domains. So, we can't use *.rammus.cf in apiVersion : cert-manager.io/v1alpha2 kind : Issuer metadata : namespace : web name : rammus spec : acme : email : rammus@rammus.cf server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : rammus solvers : - http01: ingress : class : nginx --- apiVersion : cert-manager.io/v1alpha2 kind : Certificate metadata : namespace : web name : rammus spec : secretName : rammus-tls issuerRef : # The issuer created previously kind : Issuer name : rammus dnsNames : - 'rammus.cf' - '*.rammus.cf' - 'api.rammus.cf'","title":"Failed to determine a valid solver configuration for the set of domains on the Order: no configured challenge solvers can be used for this challenge"},{"location":"Today-I-Learned/2020/#2020-06-05","text":"","title":"2020-06-05"},{"location":"Today-I-Learned/2020/#gsutil-verify-a-google-service-account-with-docker-and-a-environment-variable","text":"docker run -it --rm --entrypoint bash gcr.io/cloud-builders/gsutil sa = '{key.json,....}' gcloud auth activate-service-account --key-file = < ( echo $sa ) gsutil ls gs://rammus.dev","title":"gsutil - Verify a google service account with docker and a environment variable"},{"location":"Today-I-Learned/2020/#2020-06-02","text":"","title":"2020-06-02"},{"location":"Today-I-Learned/2020/#kubernetes-get-client-ip-from-google-network-load-balancer","text":"https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer spec : externalTrafficPolicy : Local type : LoadBalancer kubernetes issue: https://github.com/kubernetes/kubernetes/issues/10921","title":"Kubernetes - Get client ip from Google Network Load Balancer"},{"location":"Today-I-Learned/2020/#direct-server-return-dsr","text":"https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236","title":"Direct server return (DSR)"},{"location":"Today-I-Learned/2020/#2020-05-26","text":"","title":"2020-05-26"},{"location":"Today-I-Learned/2020/#nginx-get-request-connection-id","text":"ref: - https://stackoverflow.com/questions/17748735/setting-a-trace-id-in-nginx-load-balancer - http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive server { listen 80 default_server deferred; set $trace_id $connection-$connection_requests; location / { proxy_set_header Host 'api.swag.live'; proxy_pass https://api$request_uri; proxy_cache_key api$request_uri; proxy_set_header X-Request-Id $trace_id; } }","title":"Nginx - get request connection id"},{"location":"Today-I-Learned/2020/#nginx-proxy_set_header-will-diable-persistent-connection","text":"proxy_set_header upstream swaglive { server swaglive.web; keepalive 16; keepalive_requests 100000; } proxy_http_version 1.1; proxy_set_header Connection \"\";","title":"Nginx - proxy_set_header will diable persistent connection"},{"location":"Today-I-Learned/2020/#html-expires-and-cache-control","text":"Cache-Control > Expires Expires: HTTP 1.0 Cache-Control: HTTP 1.1 ref: https://blog.techbridge.cc/2017/06/17/cache-introduction/","title":"HTML - Expires and Cache-Control"},{"location":"Today-I-Learned/2020/#2020-05-22","text":"","title":"2020-05-22"},{"location":"Today-I-Learned/2020/#nginx-use-http-header-as-variable","text":"$http_name ex: $http_referer $http_user_agent $http_x_forwarded_for","title":"Nginx - use http header as variable"},{"location":"Today-I-Learned/2020/#nginx-ssl_do_handshake-failed-ssl-error1408f10bssl-routinesssl3_get_recordwrong-version-number-while-ssl-handshaking-to-upstream","text":"proxy_ssl_session_reuse off;","title":"Nginx - SSL_do_handshake() failed (SSL: error:1408F10B:SSL routines:SSL3_GET_RECORD:wrong version number) while SSL handshaking to upstream"},{"location":"Today-I-Learned/2020/#nginx-server-listen-80-default-deferred","text":"server { listen 80 default deferred; ... } ref: https://stackoverflow.com/questions/8449058/what-does-the-deferred-option-mean-in-nginxs-listen-directive TCP_DEFER_ACCEPT can help boost performance by reducing the amount of preliminary formalities that happen between the server and client. \"deferred\" is Linux-only. For example on FreeBSD it won't work","title":"Nginx - server listen 80 default deferred"},{"location":"Today-I-Learned/2020/#nginx-print-cache-status-log","text":"log_format main '$remote_addr - $remote_user - $upstream_cache_status [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main;","title":"Nginx - Print cache status log"},{"location":"Today-I-Learned/2020/#2020-05-20","text":"","title":"2020-05-20"},{"location":"Today-I-Learned/2020/#nginx-proxy_pass-cache-prority","text":"proxy_cache_path inactive=10m Cache-Control: s-maxage Cache-Control: max-age proxy_cache_valid 200 2s; https://github.com/RammusXu/toolkit/tree/master/docker/two-layer-nginx","title":"Nginx - proxy_pass cache prority"},{"location":"Today-I-Learned/2020/#2020-05-13","text":"","title":"2020-05-13"},{"location":"Today-I-Learned/2020/#probot-update-file-and-create-pull-request","text":"https://github.com/octokit/rest.js/issues/845#issuecomment-386108187","title":"Probot - update file and create pull request"},{"location":"Today-I-Learned/2020/#2020-05-05","text":"","title":"2020-05-05"},{"location":"Today-I-Learned/2020/#got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socket-at-unixvarrundockersock-get-http2fvar2frun2fdockersockv140containersjson-dial-unix-varrundockersock-connect-permission-denied","text":"Solution sudo chmod 777 /var/run/docker.sock","title":"Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/json: dial unix /var/run/docker.sock: connect: permission denied"},{"location":"Today-I-Learned/2020/#install-docker-on-debian-linux","text":"apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common sudo apt-key fingerprint 0EBFCD88 sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian \\ $( lsb_release -cs ) \\ stable\" sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker run hello-world","title":"Install docker on Debian Linux"},{"location":"Today-I-Learned/2020/#ab-benchmark-is-using-1-core","text":"docker run --rm russmckendrick/ab ab -k -n 20000 -c 2000 https://rammus.cf/ Better to use multi-thread benchmark tool docker run --rm williamyeh/wrk -t10 -c500 -d30 --latency https://rammus.cf apk add wrk wrk -t10 -c500 -d30 --latency http://localhost:3000 Can monitor this behavior with: docker stats ab will never over 100%, also need to care about how much resource you give it to docker machine.","title":"ab benchmark is using 1 core"},{"location":"Today-I-Learned/2020/#2020-05-04","text":"","title":"2020-05-04"},{"location":"Today-I-Learned/2020/#pemission-denied-when-volumemounts-configmap-as-file","text":"https://github.com/kubernetes/kubernetes/issues/71356 subprocess.call(['./demo.sh']) File \"/usr/local/lib/python3.8/subprocess.py\", line 340, in call with Popen(*popenargs, **kwargs) as p: File \"/usr/local/lib/python3.8/subprocess.py\", line 854, in __init__ self._execute_child(args, executable, preexec_fn, close_fds, File \"/usr/local/lib/python3.8/subprocess.py\", line 1702, in _execute_child raise child_exception_type(errno_num, err_msg, err_filename) PermissionError: [Errno 13] Permission denied: './demo.sh' kind : ConfigMap metadata : name : tls-watch-config data : app.py : | import subprocess subprocess.call(['./update-cert.sh', filename, target_proxy]) update-cert.sh : | echo 'update' volumes : - name : workspace configMap : name : tls-watcher-config defaultMode : 0555 containers : - name : tls-watcher image : python:3.8-alpine3.11 volumeMounts : - name : workspace mountPath : /workspace workingDir : /workspace command : [ \"sh\" , \"-c\" ] args : - | python -u app.py","title":"Pemission denied when volumeMounts configmap as file"},{"location":"Today-I-Learned/2020/#2020-04-30","text":"","title":"2020-04-30"},{"location":"Today-I-Learned/2020/#generate-an-unique-sha-from-multiple-file-in-mac","text":"shasum *.json| shasum | cut -d' ' -f1","title":"Generate an unique sha from multiple file in Mac"},{"location":"Today-I-Learned/2020/#2020-04-24","text":"","title":"2020-04-24"},{"location":"Today-I-Learned/2020/#nginx-could-not-find-named-location","text":"2020/04/24 09:34:31 [error] 7#7: *58 could not find named location \"@gcsfiles\" while sending to client, client: 10.4.4.2, server: location ~* '^/(js|img|locale)/' { proxy_pass http://backend/$uri; proxy_cache_key rammus.cf$uri; add_header \"Cache-Control\" \"public, max-age=3600\"; add_header Strict-Transport-Security \"max-age=86400; includeSubDomains\" always; proxy_intercept_errors on; error_page 404 = @gcsfiles; } location = @gcsfiles { proxy_pass http://gcs/rammus.cf$uri; proxy_cache_key $http_host$uri; # Enabled HSTS add_header Strict-Transport-Security \"max-age=86400; includeSubDomains\" always; add_header \"Cache-Control\" \"public, max-age=2592300\"; } It should be location = @gcsfiles { location @gcsfiles { without =","title":"Nginx: could not find named location"},{"location":"Today-I-Learned/2020/#2020-04-17","text":"","title":"2020-04-17"},{"location":"Today-I-Learned/2020/#gke-ingress-with-managed-certificates","text":"apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : web namespace : default annotations : # gcloud compute addresses create gclb-web --global # gcloud compute addresses list networking.gke.io/static-ip : 1.1.1.1 # kubectl apply -f certificate.yaml # gcloud compute ssl-certificates list networking.gke.io/managed-certificates : rammus-cf spec : rules : - host : rammus.cf http : paths : - backend : serviceName : my-svc servicePort : http - http : paths : - backend : serviceName : my-svc servicePort : http apiVersion : networking.gke.io/v1beta1 kind : ManagedCertificate metadata : name : rammus-cf spec : domains : - \"rammus.cf\"","title":"GKE ingress with managed-certificates"},{"location":"Today-I-Learned/2020/#2020-04-07","text":"","title":"2020-04-07"},{"location":"Today-I-Learned/2020/#test-a-website-speed","text":"docker run --rm -v \"$(pwd)\":/sitespeed.io sitespeedio/sitespeed.io:12.3.1 https://app.swag.live","title":"Test a website speed"},{"location":"Today-I-Learned/2020/#2020-03-14","text":"","title":"2020-03-14"},{"location":"Today-I-Learned/2020/#find-other-lan-users-ip","text":"arp -a","title":"Find other LAN user's IP"},{"location":"Today-I-Learned/2020/#2020-03-13","text":"","title":"2020-03-13"},{"location":"Today-I-Learned/2020/#httpswww17cecom","text":"\u53ef\u4ee5\u6e2c\u8a66 CDN \u6548\u679c benchmark warm up","title":"\u4e2d\u570b\u7684\u6e2c\u901f\u7db2\u7ad9 https://www.17ce.com/"},{"location":"Today-I-Learned/2020/#2020-03-12","text":"","title":"2020-03-12"},{"location":"Today-I-Learned/2020/#dnsmasq-unsupported-option-check-that-dnsmasq-was-compiled-with-dhcptftpdnssecdbus-support","text":"Solution apk --no-cache add dnsmasq-dnssec \u9019\u500b\u932f\u8aa4\u767c\u751f\u5728: \u4f7f\u7528 alpine linux apk add dnsmasq Enable dnssec # /etc/dnsmasq.conf dnssec conf-file = /usr/share/dnsmasq/trust-anchors.conf dnssec-check-unsigned or # /etc/dnsmasq.conf dnssec trust-anchor=.,19036,8,2,49AAC11D7B6F6446702E54A1607371607A1A41855200FD2CE1CDDE32F24E8FB5 trust-anchor=.,20326,8,2,E06D44B80B8F1D39A95C0B0D7C65D08458E880409BBC683457104237C7F8EC8D dnssec-check-unsigned Success nsmasq_1 | dnsmasq: started, version 2 .80 cachesize 150 dnsmasq_1 | dnsmasq: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN DHCP DHCPv6 no-Lua TFTP no-conntrack ipset auth DNSSEC loop-detect inotify dumpfile dnsmasq_1 | dnsmasq: DNSSEC validation enabled dnsmasq_1 | dnsmasq: configured with trust anchor for <root> keytag 20326 dnsmasq_1 | dnsmasq: configured with trust anchor for <root> keytag 19036","title":"dnsmasq: unsupported option (check that dnsmasq was compiled with DHCP/TFTP/DNSSEC/DBus support)"},{"location":"Today-I-Learned/2020/#parsing-dnssec-anchors-in-shell-scriptbash","text":"ref: https://stackoverflow.com/questions/19908777/curl-and-xmllint-pipe https://data.iana.org/root-anchors/root-anchors.xml curl -s https://data.iana.org/root-anchors/root-anchors.xml | \\ xmllint --format --xpath 'concat(\"trust-anchor=.,\", /TrustAnchor/KeyDigest[1]/KeyTag, \",\", /TrustAnchor/KeyDigest[1]/Algorithm, \",\",/TrustAnchor/KeyDigest[1]//DigestType, \",\", /TrustAnchor/KeyDigest[1]/Digest)' - curl -s https://data.iana.org/root-anchors/root-anchors.xml | \\ xmllint --format --xpath 'concat(\"trust-anchor=.,\", /TrustAnchor/KeyDigest[2]/KeyTag, \",\", /TrustAnchor/KeyDigest[2]/Algorithm, \",\",/TrustAnchor/KeyDigest[2]//DigestType, \",\", /TrustAnchor/KeyDigest[2]/Digest)' -","title":"Parsing dnssec anchors in shell script(bash)"},{"location":"Today-I-Learned/2020/#commands-of-testing-domain","text":"apk add bind-tools nslookup swag.live localhost nslookup swag.live 127 .0.0.1 dig @localhost swag.live dig @127.0.0.1 swag.live dig @8.8.8.8 swag.live dig +trace swag.live dig +short swag.live ns dig @dnsmasq +dnssec swag.live dig @dnsmasq +dnssec google.com","title":"Commands of testing domain"},{"location":"Today-I-Learned/2020/#2020-03-11","text":"","title":"2020-03-11"},{"location":"Today-I-Learned/2020/#check-multiple-variables-are-not-none-in-python","text":"ref: https://stackoverflow.com/questions/42360956/what-is-the-most-pythonic-way-to-check-if-multiple-variables-are-not-none params = os . getenv ( 'PARAMS' ) sid = os . getenv ( 'SID' ) skey = os . getenv ( 'SKEY' ) if None in ( params , sid , skey ): print ( \"Must have SID, SKEY, PARAMS\" ) exit ( 1 )","title":"Check multiple variables are not None in Python"},{"location":"Today-I-Learned/2020/#2020-03-10","text":"","title":"2020-03-10"},{"location":"Today-I-Learned/2020/#gcs-roles","text":"Storage Object Admin resourcemanager.projects.get resourcemanager.projects.list storage.objects.create storage.objects.delete storage.objects.get storage.objects.getIamPolicy storage.objects.list storage.objects.setIamPolicy storage.objects.update Storage Object Creator resourcemanager.projects.get resourcemanager.projects.list storage.objects.create Storage Object Viewer resourcemanager.projects.get resourcemanager.projects.list storage.objects.get storage.objects.list","title":"GCS roles"},{"location":"Today-I-Learned/2020/#2020-03-09","text":"","title":"2020-03-09"},{"location":"Today-I-Learned/2020/#get-nth-line-of-stdout-on-linux","text":"ref: https://stackoverflow.com/questions/1429556/command-to-get-nth-line-of-stdout ls -l | sed -n 2p ls -l | head -2 | tail -1","title":"Get nth line of stdout on linux"},{"location":"Today-I-Learned/2020/#sort-gcs-google-cloud-storage-objects-by-date","text":"ref: https://stackoverflow.com/a/51709554/3854890 gsutil ls -l gs:// [ bucket-name ] / | sort -r -k 2 Example: ~ gsutil ls -l gs://rammus.cf/download | sort -r -k 2 62786148 2020 -03-06T05:52:53Z gs://rammus.cf/download/3.0.2.8087.086886.apk 62732280 2020 -03-04T03:07:33Z gs://rammus.cf/download/3.0.1-8070.apk 62729059 2020 -03-02T16:25:22Z gs://rammus.cf/download/3_0_1_8ca354.apk 11 2020 -03-02T16:25:03Z gs://rammus.cf/download/","title":"Sort GCS (google cloud storage) objects by date"},{"location":"Today-I-Learned/2020/#measuring-kubernetes-dns","text":"bash-5.0# time ( for i in { 1 ..100 } ; do host -U echoserver.ops > /dev/null ; done ) real 0m1.150s user 0m0.445s sys 0m0.278s bash-5.0# time ( for i in { 1 ..100 } ; do host -U echoserver.ops.svc.cluster.local > /dev/null ; done ) real 0m1.762s user 0m0.463s sys 0m0.362s bash-5.0# host -v echoserver.ops Trying \"echoserver.ops.ops.svc.cluster.local\" Trying \"echoserver.ops.svc.cluster.local\" bash-5.0# host -v echoserver.ops.svc.cluster.local Trying \"echoserver.ops.svc.cluster.local.ops.svc.cluster.local\" Trying \"echoserver.ops.svc.cluster.local.svc.cluster.local\" Trying \"echoserver.ops.svc.cluster.local.cluster.local\" Trying \"echoserver.ops.svc.cluster.local.google.internal\" Trying \"echoserver.ops.svc.cluster.local\" bash-5.0# cat /etc/resolv.conf nameserver 10 .24.0.10 search ops.svc.cluster.local svc.cluster.local cluster.local google.internal options ndots:5","title":"Measuring kubernetes dns"},{"location":"Today-I-Learned/2020/#2020-03-06","text":"","title":"2020-03-06"},{"location":"Today-I-Learned/2020/#how-does-udp-request-receiving-responses","text":"SOCK_STREAM: TCP SOCK_DGRAM: UDP https://stackoverflow.com/questions/1815030/receiving-a-response-through-udp Client emits UDP packet. Router passes UDP packet to the Internet. Router remembers that client sent a UDP packet to server, and establishes a mapping in its memory. Server sends a UDP packet, probably on the same port. Router receives packet, and checks mapping to find client talked to server recently. Router passes packet to client. https://ns1.com/resources/dns-protocol DNS communication occurs via two types of messages: queries and replies. Both DNS query format and reply format consist of the following sections: The header section contains Identification; Flags; Number of questions; Number of answers; Number of authority resource records (RRs); and Number of additional resource records. The flag field contains sections of one or four bits, indicating type of message, whether the name server is authoritative; whether the query is recursive or not, whether request was truncated, and status. The question section contains the domain name and type of record (A, AAAA, MX, TXT, etc.) being resolved. Each label in the domain name is prefixed by its length. The answer section has the resource records of the queried name. http://www-inf.int-evry.fr/~hennequi/CoursDNS/NOTES-COURS_eng/msg.html","title":"How does UDP request receiving responses."},{"location":"Today-I-Learned/2020/#weave-scope-kubernetes","text":"ref: https://www.weave.works/docs/scope/latest/installing/#kubernetes \u5b89\u88dd Weave Scope kubectl apply -f \"https://cloud.weave.works/k8s/scope.yaml?k8s-version= $( kubectl version | base64 | tr -d '\\n' ) \" Expose \u670d\u52d9\u5230 localhost kubectl port-forward -n weave service/weave-scope-app 4040:80 open -a \"Google Chrome\" \"http://localhost:4040\"","title":"Weave Scope - \u76e3\u63a7 kubernetes \u7684\u5de5\u5177"},{"location":"Today-I-Learned/2020/#2020-03-05","text":"","title":"2020-03-05"},{"location":"Today-I-Learned/2020/#try-to-resolve-a-domain-in-kubernetes","text":"Default /etc/resolv.conf is like: nameserver 10.24.0.10 search default.svc.cluster.local svc.cluster.local cluster.local google.internal options ndots:5 \u5c11\u65bc 5 \u500b dot (.) \u5c07\u6703\u5148\u641c\u5c0b search default.svc.cluster.local svc.cluster.local cluster.local google.internal > host -v a.a.a.www.google.com Trying \"a.a.a.www.google.com\" > host -v a.a.www.google.com Trying \"a.a.www.google.com.ops.svc.cluster.local\" Trying \"a.a.www.google.com.svc.cluster.local\" Trying \"a.a.www.google.com.cluster.local\" Trying \"a.a.www.google.com.google.internal\" Trying \"a.a.www.google.com\" > host -v www.google.com Trying \"www.google.com.ops.svc.cluster.local\" Trying \"www.google.com.svc.cluster.local\" Trying \"www.google.com.cluster.local\" Trying \"www.google.com.google.internal\" Trying \"www.google.com\"","title":"Try to resolve a domain in kubernetes"},{"location":"Today-I-Learned/2020/#2020-03-04","text":"","title":"2020-03-04"},{"location":"Today-I-Learned/2020/#how-to-perform-ddos-test-as-a-pentester","text":"https://pentest.blog/how-to-perform-ddos-test-as-a-pentester/","title":"how-to-perform-ddos-test-as-a-pentester"},{"location":"Today-I-Learned/2020/#install-netstress-on-kali-linux","text":"apt-get update apt-get install netstress","title":"Install netstress on kali linux"},{"location":"Today-I-Learned/2020/#run-kali-linux-on-kubernetes","text":"apiVersion : v1 kind : Pod metadata : name : kali labels : app : kali spec : ## Select node pool in GKE # affinity: # nodeAffinity: # requiredDuringSchedulingIgnoredDuringExecution: # nodeSelectorTerms: # - matchExpressions: # - key: cloud.google.com/gke-nodepool # operator: In # values: # - \"pool-1\" containers : - image : kalilinux/kali command : [ \"/bin/sh\" , \"-c\" ] args : - | tail -f /dev/null imagePullPolicy : IfNotPresent name : kali restartPolicy : Never","title":"Run kali linux on Kubernetes"},{"location":"Today-I-Learned/2020/#gke-nodelocal-dnscache","text":"https://cloud.google.com/kubernetes-engine/docs/how-to/nodelocal-dns-cache Base on CoreDNS","title":"GKE NodeLocal DNSCache"},{"location":"Today-I-Learned/2020/#install-dnsperf-on-alpine","text":"ref: - https://github.com/ssro/dnsperf/blob/master/Dockerfile - https://github.com/guessi/docker-dnsperf/blob/master/bench/k8s-dnsperf-bench.yaml DNSPERF = dnsperf-2.3.2 apk add --update --no-cache --virtual deps wget g++ make bind-dev openssl-dev libxml2-dev libcap-dev json-c-dev krb5-dev protobuf-c-dev fstrm-dev \\ && apk add --update --no-cache bind libcrypto1.1 \\ && wget https://www.dns-oarc.net/files/dnsperf/ $DNSPERF .tar.gz \\ && tar zxvf $DNSPERF .tar.gz \\ && cd $DNSPERF \\ && sh configure \\ && make \\ && strip ./src/dnsperf ./src/resperf \\ && make install echo \"kube-dns.kube-system.svc.cluster.local A\" > records.txt echo \"echoserver.ops.svc.cluster.local A\" > records.txt dnsperf -l 10 \\ -s 10 .140.0.53 \\ -T 20 \\ -c 20 \\ -q 10000 \\ -Q 10000 \\ -S 5 \\ -d records.txt dnsperf -l 10 \\ -T 20 \\ -c 20 \\ -q 10000 \\ -Q 10000 \\ -S 5 \\ -d records.txt -l run for at most this many seconds -s the server -T the number of threads to run -c the number of clients to act as to query (default: 127.0.0.1) -q the maximum number of queries outstanding (default: 100) -Q limit the number of queries per second -S print qps statistics every N seconds -d the input data file (default: stdin)","title":"Install dnsperf on alpine"},{"location":"Today-I-Learned/2020/#2020-03-03","text":"","title":"2020-03-03"},{"location":"Today-I-Learned/2020/#open-google-chrome-browser-in-mac-terminal","text":"open -a \"Google Chrome\" \"http://localhost:5601\"","title":"Open Google Chrome browser in Mac terminal"},{"location":"Today-I-Learned/2020/#2020-03-02","text":"","title":"2020-03-02"},{"location":"Today-I-Learned/2020/#create-a-temporary-pod-to-debug-and-kill-itself-after-an-hour","text":"apiVersion : v1 kind : Pod metadata : name : busybox1 labels : app : busybox1 spec : containers : # - image: busybox - image : alpine:3.11 command : - sleep - \"3600\" imagePullPolicy : IfNotPresent name : busybox restartPolicy : Never","title":"Create a temporary pod to debug and kill itself after an hour"},{"location":"Today-I-Learned/2020/#dns-load-testing-in-alpine","text":"apk add gcc g++ make libffi-dev openssl-dev git git clone https://github.com/jedisct1/dnsblast.git cd dnsblast && make #./dnsblast [host] [times] [request per second] ./dnsblast kube-dns.kube-system 10000 1000 ./dnsblast 127 .0.0.1 10000 1000 The command above will break kube-dns. There are 5 kube-dns pods, but only one is receiving request. Caused by iptable and UDP. dnsmasq I0302 08 :47:01.002440 1 nanny.go:146 [] dnsmasq [ 23 ] : Maximum number of concurrent DNS queries reached ( max: 1500 ) sidecar W0302 08 :47:01.248582 1 server.go:64 [] Error getting metrics from dnsmasq: read udp 127 .0.0.1:37986->127.0.0.1:53: i/o timeout","title":"DNS load testing in Alpine"},{"location":"Today-I-Learned/2020/#gke-v113x-uses-kube-dns-rather-than-core-dns","text":"ref: https://cloud.google.com/kubernetes-engine/docs/release-notes#new_features_6 GKE is using kube- rather than core-dns. No idea why they are doing this.","title":"GKE v1.13.x uses kube-dns rather than core-dns."},{"location":"Today-I-Learned/2020/#install-gcc-compiler-in-alpine","text":"ref: https://github.com/nange/blog/issues/3 apk add gcc g++ make libffi-dev openssl-dev","title":"Install gcc compiler in Alpine"},{"location":"Today-I-Learned/2020/#echo-n","text":"https://linux.die.net/man/1/echo -n do not output the trailing newline","title":"echo -n"},{"location":"Today-I-Learned/2020/#2020-02-27","text":"","title":"2020-02-27"},{"location":"Today-I-Learned/2020/#get-github-user-info","text":"https://developer.github.com/v3/#authentication curl -u \"username\" https://api.github.com/user curl -H \"Authorization: token $PAT \" https://api.github.com/user","title":"Get GitHub user info"},{"location":"Today-I-Learned/2020/#2020-02-26","text":"","title":"2020-02-26"},{"location":"Today-I-Learned/2020/#use-cloudflare-warp-as-vpn-on-macpc","text":"https://community.cloudflare.com/t/tutorial-how-to-use-cloudflare-warp-on-your-mac/129919?fbclid=IwAR3OlvJrv2EW3KoH3GlDA-gURM5BgPKiaP5RDjjlgBHyYpKWbryZzbrPDGw WARP (CloudFlare VPN) is made from Wireguard. Therefore we can generate a Wirrguard config from CloudFlare and use it on PC.","title":"Use CloudFlare WARP as VPN on Mac/PC"},{"location":"Today-I-Learned/2020/#refreshclean-cdn-cache-on-tencent-cloud","text":"https://console.cloud.tencent.com/cdn/refresh Just type what url you want to refresh.","title":"Refresh/Clean CDN cache on Tencent Cloud"},{"location":"Today-I-Learned/2020/#you-might-have-to-verify-by-doing-a-request-from-a-location-with-a-cloudflare-edge","text":"I tested it on https://tools.pingdom.com/ test in Tokyo CloudFlare/Google CDN both have edges GCS hosting need more DNS time: 40 ms","title":"You might have to verify by doing a request from a location with a Cloudflare edge"},{"location":"Today-I-Learned/2020/#2020-02-24","text":"","title":"2020-02-24"},{"location":"Today-I-Learned/2020/#cloudflare-worker-cant-resovlefind-domain","text":"Need to manully add this record to route worker. ref: https://community.cloudflare.com/t/a-record-name-for-worker/98841 Solution Add an A record to 192.0.2.1","title":"CloudFlare worker - Can't resovle/find domain"},{"location":"Today-I-Learned/2020/#cloudflare-worker-how-to-handle-spa","text":"I found there's 404 when I tried to refresh in other page like /faq. ref: https://stackoverflow.com/questions/58432345/cloudflare-workers-spa-with-vuejs options . mapRequestToAsset = req => { // First let's apply the default handler, which we imported from // '@cloudflare/kv-asset-handler' at the top of the file. We do // this because the default handler already has logic to detect // paths that should map to HTML files, for which it appends // `/index.html` to the path. req = mapRequestToAsset ( req ) // Now we can detect if the default handler decided to map to // index.html in some specific directory. if ( req . url . endsWith ( '/index.html' )) { // Indeed. Let's change it to instead map to the root `/index.html`. // This avoids the need to do a redundant lookup that we know will // fail. return new Request ( ` ${ new URL ( req . url ). origin } /index.html` , req ) } else { // The default handler decided this is not an HTML page. It's probably // an image, CSS, or JS file. Leave it as-is. return req } }","title":"CloudFlare worker - how to handle SPA"},{"location":"Today-I-Learned/2020/#2020-02-21","text":"","title":"2020-02-21"},{"location":"Today-I-Learned/2020/#multiple-static-ip-in-a-load-balancer","text":"Steps: Manual create ip addresses. Assign ip addresses to load balancer frontend Use externalIPs instead of loadBalancerIP kind : Service apiVersion : v1 metadata : name : dnsmasq spec : selector : name : dnsmasq type : LoadBalancer externalIPs : - a.a.a.a - a.a.a.b ports : - name : dnsmasq-udp port : 53 protocol : UDP targetPort : dnsmasq-udp # loadBalancerIP: a.a.a.a","title":"Multiple static IP in a load balancer"},{"location":"Today-I-Learned/2020/#testing-hpa-high-memory","text":"ref: https://github.com/feiskyer/kubernetes-handbook/blob/master/examples/hpa-memory.yaml apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler metadata : name : nginx-hpa spec : scaleTargetRef : apiVersion : extensions/v1beta1 kind : Deployment name : dnsmasq minReplicas : 1 maxReplicas : 5 metrics : - type : Resource resource : name : memory targetAverageUtilization : 60 and get in a container $ kubectl exec -it dnsmasq-5964d6fdc-2ktt8 sh generate high memory usage $ yes | tr \\\\ n x | head -c 100m | grep n","title":"Testing HPA high memory"},{"location":"Today-I-Learned/2020/#about-kubernetes-hpahorizontal-pod-autoscaler","text":"ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )] \u6bcf 15 \u79d2\u6aa2\u67e5\u4e00\u6b21 \u9810\u8a2d downscale: 5m","title":"About Kubernetes HPA(Horizontal Pod Autoscaler)"},{"location":"Today-I-Learned/2020/#2020-02-19","text":"","title":"2020-02-19"},{"location":"Today-I-Learned/2020/#use-environment-from-parent-process-in-nginxopenresty","text":"\u5728 nginx \u8b80\u53d6\u74b0\u5883\u8b8a\u6578\u7684\u6b63\u78ba\u65b9\u6cd5: \u5148\u5728 root block export \u8b8a\u6578 \u4f7f\u7528 lua os.getenv(\"MY_ENV\")) env MY_ENV; env PATH; http { server { location / { content_by_lua_block { ngx.say(os.getenv(\"MY_ENV\")); ngx.say(os.getenv(\"PATH\")); } } } }","title":"Use environment from parent process in Nginx(OpenResty)"},{"location":"Today-I-Learned/2020/#cannot-create-an-external-load-balancer-with-mix-protocols","text":"The Service \"dnsmasq\" is invalid: spec.ports: Invalid value: [] core.ServicePort { core.ServicePort { Name: \"dnsmasq\" , Protocol: \"TCP\" , Port:53, TargetPort:intstr.IntOrString { Type:1, IntVal:0, StrVal: \"dnsmasq\" } , NodePort:0 } , core.ServicePort { Name: \"dnsmasq-udp\" , Protocol: \"UDP\" , Port:53, TargetPort:intstr.IntOrString { Type:1, IntVal:0, StrVal: \"dnsmasq-udp\" } , NodePort:0 }} : cannot create an external load balancer with mix protocols","title":"cannot create an external load balancer with mix protocols"},{"location":"Today-I-Learned/2020/#2020-02-18","text":"","title":"2020-02-18"},{"location":"Today-I-Learned/2020/#try-docker-compose-health-check","text":"https://github.com/peter-evans/docker-compose-healthcheck healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U postgres\"] interval: 10s timeout: 5s retries: 5","title":"Try docker-compose health check"},{"location":"Today-I-Learned/2020/#docker-docker-credential-osxkeychain-ci-db","text":"https://github.com/docker/for-mac/issues/3805#issuecomment-518619953 Solution Open ~/.docker/config.json Set \"credsStore\":\"\"","title":"Docker \u66f4\u65b0\u5f8c\u8df3\u51fa docker-credential-osxkeychain \u60f3\u4f7f\u7528\u9470\u5319\u5708 ci-db"},{"location":"Today-I-Learned/2020/#how-to-use-cc-by-sa-license","text":"Plain text: https://creativecommons.org/licenses/by-sa/4.0/legalcode.txt Image: <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a> [![](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)","title":"How to use cc-by-sa license"},{"location":"Today-I-Learned/2020/#print-a-colorful-text-in-terminal","text":"ANSI - \u8f38\u51fa\u6587\u5b57\u8b8a\u8272 echo -e \"\\e[1;31mHello\\e[0m World\"","title":"Print a colorful text in terminal"},{"location":"Today-I-Learned/2020/#render-a-chart-inside-markdown-with-canvasjs","text":"window.onload = function () { var limit = 50000; var y = 100; var data = []; var dataSeries = { type: \"line\" }; var dataPoints = []; for (var i = 0; i < limit; i += 1) { y += Math.round(Math.random() * 10 - 5); dataPoints.push({ x: i, y: y }); } dataSeries.dataPoints = dataPoints; data.push(dataSeries); //Better to construct options first and then pass it as a parameter var options = { zoomEnabled: true, animationEnabled: true, title: { text: \"Try Zooming - Panning\" }, axisY: { includeZero: false, lineThickness: 1 }, data: data // random data }; var chart = new CanvasJS.Chart(\"chartContainer\", options); chart.render(); }","title":"Render a chart inside markdown with canvasjs"},{"location":"Today-I-Learned/2020/#2020-02-15","text":"","title":"2020-02-15"},{"location":"Today-I-Learned/2020/#restart-a-kubernetes-resource-without-down-time-and-using-same-configyaml","text":"Kubernetes >= 1.15 ref: https://github.com/kubernetes/kubernetes/issues/33664#issuecomment-497242094 Gracefully rolling restart deployment. kubectl rollout restart deployment/my-sites --namespace = default","title":"Restart a kubernetes resource without down time and using same config(yaml)"},{"location":"Today-I-Learned/2020/#run-commnad-withoutignoring-output","text":"https://askubuntu.com/questions/474556/hiding-output-of-a-command command > /dev/null 2 > & 1 command > & /dev/null Example: Still show errors when command failed. $ edho hi > /dev/null zsh: command not found: edho Don't show error even when command failed. $ edho hi > & /dev/null","title":"\bRun commnad without(ignoring) output"},{"location":"Today-I-Learned/2020/#2020-02-13","text":"","title":"2020-02-13"},{"location":"Today-I-Learned/2020/#docker-compose","text":"service name \u6703\u88ab\u7d81\u5230 DNS\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 service name \u7576\u4f5c host version : '3' services : redis : image : \"redis:alpine\" ports : - \"6379:6379\" celery : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis celery-2 : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis $ docker network ls NETWORK ID NAME DRIVER SCOPE 01681ec52fea celery_default bridge local $ docker exec -it celery_celery_1 bash user@dcd8cf4a9d04:~$ ping celery-2 PING celery-2 ( 192 .168.0.4 ) : 56 data bytes 64 bytes from 192 .168.0.4: icmp_seq = 0 ttl = 64 time = 0 .162 ms 64 bytes from 192 .168.0.4: icmp_seq = 1 ttl = 64 time = 0 .223 ms ^C--- celery-2 ping statistics --- 2 packets transmitted, 2 packets received, 0 % packet loss round-trip min/avg/max/stddev = 0 .162/0.193/0.223/0.031 ms user@dcd8cf4a9d04:~$ ping celery-3 ping: unknown host","title":"\u5728 docker-compose \u4e2d\u7684\u5bb9\u5668\u4e92\u76f8\u6e9d\u901a"},{"location":"Today-I-Learned/2020/#mkdocs-minify-html-got-error","text":"mkdocs.yaml plugins : - minify : minify_html : true Bug print \"htmlmin option \" + key + \" not recognized\" ^ SyntaxError: Missing parentheses in call to 'print' . Did you mean print ( \"htmlmin option \" + key + \" not recognized\" ) ? Solution ref: https://github.com/byrnereese/mkdocs-minify-plugin/issues/8 Upgrade mkdocs-minify-plugin>= 0.2.3","title":"mkdocs minify html got error"},{"location":"Today-I-Learned/2021/","text":"What I learned in 2021. 2021-05-06 \u00b6 Kubernetes - Upgrade cert-manager to v1.3.1 \u00b6 Check exited CRD resources. kubectl get Issuers,ClusterIssuers,Certificates,CertificateRequests,Orders,Challenges --all-namespaces Backup resources. kubectl get -o yaml \\ --all-namespaces \\ issuer,clusterissuer,certificates > cert-manager-backup.yaml Use Helm to deploy cert-manager:v1.3.1 helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.3.1 \\ --set installCRDs=true 2021-04-29 \u00b6 Redis - Cluster failover \u00b6 3 master down -> cluster shutdown, can't failover to replicas -> when 2 master back, still not back -> need all 3 master back and re-sync 1 master + 1 replica down -> cluster shutdown -> 1 master back, still not back 2 master down -> cluster shutdown -> 1 master back, still not back conclusion: If cluster turns down, need all nodes re-sync to get it back. over 1/2 master down at same time will cause cluster down 1 shard down will cause cluster down 2021-04-15 \u00b6 Mongo - sharding not enabled for db \u00b6 sh.enableSharding ( \"mydatabase\" ) Mongo - update on a sharded collection must either contain an exact match on _id or must target a single shard \u00b6 A {multi:false} update on a sharded collection must either contain an exact match on _id or must target a single shard but this update targeted _id (and have the collection default collation) or must target a single shard (and have the simple collation), but this update targeted 2 shards. Update request: { q: { nb: 0 }, u: { $set: { date: new Date(1618511355253), c32: 13, c64: 10818 } }, multi: false, upsert: false }, shard key pattern: { c32: 1.0, c64: 1.0 }, full error: {'index': 0, 'code': 72, 'codeName': 'InvalidOptions', 'errmsg': 'A {multi:false} update on a sharded collection must either contain an exact match on _id or must target a single shard but this update targeted _id (and have the collection default collation) or must target a single shard (and have the simple collation), but this update targeted 2 shards. Update request: { q: { nb: 0 }, u: { $set: { date: new Date(1618511355253), c32: 13, c64: 10818 } }, multi: false, upsert: false }, shard key pattern: { c32: 1.0, c64: 1.0 }'} New document must contains shard key fields. In this case is c32, c64 . 2021-04-14 \u00b6 Mongo - transaction \u00b6 GKE - NEG get 502 when rollingUpate \u00b6 credit: https://cloud.google.com/kubernetes-engine/docs/how-to/standalone-neg#traffic_does_not_reach_the_endpoints https://pracucci.com/graceful-shutdown-of-kubernetes-pods.html lifecycle: preStop: exec: # SIGTERM triggers a quick exit; gracefully terminate instead command: [\"nginx\", \"-s\", \"quit\"] 2021-04-13 \u00b6 gsutil - Download large file with crcmod on macOS \u00b6 pip3 install -U crcmod Before: # gsutil version -l gsutil version: 4 .55 checksum: adebf7d276641651e3345d12aca978c0 ( OK ) boto version: 2 .49.0 python version: 3 .9.4 ( default, Apr 5 2021 , 01 :47:16 ) [ Clang 11 .0.0 ( clang-1100.0.33.17 )] OS: Darwin 18 .7.0 multiprocessing available: True using cloud sdk: True pass cloud sdk credentials to gsutil: True config path ( s ) : /Users/rammus/.boto, /Users/rammus/.config/gcloud/legacy_credentials/rammus.xu@swag.live/.boto gsutil path: /usr/local/Caskroom/google-cloud-sdk/latest/google-cloud-sdk/bin/gsutil compiled crcmod: False installed via package manager: False editable install: False After: # gsutil version -l gsutil version: 4 .55 checksum: adebf7d276641651e3345d12aca978c0 ( OK ) boto version: 2 .49.0 python version: 3 .9.4 ( default, Apr 5 2021 , 01 :47:16 ) [ Clang 11 .0.0 ( clang-1100.0.33.17 )] OS: Darwin 18 .7.0 multiprocessing available: True using cloud sdk: True pass cloud sdk credentials to gsutil: True config path ( s ) : /Users/rammus/.boto, /Users/rammus/.config/gcloud/legacy_credentials/rammus.xu@swag.live/.boto gsutil path: /usr/local/Caskroom/google-cloud-sdk/latest/google-cloud-sdk/bin/gsutil compiled crcmod: True installed via package manager: False editable install: False 2021-03-29 \u00b6 Kubernetes - Install cert-manager v1.2.0 \u00b6 helm repo add jetstack https://charts.jetstack.io helm repo update helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --version v1.2.0 \\ --create-namespace \\ --set installCRDs = true 2021-03-25 \u00b6 docker - Can't resolve host on build time \u00b6 Resolving github.com (github.com)... failed: Name does not resolve. wget: unable to resolve host address 'github.com' Solution Upgrade docker desktop to > 3.1.0 This happens on my Macbook Pro ( docker desktop: 2.5.0.1 ). It's fixed after I upgrade to 3.2.2 . 2021-03-24 \u00b6 Linkerd vs Istio on 2019 \u00b6 https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781 Istio\u2019s Envoy proxy uses more than 50% more CPU than Linkerd\u2019s k8s: 1.12.7-gke.7 node: n1-standard-4 4-16 nodes linkerd: 2.3.0 (now: 2.10) istio: 1.0.6 (now: 1.9.0) 2021-03-18 \u00b6 \u70ba\u4ec0\u9ebc TCP \u8981 3-way handshake \u00b6 https://draveness.me/whys-the-design-tcp-three-way-handshake/ TCP \u662f\u96d9\u5411\u5c0d\u8a71 (bi-directional communication protocol) \u96d9\u65b9\u90fd\u9700\u8981 SYN, ACK Client ------SYN-----> Server Client <---ACK/SYN---- Server Client ------ACK-----> Server 2021-03-15 \u00b6 Docker - Run different platform architecture images on Apple M1 mini \u00b6 rammus.xu@mac-mini ~ % docker run -it --rm alpine uname -a Linux ffb2f47751c8 4 .19.121-linuxkit #1 SMP PREEMPT Thu Jan 21 15:45:22 UTC 2021 aarch64 Linux rammus.xu@mac-mini ~ % docker run -it --rm --platform amd64 alpine uname -a Unable to find image 'alpine:latest' locally latest: Pulling from library/alpine ba3557a56b15: Pull complete Digest: sha256:a75afd8b57e7f34e4dad8d65e2c7ba2e1975c795ce1ee22fa34f8cf46f96a3be Status: Downloaded newer image for alpine:latest docker: Error response from daemon: image with reference alpine was found but does not match the specified platform: wanted darwin/amd64, actual: linux/amd64. See 'docker run --help' . rammus.xu@mac-mini ~ % docker run -it --rm --platform linux/amd64 alpine uname -a Linux f313db1d82a1 4 .19.121-linuxkit #1 SMP PREEMPT Thu Jan 21 15:45:22 UTC 2021 x86_64 Linux rammus.xu@mac-mini ~ % docker run -it --rm --platform linux/i386 alpine uname -a Unable to find image 'alpine:latest' locally latest: Pulling from library/alpine 86205afa28f6: Pull complete Digest: sha256:a75afd8b57e7f34e4dad8d65e2c7ba2e1975c795ce1ee22fa34f8cf46f96a3be Status: Downloaded newer image for alpine:latest Linux 4aff8fb39ae9 4 .19.121-linuxkit #1 SMP PREEMPT Thu Jan 21 15:45:22 UTC 2021 i686 Linux 2021-03-09 \u00b6 Kubernetes - Increase metrics-server resources (cpu/memory) \u00b6 Metrics not available for pod Ref: https://github.com/kubernetes/autoscaler/tree/master/addon-resizer Environment: Kubernetes: v1.17.15-gke.800 It's 3-5 minutes downtime. > kubectl apply -f metrics-server-config.yaml apiVersion : v1 kind : ConfigMap metadata : labels : addonmanager.kubernetes.io/mode : EnsureExists kubernetes.io/cluster-service : \"true\" name : metrics-server-config namespace : kube-system data : NannyConfiguration : |- apiVersion: nannyconfig/v1alpha1 kind: NannyConfiguration baseCPU: 200m cpuPerNode: 2m baseMemory: 150Mi memoryPerNode: 4Mi > kubectl delete deployment -n kube-system metrics-server-v0.3.6 deployment.apps \"metrics-server-v0.3.6\" deleted 2021-02-23 \u00b6 2021 Client Side Real User Monitoring (RUM) \u00b6 Cloud Hosted: Aliyun ARMS - https://www.alibabacloud.com/help/doc-detail/58652.htm pricing: https://www.alibabacloud.com/tc/product/arms/pricing Datadog - https://www.datadoghq.com/product/real-user-monitoring/ Micro Focus - https://www.microfocus.com/en-us/products/end-user-monitoring/overview Self Hosted: Elastic - https://www.elastic.co/guide/en/apm/agent/rum-js/current/intro.html boomerang - https://github.com/akamai/boomerang server: 2018 https://github.com/springernature/boomcatch 2016 https://github.com/andreas-marschke/boomerang-express https://matomo.org/ demo: https://demo.matomo.cloud/index.php https://github.com/basicrum/backoffice 2021-02-05 \u00b6 Kubernetes - Use annotation and initContainer to donwload GCS files \u00b6 apiVersion : apps/v1 kind : Deployment metadata : name : test spec : selector : matchLabels : app : demo replicas : 1 template : metadata : labels : app : demo annotations : update : \"true\" spec : volumes : - name : assets emptyDir : {} initContainers : - name : download-assets image : gcr.io/google.com/cloudsdktool/cloud-sdk:315.0.0-alpine command : [ \"/bin/bash\" , \"-c\" ] env : - name : IF_UPDATE valueFrom : fieldRef : fieldPath : metadata.annotations['update'] args : - | [ \"$IF_UPDATE\" = \"false\" ] && exit 0 gsutil -m cp -r gs://rammus.tw/assets /assets volumeMounts : - name : assets mountPath : /assets containers : - name : nginx image : nginx ports : - containerPort : 80 volumeMounts : - name : assets mountPath : /assets 2021-01-26 \u00b6 Docker - Build a userspace Wireguard image \u00b6 ghcr.io/linuxserver/wireguard default to use Linux kernal library. If you want to use userspace library or your machine doesn't support Linux kernal library. FROM rust:1.40-slim-buster AS builder ARG BORINGTUN_VERSION = 0 .3.0 RUN cargo install boringtun --version ${ BORINGTUN_VERSION } ### FROM ghcr.io/linuxserver/wireguard:version-v1.0.20200827 COPY --from = builder /usr/local/cargo/bin/boringtun /usr/local/bin ENV WG_QUICK_USERSPACE_IMPLEMENTATION = boringtun \\ WG_SUDO = 1 2021-01-25 \u00b6 MongoDB - Get wiredTiger stats \u00b6 ref: https://docs.mongodb.com/manual/reference/command/serverStatus/#wiredtiger db.runCommand ( { serverStatus: 1 } ) .wiredTiger 2021-01-21 \u00b6 mkdocs-material lexers - code block supported programming languages \u00b6 mkdocs-material \u4f7f\u7528 pygments \u7576\u4f5c\u8a9e\u6cd5\u5206\u6790\u5668\uff0c\u4ee5\u4e0b\u662f\u80fd\u652f\u63f4\u7684\u7a0b\u5f0f\u8a9e\u8a00 as3, actionscript3 as, actionscript mxml bc gap mathematica, mma, nb mupad at, ambienttalk, ambienttalk/2 ampl apl adl cadl odin arrow c-objdump ca65 cpp-objdump, c++-objdumb, cxx-objdump d-objdump dasm16 gas, asm hsail, hsa llvm llvm-mir-body llvm-mir nasm objdump-nasm objdump tasm autoit ahk, autohotkey bare bbcbasic blitzbasic, b3d, bplus blitzmax, bmax cbmbas monkey qbasic, basic vbscript bst, bst-pybtex bib, bibtex boa abap cobolfree cobol gooddata-cl maql openedge, abl, progress c cpp, c++ arduino charmci clay cuda, cu ec mql, mq4, mq5, mql4, mql5 nesc pike swig vala, vapi capnp chapel, chpl clean apacheconf, aconf, apache augeas cfengine3, cf3 docker, dockerfile ini, cfg, dosini kconfig, menuconfig, linux-config, kernel-config lighty, lighttpd nginx pacmanconf pkgconfig properties, jproperties registry singularity squidconf, squid.conf, squid toml termcap terminfo terraform, tf pypylog, pypy vctreestatus cr, crystal csound-document, csound-csd csound, csound-orc csound-score, csound-sco css less sass scss croc d minid smali None jsonld, json-ld json, json-object yaml devicetree, dts dpatch diff, udiff wdiff boo aspx-cs csharp, c# fsharp, f# nemerle aspx-vb vb.net, vbnet alloy crmsh, pcmk flatline mscgen, msc pan protobuf, proto puppet rsl snowball thrift vgl zeek, bro dylan-console, dylan-repl dylan dylan-lid, lid ecl eiffel elm email, eml iex elixir, ex, exs erlang erl aheui befunge brainfuck, bf camkes, idl4 capdl redcode ezhil factor fan felix, flx floscript, flo forth fortranfixed fortran foxpro, vfp, clipper, xbase freefem gdscript, gd go abnf bnf jsgf peg cypher asy, asymptote glsl gnuplot hlsl postscript, postscr pov agda cryptol, cry haskell, hs hspec idris, idr koka lagda, literate-agda lcry, literate-cryptol, lcryptol lhs, literate-haskell, lhaskell lidr, literate-idris, lidris hx, haxe, hxsl haxeml, hxml systemverilog, sv verilog, v vhdl hexdump dtd haml html pug, jade scaml xml xslt idl igor, igorpro limbo control, debcontrol nsis, nsi, nsh spec sourceslist, sources.list, debsources inform6, i6 i6t inform7, i7 tads3 io j coffee-script, coffeescript, coffee dart earl-grey, earlgrey, eg js, javascript juttle kal lasso, lassoscript live-script, livescript mask objective-j, objectivej, obj-j, objj ts, typescript jlcon julia, jl aspectj ceylon clojure, clj clojurescript, cljs golo gosu gst groovy ioke, ik jasmin, jasminxt java kotlin pig sarl scala xtend cpsa common-lisp, cl, lisp emacs, elisp, emacs-lisp fennel, fnl hylang newlisp racket, rkt scheme, scm shen extempore basemake cmake make, makefile, mf, bsdmake bbcode groff, nroff, man md, markdown trac-wiki, moin css+mozpreproc mozhashpreproc javascript+mozpreproc mozpercentpreproc xul+mozpreproc rst, rest, restructuredtext tex, latex tid matlab matlabsession octave scilab mime fstar ocaml opa reason, reasonml sml bugs, winbugs, openbugs jags modelica stan modula2, m2 monte mosel ncl nim, nimrod nit nixos, nix componentpascal, cp logos objective-c, objectivec, obj-c, objc objective-c++, objectivec++, obj-c++, objc++ swift ooc parasail antlr-as, antlr-actionscript antlr-csharp, antlr-c# antlr-cpp antlr-java antlr antlr-objc antlr-perl antlr-python antlr-ruby, antlr-rb ebnf ragel-c ragel-cpp ragel-d ragel-em ragel-java ragel ragel-objc ragel-ruby, ragel-rb treetop ada, ada95, ada2005 delphi, pas, pascal, objectpascal pawn sp perl6, pl6, raku perl, pl php, php3, php4, php5 psysh zephir pointless pony praat logtalk prolog promql cython, pyx, pyrex dg numpy python2, py2 py2tb pycon python, py, sage, python3, py3 pytb, py3tb qvto, qvt rconsole, rout rd splus, s, r shexc, shex sparql turtle rebol red, red/system resource, resourcebundle ride rnc, rng-compact roboconf-graph roboconf-instances robotframework fancy, fy rbcon, irb rb, ruby, duby rust, rs sas scdoc, scd applescript chai, chaiscript easytrieve hybris, hy jcl lsl lua moocode, moo ms, miniscript moon, moonscript rexx, arexx sgf bash, sh, ksh, zsh, shell console, shell-session bat, batch, dosbatch, winbatch execline fish, fishshell doscon powershell, posh, ps1, psm1 ps1con slurm, sbatch tcsh, csh tcshcon sieve slash newspeak smalltalk, squeak, st nusmv snobol solidity raw text mysql plpgsql psql, postgresql-console, postgres-console postgresql, postgres rql sql sqlite3 tsql, t-sql stata, do sc, supercollider tcl html+ng2 ng2 html+cheetah, html+spitfire, htmlcheetah js+cheetah, javascript+cheetah, js+spitfire, javascript+spitfire cheetah, spitfire xml+cheetah, xml+spitfire cfc cfm cfs css+django, css+jinja css+erb, css+ruby css+genshitext, css+genshi css+php css+smarty django, jinja erb html+evoque evoque xml+evoque genshi, kid, xml+genshi, xml+kid genshitext html+handlebars handlebars html+django, html+jinja, htmldjango html+genshi, html+kid html+php html+smarty js+django, javascript+django, js+jinja, javascript+jinja js+erb, javascript+erb, js+ruby, javascript+ruby js+genshitext, js+genshi, javascript+genshitext, javascript+genshi js+php, javascript+php js+smarty, javascript+smarty jsp css+lasso html+lasso js+lasso, javascript+lasso xml+lasso liquid css+mako html+mako js+mako, javascript+mako mako xml+mako mason css+myghty html+myghty js+myghty, javascript+myghty myghty xml+myghty rhtml, html+erb, html+ruby smarty ssp tea html+twig twig html+velocity velocity xml+velocity xml+django, xml+jinja xml+erb, xml+ruby xml+php xml+smarty yaml+jinja, salt, sls ttl, teraterm, teratermmacro cucumber, gherkin tap awk, gawk, mawk, nawk vim pot, po http irc kmsg, dmesg notmuch todotxt coq isabelle lean tnt rts, trafficscript typoscriptcssdata typoscripthtmldata typoscript icon ucode unicon urbiscript usd, usda vcl vclsnippets, vclsnippet boogie silver webidl cirru duel, jbst, jsonml+bst qml, qbs slim xquery, xqy, xq, xql, xqm whiley x10, xten xorg.conf yang zig 2021-01-19 \u00b6 ACK - failed to provision volume with StorageClass \"alicloud-disk-ssd\": rpc error: code = Internal desc = SDK.ServerError \u00b6 ErrorCode: InvalidDiskSize.NotSupported \u56e0\u70ba\u7533\u8acb\u592a\u5c0f\u7684\u5bb9\u91cf\uff0c\u6240\u4ee5\u51fa\u73fe\u9019\u500b\u932f\u8aa4\u3002 ref: https://help.aliyun.com/document_detail/127601.html \u9ad8\u6548\u4e91\u76d8\uff1a\u6700\u5c0f20 GiB\u3002 SSD\u4e91\u76d8\uff1a\u6700\u5c0f20 GiB\u3002 ESSD\u4e91\u76d8\uff1a\u6700\u5c0f20 GiB\u3002 Nginx - Use NFS to share proxy_cache \u00b6 proxy_cache_path / var /cache/nginx levels=1:2 keys_zone=storage:128m inactive=1y max_size=64G use_temp_path=off; Must to add use_temp_path=off which default to on . 2021-01-08 \u00b6 gsutil - Upload file to AWS S3 \u00b6 Least AWS user permission. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"VisualEditor0\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"s3:PutObject\" , \"s3:PutObjectAcl\" , \"s3:GetObject\" , \"s3:GetObjectAcl\" , \"s3:DeleteObject\" ], \"Resource\" : \"arn:aws:s3:::backup.rammus.tw/*\" }, { \"Sid\" : \"VisualEditor1\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"s3:ListBucket\" , \"s3:GetBucketLocation\" ], \"Resource\" : \"arn:aws:s3:::backup.rammus.tw\" } ] } Generate configuration export AWS_ACCESS_KEY_ID = export AWS_SECRET_ACCESS_KEY = cat << EOF > ~/.boto [Credentials] aws_access_key_id = $AWS_ACCESS_KEY_ID aws_secret_access_key = $AWS_SECRET_ACCESS_KEY [s3] calling_format = boto.s3.connection.OrdinaryCallingFormat use-sigv4=True host=s3.ap-northeast-1.amazonaws.com EOF Start to uplaod gsutil cp a s3://backup.rammus.tw","title":"2021"},{"location":"Today-I-Learned/2021/#2021-05-06","text":"","title":"2021-05-06"},{"location":"Today-I-Learned/2021/#kubernetes-upgrade-cert-manager-to-v131","text":"Check exited CRD resources. kubectl get Issuers,ClusterIssuers,Certificates,CertificateRequests,Orders,Challenges --all-namespaces Backup resources. kubectl get -o yaml \\ --all-namespaces \\ issuer,clusterissuer,certificates > cert-manager-backup.yaml Use Helm to deploy cert-manager:v1.3.1 helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.3.1 \\ --set installCRDs=true","title":"Kubernetes - Upgrade cert-manager to v1.3.1"},{"location":"Today-I-Learned/2021/#2021-04-29","text":"","title":"2021-04-29"},{"location":"Today-I-Learned/2021/#redis-cluster-failover","text":"3 master down -> cluster shutdown, can't failover to replicas -> when 2 master back, still not back -> need all 3 master back and re-sync 1 master + 1 replica down -> cluster shutdown -> 1 master back, still not back 2 master down -> cluster shutdown -> 1 master back, still not back conclusion: If cluster turns down, need all nodes re-sync to get it back. over 1/2 master down at same time will cause cluster down 1 shard down will cause cluster down","title":"Redis - Cluster failover"},{"location":"Today-I-Learned/2021/#2021-04-15","text":"","title":"2021-04-15"},{"location":"Today-I-Learned/2021/#mongo-sharding-not-enabled-for-db","text":"sh.enableSharding ( \"mydatabase\" )","title":"Mongo - sharding not enabled for db"},{"location":"Today-I-Learned/2021/#mongo-update-on-a-sharded-collection-must-either-contain-an-exact-match-on-_id-or-must-target-a-single-shard","text":"A {multi:false} update on a sharded collection must either contain an exact match on _id or must target a single shard but this update targeted _id (and have the collection default collation) or must target a single shard (and have the simple collation), but this update targeted 2 shards. Update request: { q: { nb: 0 }, u: { $set: { date: new Date(1618511355253), c32: 13, c64: 10818 } }, multi: false, upsert: false }, shard key pattern: { c32: 1.0, c64: 1.0 }, full error: {'index': 0, 'code': 72, 'codeName': 'InvalidOptions', 'errmsg': 'A {multi:false} update on a sharded collection must either contain an exact match on _id or must target a single shard but this update targeted _id (and have the collection default collation) or must target a single shard (and have the simple collation), but this update targeted 2 shards. Update request: { q: { nb: 0 }, u: { $set: { date: new Date(1618511355253), c32: 13, c64: 10818 } }, multi: false, upsert: false }, shard key pattern: { c32: 1.0, c64: 1.0 }'} New document must contains shard key fields. In this case is c32, c64 .","title":"Mongo - update on a sharded collection must either contain an exact match on _id or must target a single shard"},{"location":"Today-I-Learned/2021/#2021-04-14","text":"","title":"2021-04-14"},{"location":"Today-I-Learned/2021/#mongo-transaction","text":"","title":"Mongo - transaction"},{"location":"Today-I-Learned/2021/#gke-neg-get-502-when-rollingupate","text":"credit: https://cloud.google.com/kubernetes-engine/docs/how-to/standalone-neg#traffic_does_not_reach_the_endpoints https://pracucci.com/graceful-shutdown-of-kubernetes-pods.html lifecycle: preStop: exec: # SIGTERM triggers a quick exit; gracefully terminate instead command: [\"nginx\", \"-s\", \"quit\"]","title":"GKE - NEG get 502 when rollingUpate"},{"location":"Today-I-Learned/2021/#2021-04-13","text":"","title":"2021-04-13"},{"location":"Today-I-Learned/2021/#gsutil-download-large-file-with-crcmod-on-macos","text":"pip3 install -U crcmod Before: # gsutil version -l gsutil version: 4 .55 checksum: adebf7d276641651e3345d12aca978c0 ( OK ) boto version: 2 .49.0 python version: 3 .9.4 ( default, Apr 5 2021 , 01 :47:16 ) [ Clang 11 .0.0 ( clang-1100.0.33.17 )] OS: Darwin 18 .7.0 multiprocessing available: True using cloud sdk: True pass cloud sdk credentials to gsutil: True config path ( s ) : /Users/rammus/.boto, /Users/rammus/.config/gcloud/legacy_credentials/rammus.xu@swag.live/.boto gsutil path: /usr/local/Caskroom/google-cloud-sdk/latest/google-cloud-sdk/bin/gsutil compiled crcmod: False installed via package manager: False editable install: False After: # gsutil version -l gsutil version: 4 .55 checksum: adebf7d276641651e3345d12aca978c0 ( OK ) boto version: 2 .49.0 python version: 3 .9.4 ( default, Apr 5 2021 , 01 :47:16 ) [ Clang 11 .0.0 ( clang-1100.0.33.17 )] OS: Darwin 18 .7.0 multiprocessing available: True using cloud sdk: True pass cloud sdk credentials to gsutil: True config path ( s ) : /Users/rammus/.boto, /Users/rammus/.config/gcloud/legacy_credentials/rammus.xu@swag.live/.boto gsutil path: /usr/local/Caskroom/google-cloud-sdk/latest/google-cloud-sdk/bin/gsutil compiled crcmod: True installed via package manager: False editable install: False","title":"gsutil - Download large file with crcmod on macOS"},{"location":"Today-I-Learned/2021/#2021-03-29","text":"","title":"2021-03-29"},{"location":"Today-I-Learned/2021/#kubernetes-install-cert-manager-v120","text":"helm repo add jetstack https://charts.jetstack.io helm repo update helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --version v1.2.0 \\ --create-namespace \\ --set installCRDs = true","title":"Kubernetes - Install cert-manager v1.2.0"},{"location":"Today-I-Learned/2021/#2021-03-25","text":"","title":"2021-03-25"},{"location":"Today-I-Learned/2021/#docker-cant-resolve-host-on-build-time","text":"Resolving github.com (github.com)... failed: Name does not resolve. wget: unable to resolve host address 'github.com' Solution Upgrade docker desktop to > 3.1.0 This happens on my Macbook Pro ( docker desktop: 2.5.0.1 ). It's fixed after I upgrade to 3.2.2 .","title":"docker - Can't resolve host on build time"},{"location":"Today-I-Learned/2021/#2021-03-24","text":"","title":"2021-03-24"},{"location":"Today-I-Learned/2021/#linkerd-vs-istio-on-2019","text":"https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781 Istio\u2019s Envoy proxy uses more than 50% more CPU than Linkerd\u2019s k8s: 1.12.7-gke.7 node: n1-standard-4 4-16 nodes linkerd: 2.3.0 (now: 2.10) istio: 1.0.6 (now: 1.9.0)","title":"Linkerd vs Istio on 2019"},{"location":"Today-I-Learned/2021/#2021-03-18","text":"","title":"2021-03-18"},{"location":"Today-I-Learned/2021/#tcp-3-way-handshake","text":"https://draveness.me/whys-the-design-tcp-three-way-handshake/ TCP \u662f\u96d9\u5411\u5c0d\u8a71 (bi-directional communication protocol) \u96d9\u65b9\u90fd\u9700\u8981 SYN, ACK Client ------SYN-----> Server Client <---ACK/SYN---- Server Client ------ACK-----> Server","title":"\u70ba\u4ec0\u9ebc TCP \u8981 3-way handshake"},{"location":"Today-I-Learned/2021/#2021-03-15","text":"","title":"2021-03-15"},{"location":"Today-I-Learned/2021/#docker-run-different-platform-architecture-images-on-apple-m1-mini","text":"rammus.xu@mac-mini ~ % docker run -it --rm alpine uname -a Linux ffb2f47751c8 4 .19.121-linuxkit #1 SMP PREEMPT Thu Jan 21 15:45:22 UTC 2021 aarch64 Linux rammus.xu@mac-mini ~ % docker run -it --rm --platform amd64 alpine uname -a Unable to find image 'alpine:latest' locally latest: Pulling from library/alpine ba3557a56b15: Pull complete Digest: sha256:a75afd8b57e7f34e4dad8d65e2c7ba2e1975c795ce1ee22fa34f8cf46f96a3be Status: Downloaded newer image for alpine:latest docker: Error response from daemon: image with reference alpine was found but does not match the specified platform: wanted darwin/amd64, actual: linux/amd64. See 'docker run --help' . rammus.xu@mac-mini ~ % docker run -it --rm --platform linux/amd64 alpine uname -a Linux f313db1d82a1 4 .19.121-linuxkit #1 SMP PREEMPT Thu Jan 21 15:45:22 UTC 2021 x86_64 Linux rammus.xu@mac-mini ~ % docker run -it --rm --platform linux/i386 alpine uname -a Unable to find image 'alpine:latest' locally latest: Pulling from library/alpine 86205afa28f6: Pull complete Digest: sha256:a75afd8b57e7f34e4dad8d65e2c7ba2e1975c795ce1ee22fa34f8cf46f96a3be Status: Downloaded newer image for alpine:latest Linux 4aff8fb39ae9 4 .19.121-linuxkit #1 SMP PREEMPT Thu Jan 21 15:45:22 UTC 2021 i686 Linux","title":"Docker - Run different platform architecture images on Apple M1 mini"},{"location":"Today-I-Learned/2021/#2021-03-09","text":"","title":"2021-03-09"},{"location":"Today-I-Learned/2021/#kubernetes-increase-metrics-server-resources-cpumemory","text":"Metrics not available for pod Ref: https://github.com/kubernetes/autoscaler/tree/master/addon-resizer Environment: Kubernetes: v1.17.15-gke.800 It's 3-5 minutes downtime. > kubectl apply -f metrics-server-config.yaml apiVersion : v1 kind : ConfigMap metadata : labels : addonmanager.kubernetes.io/mode : EnsureExists kubernetes.io/cluster-service : \"true\" name : metrics-server-config namespace : kube-system data : NannyConfiguration : |- apiVersion: nannyconfig/v1alpha1 kind: NannyConfiguration baseCPU: 200m cpuPerNode: 2m baseMemory: 150Mi memoryPerNode: 4Mi > kubectl delete deployment -n kube-system metrics-server-v0.3.6 deployment.apps \"metrics-server-v0.3.6\" deleted","title":"Kubernetes - Increase metrics-server resources (cpu/memory)"},{"location":"Today-I-Learned/2021/#2021-02-23","text":"","title":"2021-02-23"},{"location":"Today-I-Learned/2021/#2021-client-side-real-user-monitoring-rum","text":"Cloud Hosted: Aliyun ARMS - https://www.alibabacloud.com/help/doc-detail/58652.htm pricing: https://www.alibabacloud.com/tc/product/arms/pricing Datadog - https://www.datadoghq.com/product/real-user-monitoring/ Micro Focus - https://www.microfocus.com/en-us/products/end-user-monitoring/overview Self Hosted: Elastic - https://www.elastic.co/guide/en/apm/agent/rum-js/current/intro.html boomerang - https://github.com/akamai/boomerang server: 2018 https://github.com/springernature/boomcatch 2016 https://github.com/andreas-marschke/boomerang-express https://matomo.org/ demo: https://demo.matomo.cloud/index.php https://github.com/basicrum/backoffice","title":"2021 Client Side Real User Monitoring (RUM)"},{"location":"Today-I-Learned/2021/#2021-02-05","text":"","title":"2021-02-05"},{"location":"Today-I-Learned/2021/#kubernetes-use-annotation-and-initcontainer-to-donwload-gcs-files","text":"apiVersion : apps/v1 kind : Deployment metadata : name : test spec : selector : matchLabels : app : demo replicas : 1 template : metadata : labels : app : demo annotations : update : \"true\" spec : volumes : - name : assets emptyDir : {} initContainers : - name : download-assets image : gcr.io/google.com/cloudsdktool/cloud-sdk:315.0.0-alpine command : [ \"/bin/bash\" , \"-c\" ] env : - name : IF_UPDATE valueFrom : fieldRef : fieldPath : metadata.annotations['update'] args : - | [ \"$IF_UPDATE\" = \"false\" ] && exit 0 gsutil -m cp -r gs://rammus.tw/assets /assets volumeMounts : - name : assets mountPath : /assets containers : - name : nginx image : nginx ports : - containerPort : 80 volumeMounts : - name : assets mountPath : /assets","title":"Kubernetes - Use annotation and initContainer to donwload GCS files"},{"location":"Today-I-Learned/2021/#2021-01-26","text":"","title":"2021-01-26"},{"location":"Today-I-Learned/2021/#docker-build-a-userspace-wireguard-image","text":"ghcr.io/linuxserver/wireguard default to use Linux kernal library. If you want to use userspace library or your machine doesn't support Linux kernal library. FROM rust:1.40-slim-buster AS builder ARG BORINGTUN_VERSION = 0 .3.0 RUN cargo install boringtun --version ${ BORINGTUN_VERSION } ### FROM ghcr.io/linuxserver/wireguard:version-v1.0.20200827 COPY --from = builder /usr/local/cargo/bin/boringtun /usr/local/bin ENV WG_QUICK_USERSPACE_IMPLEMENTATION = boringtun \\ WG_SUDO = 1","title":"Docker - Build a userspace Wireguard image"},{"location":"Today-I-Learned/2021/#2021-01-25","text":"","title":"2021-01-25"},{"location":"Today-I-Learned/2021/#mongodb-get-wiredtiger-stats","text":"ref: https://docs.mongodb.com/manual/reference/command/serverStatus/#wiredtiger db.runCommand ( { serverStatus: 1 } ) .wiredTiger","title":"MongoDB - Get wiredTiger stats"},{"location":"Today-I-Learned/2021/#2021-01-21","text":"","title":"2021-01-21"},{"location":"Today-I-Learned/2021/#mkdocs-material-lexers-code-block-supported-programming-languages","text":"mkdocs-material \u4f7f\u7528 pygments \u7576\u4f5c\u8a9e\u6cd5\u5206\u6790\u5668\uff0c\u4ee5\u4e0b\u662f\u80fd\u652f\u63f4\u7684\u7a0b\u5f0f\u8a9e\u8a00 as3, actionscript3 as, actionscript mxml bc gap mathematica, mma, nb mupad at, ambienttalk, ambienttalk/2 ampl apl adl cadl odin arrow c-objdump ca65 cpp-objdump, c++-objdumb, cxx-objdump d-objdump dasm16 gas, asm hsail, hsa llvm llvm-mir-body llvm-mir nasm objdump-nasm objdump tasm autoit ahk, autohotkey bare bbcbasic blitzbasic, b3d, bplus blitzmax, bmax cbmbas monkey qbasic, basic vbscript bst, bst-pybtex bib, bibtex boa abap cobolfree cobol gooddata-cl maql openedge, abl, progress c cpp, c++ arduino charmci clay cuda, cu ec mql, mq4, mq5, mql4, mql5 nesc pike swig vala, vapi capnp chapel, chpl clean apacheconf, aconf, apache augeas cfengine3, cf3 docker, dockerfile ini, cfg, dosini kconfig, menuconfig, linux-config, kernel-config lighty, lighttpd nginx pacmanconf pkgconfig properties, jproperties registry singularity squidconf, squid.conf, squid toml termcap terminfo terraform, tf pypylog, pypy vctreestatus cr, crystal csound-document, csound-csd csound, csound-orc csound-score, csound-sco css less sass scss croc d minid smali None jsonld, json-ld json, json-object yaml devicetree, dts dpatch diff, udiff wdiff boo aspx-cs csharp, c# fsharp, f# nemerle aspx-vb vb.net, vbnet alloy crmsh, pcmk flatline mscgen, msc pan protobuf, proto puppet rsl snowball thrift vgl zeek, bro dylan-console, dylan-repl dylan dylan-lid, lid ecl eiffel elm email, eml iex elixir, ex, exs erlang erl aheui befunge brainfuck, bf camkes, idl4 capdl redcode ezhil factor fan felix, flx floscript, flo forth fortranfixed fortran foxpro, vfp, clipper, xbase freefem gdscript, gd go abnf bnf jsgf peg cypher asy, asymptote glsl gnuplot hlsl postscript, postscr pov agda cryptol, cry haskell, hs hspec idris, idr koka lagda, literate-agda lcry, literate-cryptol, lcryptol lhs, literate-haskell, lhaskell lidr, literate-idris, lidris hx, haxe, hxsl haxeml, hxml systemverilog, sv verilog, v vhdl hexdump dtd haml html pug, jade scaml xml xslt idl igor, igorpro limbo control, debcontrol nsis, nsi, nsh spec sourceslist, sources.list, debsources inform6, i6 i6t inform7, i7 tads3 io j coffee-script, coffeescript, coffee dart earl-grey, earlgrey, eg js, javascript juttle kal lasso, lassoscript live-script, livescript mask objective-j, objectivej, obj-j, objj ts, typescript jlcon julia, jl aspectj ceylon clojure, clj clojurescript, cljs golo gosu gst groovy ioke, ik jasmin, jasminxt java kotlin pig sarl scala xtend cpsa common-lisp, cl, lisp emacs, elisp, emacs-lisp fennel, fnl hylang newlisp racket, rkt scheme, scm shen extempore basemake cmake make, makefile, mf, bsdmake bbcode groff, nroff, man md, markdown trac-wiki, moin css+mozpreproc mozhashpreproc javascript+mozpreproc mozpercentpreproc xul+mozpreproc rst, rest, restructuredtext tex, latex tid matlab matlabsession octave scilab mime fstar ocaml opa reason, reasonml sml bugs, winbugs, openbugs jags modelica stan modula2, m2 monte mosel ncl nim, nimrod nit nixos, nix componentpascal, cp logos objective-c, objectivec, obj-c, objc objective-c++, objectivec++, obj-c++, objc++ swift ooc parasail antlr-as, antlr-actionscript antlr-csharp, antlr-c# antlr-cpp antlr-java antlr antlr-objc antlr-perl antlr-python antlr-ruby, antlr-rb ebnf ragel-c ragel-cpp ragel-d ragel-em ragel-java ragel ragel-objc ragel-ruby, ragel-rb treetop ada, ada95, ada2005 delphi, pas, pascal, objectpascal pawn sp perl6, pl6, raku perl, pl php, php3, php4, php5 psysh zephir pointless pony praat logtalk prolog promql cython, pyx, pyrex dg numpy python2, py2 py2tb pycon python, py, sage, python3, py3 pytb, py3tb qvto, qvt rconsole, rout rd splus, s, r shexc, shex sparql turtle rebol red, red/system resource, resourcebundle ride rnc, rng-compact roboconf-graph roboconf-instances robotframework fancy, fy rbcon, irb rb, ruby, duby rust, rs sas scdoc, scd applescript chai, chaiscript easytrieve hybris, hy jcl lsl lua moocode, moo ms, miniscript moon, moonscript rexx, arexx sgf bash, sh, ksh, zsh, shell console, shell-session bat, batch, dosbatch, winbatch execline fish, fishshell doscon powershell, posh, ps1, psm1 ps1con slurm, sbatch tcsh, csh tcshcon sieve slash newspeak smalltalk, squeak, st nusmv snobol solidity raw text mysql plpgsql psql, postgresql-console, postgres-console postgresql, postgres rql sql sqlite3 tsql, t-sql stata, do sc, supercollider tcl html+ng2 ng2 html+cheetah, html+spitfire, htmlcheetah js+cheetah, javascript+cheetah, js+spitfire, javascript+spitfire cheetah, spitfire xml+cheetah, xml+spitfire cfc cfm cfs css+django, css+jinja css+erb, css+ruby css+genshitext, css+genshi css+php css+smarty django, jinja erb html+evoque evoque xml+evoque genshi, kid, xml+genshi, xml+kid genshitext html+handlebars handlebars html+django, html+jinja, htmldjango html+genshi, html+kid html+php html+smarty js+django, javascript+django, js+jinja, javascript+jinja js+erb, javascript+erb, js+ruby, javascript+ruby js+genshitext, js+genshi, javascript+genshitext, javascript+genshi js+php, javascript+php js+smarty, javascript+smarty jsp css+lasso html+lasso js+lasso, javascript+lasso xml+lasso liquid css+mako html+mako js+mako, javascript+mako mako xml+mako mason css+myghty html+myghty js+myghty, javascript+myghty myghty xml+myghty rhtml, html+erb, html+ruby smarty ssp tea html+twig twig html+velocity velocity xml+velocity xml+django, xml+jinja xml+erb, xml+ruby xml+php xml+smarty yaml+jinja, salt, sls ttl, teraterm, teratermmacro cucumber, gherkin tap awk, gawk, mawk, nawk vim pot, po http irc kmsg, dmesg notmuch todotxt coq isabelle lean tnt rts, trafficscript typoscriptcssdata typoscripthtmldata typoscript icon ucode unicon urbiscript usd, usda vcl vclsnippets, vclsnippet boogie silver webidl cirru duel, jbst, jsonml+bst qml, qbs slim xquery, xqy, xq, xql, xqm whiley x10, xten xorg.conf yang zig","title":"mkdocs-material lexers - code block supported programming languages"},{"location":"Today-I-Learned/2021/#2021-01-19","text":"","title":"2021-01-19"},{"location":"Today-I-Learned/2021/#ack-failed-to-provision-volume-with-storageclass-alicloud-disk-ssd-rpc-error-code-internal-desc-sdkservererror","text":"ErrorCode: InvalidDiskSize.NotSupported \u56e0\u70ba\u7533\u8acb\u592a\u5c0f\u7684\u5bb9\u91cf\uff0c\u6240\u4ee5\u51fa\u73fe\u9019\u500b\u932f\u8aa4\u3002 ref: https://help.aliyun.com/document_detail/127601.html \u9ad8\u6548\u4e91\u76d8\uff1a\u6700\u5c0f20 GiB\u3002 SSD\u4e91\u76d8\uff1a\u6700\u5c0f20 GiB\u3002 ESSD\u4e91\u76d8\uff1a\u6700\u5c0f20 GiB\u3002","title":"ACK - failed to provision volume with StorageClass \"alicloud-disk-ssd\": rpc error: code = Internal desc = SDK.ServerError"},{"location":"Today-I-Learned/2021/#nginx-use-nfs-to-share-proxy_cache","text":"proxy_cache_path / var /cache/nginx levels=1:2 keys_zone=storage:128m inactive=1y max_size=64G use_temp_path=off; Must to add use_temp_path=off which default to on .","title":"Nginx - Use NFS to share proxy_cache"},{"location":"Today-I-Learned/2021/#2021-01-08","text":"","title":"2021-01-08"},{"location":"Today-I-Learned/2021/#gsutil-upload-file-to-aws-s3","text":"Least AWS user permission. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"VisualEditor0\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"s3:PutObject\" , \"s3:PutObjectAcl\" , \"s3:GetObject\" , \"s3:GetObjectAcl\" , \"s3:DeleteObject\" ], \"Resource\" : \"arn:aws:s3:::backup.rammus.tw/*\" }, { \"Sid\" : \"VisualEditor1\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"s3:ListBucket\" , \"s3:GetBucketLocation\" ], \"Resource\" : \"arn:aws:s3:::backup.rammus.tw\" } ] } Generate configuration export AWS_ACCESS_KEY_ID = export AWS_SECRET_ACCESS_KEY = cat << EOF > ~/.boto [Credentials] aws_access_key_id = $AWS_ACCESS_KEY_ID aws_secret_access_key = $AWS_SECRET_ACCESS_KEY [s3] calling_format = boto.s3.connection.OrdinaryCallingFormat use-sigv4=True host=s3.ap-northeast-1.amazonaws.com EOF Start to uplaod gsutil cp a s3://backup.rammus.tw","title":"gsutil - Upload file to AWS S3"},{"location":"snippets/alpine-linux/","text":"Alpine Linux examples, template, snippet Useful packages \u00b6 apk add busybox-extra apk add bind-tools apk add curl httpie Build gcc \u00b6 apk add build-base linux-headers $ docker run -it --rm alpine:3.12 apk add build-base linux-headers fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz (1/22) Upgrading musl (1.1.24-r8 -> 1.1.24-r9) (2/22) Installing libgcc (9.3.0-r2) (3/22) Installing libstdc++ (9.3.0-r2) (4/22) Installing binutils (2.34-r1) (5/22) Installing libmagic (5.38-r0) (6/22) Installing file (5.38-r0) (7/22) Installing gmp (6.2.0-r0) (8/22) Installing isl (0.18-r0) (9/22) Installing libgomp (9.3.0-r2) (10/22) Installing libatomic (9.3.0-r2) (11/22) Installing libgphobos (9.3.0-r2) (12/22) Installing mpfr4 (4.0.2-r4) (13/22) Installing mpc1 (1.1.0-r1) (14/22) Installing gcc (9.3.0-r2) (15/22) Installing musl-dev (1.1.24-r9) (16/22) Installing libc-dev (0.7.2-r3) (17/22) Installing g++ (9.3.0-r2) (18/22) Installing make (4.3-r0) (19/22) Installing fortify-headers (1.1-r0) (20/22) Installing patch (2.7.6-r6) (21/22) Installing build-base (0.5-r2) (22/22) Installing linux-headers (5.4.5-r1) Executing busybox-1.31.1-r16.trigger OK: 213 MiB in 35 packages","title":"Alpine linux"},{"location":"snippets/alpine-linux/#useful-packages","text":"apk add busybox-extra apk add bind-tools apk add curl httpie","title":"Useful packages"},{"location":"snippets/alpine-linux/#build-gcc","text":"apk add build-base linux-headers $ docker run -it --rm alpine:3.12 apk add build-base linux-headers fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz (1/22) Upgrading musl (1.1.24-r8 -> 1.1.24-r9) (2/22) Installing libgcc (9.3.0-r2) (3/22) Installing libstdc++ (9.3.0-r2) (4/22) Installing binutils (2.34-r1) (5/22) Installing libmagic (5.38-r0) (6/22) Installing file (5.38-r0) (7/22) Installing gmp (6.2.0-r0) (8/22) Installing isl (0.18-r0) (9/22) Installing libgomp (9.3.0-r2) (10/22) Installing libatomic (9.3.0-r2) (11/22) Installing libgphobos (9.3.0-r2) (12/22) Installing mpfr4 (4.0.2-r4) (13/22) Installing mpc1 (1.1.0-r1) (14/22) Installing gcc (9.3.0-r2) (15/22) Installing musl-dev (1.1.24-r9) (16/22) Installing libc-dev (0.7.2-r3) (17/22) Installing g++ (9.3.0-r2) (18/22) Installing make (4.3-r0) (19/22) Installing fortify-headers (1.1-r0) (20/22) Installing patch (2.7.6-r6) (21/22) Installing build-base (0.5-r2) (22/22) Installing linux-headers (5.4.5-r1) Executing busybox-1.31.1-r16.trigger OK: 213 MiB in 35 packages","title":"Build gcc"},{"location":"snippets/bash/","text":"Bash \u00b6 Date \u00b6 DATE = $( date +%Y%m%d_%H%M%S ) FILE = \"/backup/backup- $DATE \" Loop \u00b6 for OUTPUT in $( Linux-Or-Unix-Command-Here ) do command1 on $OUTPUT command2 on $OUTPUT commandN done ref: https://www.cyberciti.biz/faq/bash-for-loop/ Varaible \u00b6 \b\b\u8a2d\u5b9a/\u522a\u9664 \u00b6 export A_VARIBALE unset A_VARIBALE \u4f7f\u7528\u9810\u8a2d\u503c \u00b6 ACTOR=${ACTOR:-$GITHUB_ACTOR} qq = ops:default echo ${ qq #*: } # default echo ${ qq %:* } # ops Return error code when a variable is not found \u00b6 ref: https://stackoverflow.com/a/307735/3854890 sh-3.2$ STATE = abc sh-3.2$ : ${ STATE :? \"Need to set STATE\" } sh-3.2$ echo $? 0 sh-3.2$ unset STATE sh-3.2$ : ${ STATE :? \"Need to set STATE\" } sh: STATE: Need to set STATE sh-3.2$ echo $? 1 Echo Bash List with comma(,) \u00b6 ROLE_PERMISSIONS =( compute.disks.get compute.disks.create compute.disks.createSnapshot compute.snapshots.get compute.snapshots.create compute.snapshots.useReadOnly compute.snapshots.delete compute.zones.get ) echo \" $( IFS = \",\" ; echo \" ${ ROLE_PERMISSIONS [*] } \" ) \" \u66ab\u6642\u9032\u5230\u67d0\u500b folder \u57f7\u884c\u6307\u4ee4\uff0c\u4e0d\u6539\u8b8a\u76ee\u524d path \u00b6 ( cd src/ && git checkout $NEW_VERSION_SHA ) ANSI - \u8f38\u51fa\u6587\u5b57\u8b8a\u8272 \u00b6 https://misc.flogisoft.com/bash/tip_colors_and_formatting echo -e \"Default \\e[31mRed\" echo -e \"\\e[31mHello\\e[0m World\" echo -e \"\\e[1;31mHello\\e[0m World\" -e : to use \\e[31m Reference \u00b6 https://devhints.io/bash Bash FAQ: http://mywiki.wooledge.org/BashFAQ/031","title":"Bash"},{"location":"snippets/bash/#bash","text":"","title":"Bash"},{"location":"snippets/bash/#date","text":"DATE = $( date +%Y%m%d_%H%M%S ) FILE = \"/backup/backup- $DATE \"","title":"Date"},{"location":"snippets/bash/#loop","text":"for OUTPUT in $( Linux-Or-Unix-Command-Here ) do command1 on $OUTPUT command2 on $OUTPUT commandN done ref: https://www.cyberciti.biz/faq/bash-for-loop/","title":"Loop"},{"location":"snippets/bash/#varaible","text":"","title":"Varaible"},{"location":"snippets/bash/#_1","text":"export A_VARIBALE unset A_VARIBALE","title":"\b\b\u8a2d\u5b9a/\u522a\u9664"},{"location":"snippets/bash/#_2","text":"ACTOR=${ACTOR:-$GITHUB_ACTOR} qq = ops:default echo ${ qq #*: } # default echo ${ qq %:* } # ops","title":"\u4f7f\u7528\u9810\u8a2d\u503c"},{"location":"snippets/bash/#return-error-code-when-a-variable-is-not-found","text":"ref: https://stackoverflow.com/a/307735/3854890 sh-3.2$ STATE = abc sh-3.2$ : ${ STATE :? \"Need to set STATE\" } sh-3.2$ echo $? 0 sh-3.2$ unset STATE sh-3.2$ : ${ STATE :? \"Need to set STATE\" } sh: STATE: Need to set STATE sh-3.2$ echo $? 1","title":"Return error code when a variable is not found"},{"location":"snippets/bash/#echo-bash-list-with-comma","text":"ROLE_PERMISSIONS =( compute.disks.get compute.disks.create compute.disks.createSnapshot compute.snapshots.get compute.snapshots.create compute.snapshots.useReadOnly compute.snapshots.delete compute.zones.get ) echo \" $( IFS = \",\" ; echo \" ${ ROLE_PERMISSIONS [*] } \" ) \"","title":"Echo Bash List with comma(,)"},{"location":"snippets/bash/#folder-path","text":"( cd src/ && git checkout $NEW_VERSION_SHA )","title":"\u66ab\u6642\u9032\u5230\u67d0\u500b folder \u57f7\u884c\u6307\u4ee4\uff0c\u4e0d\u6539\u8b8a\u76ee\u524d path"},{"location":"snippets/bash/#ansi-","text":"https://misc.flogisoft.com/bash/tip_colors_and_formatting echo -e \"Default \\e[31mRed\" echo -e \"\\e[31mHello\\e[0m World\" echo -e \"\\e[1;31mHello\\e[0m World\" -e : to use \\e[31m","title":"ANSI - \u8f38\u51fa\u6587\u5b57\u8b8a\u8272"},{"location":"snippets/bash/#reference","text":"https://devhints.io/bash Bash FAQ: http://mywiki.wooledge.org/BashFAQ/031","title":"Reference"},{"location":"snippets/docker-compose/","text":"Docker Compose \u00b6 version : '3' services : web : build : . ports : - \"5000:5000\" redis : image : \"redis:alpine\" networks : - frontend networks : frontend : name : custom_frontend Connect to redis \u00b6 version : '3' services : redis : image : \"redis:alpine\" ports : - \"6379:6379\" celery : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis celery-2 : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis docker exec -it celery_celery_1 ping redis docker exec -it celery_celery_1 ping redis-not-found Reference \u00b6 https://docs.docker.com/compose/compose-file/","title":"Docker Compose"},{"location":"snippets/docker-compose/#docker-compose","text":"version : '3' services : web : build : . ports : - \"5000:5000\" redis : image : \"redis:alpine\" networks : - frontend networks : frontend : name : custom_frontend","title":"Docker Compose"},{"location":"snippets/docker-compose/#connect-to-redis","text":"version : '3' services : redis : image : \"redis:alpine\" ports : - \"6379:6379\" celery : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis celery-2 : image : \"celery:4.0.2\" environment : - CELERY_BROKER_URL=redis://redis docker exec -it celery_celery_1 ping redis docker exec -it celery_celery_1 ping redis-not-found","title":"Connect to redis"},{"location":"snippets/docker-compose/#reference","text":"https://docs.docker.com/compose/compose-file/","title":"Reference"},{"location":"snippets/docker/","text":"Install docker \u00b6 ref: https://docs.docker.com/engine/install/ubuntu/#install-using-the-convenience-script curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo usermod -aG docker rammus docker-compose: https://docs.docker.com/compose/install/ sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Minimize docker image \u00b6 Delete libraries only used in build time \u00b6 apk update \\ && apk add --no-cache --virtual .build-deps curl \\ && curl -sL $TOOL_URL | gzip -d - > /usr/local/bin/new_tool \\ && chmod +x /usr/local/bin/new_tool \\ && apk del .build-deps Clena docker legacy data \u00b6 docker image prune -af docker rmi $(docker images -f \"dangling=true\" -q) -f docker volume rm $(docker volume ls -qf dangling=true) Buildkit \u00b6 Troubleshooting \u00b6 {\"registry-mirrors\": [\" https://mirror.gcr.io \"]} cause error \u00b6 \u4e0d\u80fd\u548c registry-mirrors \u4e00\u8d77\u7528 (issue: https://github.com/moby/moby/issues/39120 ) resolve image config for docker.io/docker/dockerfile:experimental: \u00b6 DOCKER_BUILDKIT = 1 docker build -t demo . [ + ] Building 0 .5s ( 3 /3 ) FINISHED = > [ internal ] load build definition from Dockerfile 0 .0s = > = > transferring dockerfile: 259B 0 .0s = > [ internal ] load .dockerignore 0 .0s = > = > transferring context: 2B 0 .0s = > ERROR resolve image config for docker.io/docker/dockerfile:experimental 0 .5s ------ > resolve image config for docker.io/docker/dockerfile:experimental: ------ failed to solve with frontend dockerfile.v0: failed to solve with frontend gateway.v0: docker.io/docker/dockerfile:experimental not found Solution \u5728 ~/.docker/daemon.json \u52a0\u5165 \"features\" : { \"buildkit\" : true } \u6216\u662f DOCKER_BUILDKIT = 1 \u8981\u5728 Dockerfile \u958b\u982d\u52a0\u5165 # syntax = docker/dockerfile:experimental # syntax = docker/dockerfile:experimental FROM alpine:3.10 failed to solve with frontend dockerfile.v0: failed to create LLB definition: Dockerfile parse error line 3: Unknown flag: mount error: failed to get status: rpc error: code = Unavailable desc = connection error: desc = \"transport: error while dialing: dial unix /run/buildkit/buildkitd.sock: connect: no such file or directory\" \u00b6 error: failed to get status: rpc error: code = Unavailable desc = connection error: desc = \"transport: error while dialing: dial unix /run/buildkit/buildkitd.sock: connect: no such file or directory\" buildctl build \\ --frontend = dockerfile.v0 \\ --local context = echo-box/2.0 --local dockerfile = echo-box/2.0 \\ --output type = image,name = ghcr.io/swaglive/action-demo:2.0,push = true \\ --export-cache type = inline \\ --import-cache type = registry,ref = ghcr.io/swaglive/action-demo:2.0","title":"Docker"},{"location":"snippets/docker/#install-docker","text":"ref: https://docs.docker.com/engine/install/ubuntu/#install-using-the-convenience-script curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo usermod -aG docker rammus docker-compose: https://docs.docker.com/compose/install/ sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose","title":"Install docker"},{"location":"snippets/docker/#minimize-docker-image","text":"","title":"Minimize docker image"},{"location":"snippets/docker/#delete-libraries-only-used-in-build-time","text":"apk update \\ && apk add --no-cache --virtual .build-deps curl \\ && curl -sL $TOOL_URL | gzip -d - > /usr/local/bin/new_tool \\ && chmod +x /usr/local/bin/new_tool \\ && apk del .build-deps","title":"Delete libraries only used in build time"},{"location":"snippets/docker/#clena-docker-legacy-data","text":"docker image prune -af docker rmi $(docker images -f \"dangling=true\" -q) -f docker volume rm $(docker volume ls -qf dangling=true)","title":"Clena docker legacy data"},{"location":"snippets/docker/#buildkit","text":"","title":"Buildkit"},{"location":"snippets/docker/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"snippets/docker/#registry-mirrors-httpsmirrorgcrio-cause-error","text":"\u4e0d\u80fd\u548c registry-mirrors \u4e00\u8d77\u7528 (issue: https://github.com/moby/moby/issues/39120 )","title":"{\"registry-mirrors\": [\"https://mirror.gcr.io\"]} cause error"},{"location":"snippets/docker/#resolve-image-config-for-dockeriodockerdockerfileexperimental","text":"DOCKER_BUILDKIT = 1 docker build -t demo . [ + ] Building 0 .5s ( 3 /3 ) FINISHED = > [ internal ] load build definition from Dockerfile 0 .0s = > = > transferring dockerfile: 259B 0 .0s = > [ internal ] load .dockerignore 0 .0s = > = > transferring context: 2B 0 .0s = > ERROR resolve image config for docker.io/docker/dockerfile:experimental 0 .5s ------ > resolve image config for docker.io/docker/dockerfile:experimental: ------ failed to solve with frontend dockerfile.v0: failed to solve with frontend gateway.v0: docker.io/docker/dockerfile:experimental not found Solution \u5728 ~/.docker/daemon.json \u52a0\u5165 \"features\" : { \"buildkit\" : true } \u6216\u662f DOCKER_BUILDKIT = 1 \u8981\u5728 Dockerfile \u958b\u982d\u52a0\u5165 # syntax = docker/dockerfile:experimental # syntax = docker/dockerfile:experimental FROM alpine:3.10 failed to solve with frontend dockerfile.v0: failed to create LLB definition: Dockerfile parse error line 3: Unknown flag: mount","title":"resolve image config for docker.io/docker/dockerfile:experimental:"},{"location":"snippets/docker/#error-failed-to-get-status-rpc-error-code-unavailable-desc-connection-error-desc-transport-error-while-dialing-dial-unix-runbuildkitbuildkitdsock-connect-no-such-file-or-directory","text":"error: failed to get status: rpc error: code = Unavailable desc = connection error: desc = \"transport: error while dialing: dial unix /run/buildkit/buildkitd.sock: connect: no such file or directory\" buildctl build \\ --frontend = dockerfile.v0 \\ --local context = echo-box/2.0 --local dockerfile = echo-box/2.0 \\ --output type = image,name = ghcr.io/swaglive/action-demo:2.0,push = true \\ --export-cache type = inline \\ --import-cache type = registry,ref = ghcr.io/swaglive/action-demo:2.0","title":"error: failed to get status: rpc error: code = Unavailable desc = connection error: desc = \"transport: error while dialing: dial unix /run/buildkit/buildkitd.sock: connect: no such file or directory\""},{"location":"snippets/dockerfiles/","text":"Dockerfile examples, template, snippet Javascript \u00b6 FROM node:12.14.0-alpine3.11 as builder ENV NODE_ENV=production WORKDIR /app COPY ./app/package.json ./ RUN npm install COPY ./app ./ ### FROM node:12.14.0-alpine3.11 ENTRYPOINT npm start ENV NODE_ENV=production WORKDIR /app COPY --from=builder /app /app","title":"Dockerfiles"},{"location":"snippets/dockerfiles/#javascript","text":"FROM node:12.14.0-alpine3.11 as builder ENV NODE_ENV=production WORKDIR /app COPY ./app/package.json ./ RUN npm install COPY ./app ./ ### FROM node:12.14.0-alpine3.11 ENTRYPOINT npm start ENV NODE_ENV=production WORKDIR /app COPY --from=builder /app /app","title":"Javascript"},{"location":"snippets/elasticsearch/","text":"Status \u00b6 curl elasticsearch-client.elasticsearch:9200 URL=\"localhost:9200\" URL=\"elasticsearch-client:9200\" curl -X GET $URL/ curl -X GET \"$URL/_cat/health?v\" curl -X GET \"$URL/_cat/nodes?v\" curl -X GET \"$URL/_cat/indices?v\" curl -X GET \"$URL/_cat/allocation?v\" curl -X GET \"$URL/_cat/shards?v\" curl -X GET \"$URL/_all/_settings?pretty\" curl -X GET http://$URL/_nodes/jvm?pretty curl -X GET http://$URL/_nodes/process?pretty curl -X GET \"$URL/_nodes/stats?pretty\" curl -X GET \"$URL/_nodes/nodeId1,nodeId2/stats\" curl -X GET \"$URL/_nodes/elasticsearch-data-2/stats\" curl -X GET $URL/_cluster/health?pretty curl -X GET $URL/_cluster/settings?pretty # Check jvm curl -X GET \"$URL/_nodes/stats/jvm?pretty\" curl -X GET \"$URL/_nodes/stats/jvm?pretty\" |grep heap_used_in_bytes CRUD \u00b6 URL=\"elasticsearch-client:9200\" curl -X PUT \"$URL/customer?pretty\" curl -X PUT \"$URL/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d' { \"name\": \"John Doe\" } ' curl -X GET \"$URL/customer/_doc/1?pretty\" curl -X GET \"$URL/_cat/indices?v\" curl -X DELETE $URL/ Plugin \u00b6 /bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.0.0/elasticsearch-analysis-ik-7.0.0.zip curl -X GET \"$URL/_cat/plugins?v&s=component&h=name,component,version,description\" curl -X GET \"$URL/_cat/plugins\" Benchmark \u00b6 esrally --track=geonames --pipeline=benchmark-only --target-hosts=elasticsearch-client:9200 esrally --track=pmc --pipeline=benchmark-only --target-hosts=elasticsearch-client:9200","title":"Elasticsearch"},{"location":"snippets/elasticsearch/#status","text":"curl elasticsearch-client.elasticsearch:9200 URL=\"localhost:9200\" URL=\"elasticsearch-client:9200\" curl -X GET $URL/ curl -X GET \"$URL/_cat/health?v\" curl -X GET \"$URL/_cat/nodes?v\" curl -X GET \"$URL/_cat/indices?v\" curl -X GET \"$URL/_cat/allocation?v\" curl -X GET \"$URL/_cat/shards?v\" curl -X GET \"$URL/_all/_settings?pretty\" curl -X GET http://$URL/_nodes/jvm?pretty curl -X GET http://$URL/_nodes/process?pretty curl -X GET \"$URL/_nodes/stats?pretty\" curl -X GET \"$URL/_nodes/nodeId1,nodeId2/stats\" curl -X GET \"$URL/_nodes/elasticsearch-data-2/stats\" curl -X GET $URL/_cluster/health?pretty curl -X GET $URL/_cluster/settings?pretty # Check jvm curl -X GET \"$URL/_nodes/stats/jvm?pretty\" curl -X GET \"$URL/_nodes/stats/jvm?pretty\" |grep heap_used_in_bytes","title":"Status"},{"location":"snippets/elasticsearch/#crud","text":"URL=\"elasticsearch-client:9200\" curl -X PUT \"$URL/customer?pretty\" curl -X PUT \"$URL/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d' { \"name\": \"John Doe\" } ' curl -X GET \"$URL/customer/_doc/1?pretty\" curl -X GET \"$URL/_cat/indices?v\" curl -X DELETE $URL/","title":"CRUD"},{"location":"snippets/elasticsearch/#plugin","text":"/bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.0.0/elasticsearch-analysis-ik-7.0.0.zip curl -X GET \"$URL/_cat/plugins?v&s=component&h=name,component,version,description\" curl -X GET \"$URL/_cat/plugins\"","title":"Plugin"},{"location":"snippets/elasticsearch/#benchmark","text":"esrally --track=geonames --pipeline=benchmark-only --target-hosts=elasticsearch-client:9200 esrally --track=pmc --pipeline=benchmark-only --target-hosts=elasticsearch-client:9200","title":"Benchmark"},{"location":"snippets/fun-markdown/","text":"2020-08-20 \u00b6 Chart.js example - Inject chart in markdown document \u00b6 https://www.chartjs.org/docs/latest/ var ctx = document.getElementById('myChart').getContext('2d'); var myChart = new Chart(ctx, { type: 'bar', data: { labels: ['Red', 'Blue', 'Yellow', 'Green', 'Purple', 'Orange'], datasets: [{ label: '# of Votes', data: [12, 19, 3, 5, 2, 3], backgroundColor: [ 'rgba(255, 99, 132, 0.2)', 'rgba(54, 162, 235, 0.2)', 'rgba(255, 206, 86, 0.2)', 'rgba(75, 192, 192, 0.2)', 'rgba(153, 102, 255, 0.2)', 'rgba(255, 159, 64, 0.2)' ], borderColor: [ 'rgba(255, 99, 132, 1)', 'rgba(54, 162, 235, 1)', 'rgba(255, 206, 86, 1)', 'rgba(75, 192, 192, 1)', 'rgba(153, 102, 255, 1)', 'rgba(255, 159, 64, 1)' ], borderWidth: 1 }] }, options: { scales: { yAxes: [{ ticks: { beginAtZero: true } }] } } });","title":"Fun markdown"},{"location":"snippets/fun-markdown/#2020-08-20","text":"","title":"2020-08-20"},{"location":"snippets/fun-markdown/#chartjs-example-inject-chart-in-markdown-document","text":"https://www.chartjs.org/docs/latest/ var ctx = document.getElementById('myChart').getContext('2d'); var myChart = new Chart(ctx, { type: 'bar', data: { labels: ['Red', 'Blue', 'Yellow', 'Green', 'Purple', 'Orange'], datasets: [{ label: '# of Votes', data: [12, 19, 3, 5, 2, 3], backgroundColor: [ 'rgba(255, 99, 132, 0.2)', 'rgba(54, 162, 235, 0.2)', 'rgba(255, 206, 86, 0.2)', 'rgba(75, 192, 192, 0.2)', 'rgba(153, 102, 255, 0.2)', 'rgba(255, 159, 64, 0.2)' ], borderColor: [ 'rgba(255, 99, 132, 1)', 'rgba(54, 162, 235, 1)', 'rgba(255, 206, 86, 1)', 'rgba(75, 192, 192, 1)', 'rgba(153, 102, 255, 1)', 'rgba(255, 159, 64, 1)' ], borderWidth: 1 }] }, options: { scales: { yAxes: [{ ticks: { beginAtZero: true } }] } } });","title":"Chart.js example - Inject chart in markdown document"},{"location":"snippets/gcp/","text":"GCP \u00b6 GKE(Google Kubernetes Engine) \u00b6 gcloud components update gcloud container clusters list gcloud container clusters get-credentials staging --region = asia-east1 kubectl config get-contexts kubectl config use-context production kubectl config set-context --current --namespace = dev kubectl create clusterrolebinding cluster-admin-binding \\ --clusterrole cluster-admin \\ --user user-account gcloud container operations list Create a regional GKE CLUSTER_NAME = old REGION = asia-east2 # Choose a static version or a release channel CLUSTER_VERSION = \"--cluster-version=1.14.10-gke.50\" # CLUSTER_VERSION=\"--release-channel regular\" gcloud beta container clusters create ${ CLUSTER_NAME } --region ${ REGION } \\ ${ CLUSTER_VERSION } \\ --machine-type \"n2-highcpu-2\" --image-type \"COS\" --disk-size \"100\" --disk-type \"pd-ssd\" \\ --scopes \"https://www.googleapis.com/auth/compute\" , \"https://www.googleapis.com/auth/devstorage.read_only\" , \\ \"https://www.googleapis.com/auth/logging.write\" , \"https://www.googleapis.com/auth/monitoring\" , \\ \"https://www.googleapis.com/auth/servicecontrol\" , \"https://www.googleapis.com/auth/service.management.readonly\" , \\ \"https://www.googleapis.com/auth/trace.append\" , \"https://www.googleapis.com/auth/cloud-platform\" \\ --num-nodes \"1\" --preemptible --enable-autoscaling --min-nodes \"1\" --max-nodes \"3\" \\ --enable-stackdriver-kubernetes --enable-ip-alias --async Create static ip address \u00b6 ref: https://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip gcloud compute addresses create dnsmasq-ip-2 --region asia-east1 gcloud compute addresses describe dnsmasq-ip-2 --region asia-east1 Use google service account key as Kubernetes secret \u00b6 Import google service account key to Kubernetes secret kubectl create secret generic my-sa-key --from-file = key.json = my-sa-key.json spec : volumes : - name : google-cloud-key secret : secretName : my-sa-key containers : - name : subscriber image : gcr.io/google-samples/pubsub-sample:v1 volumeMounts : - name : google-cloud-key mountPath : /var/secrets/google env : - name : GOOGLE_APPLICATION_CREDENTIALS value : /var/secrets/google/key.json GCS(Google Cloud Stroge) \u00b6 Public to internet \u00b6 Edit bucket permissions -> Add member -> allUsers: Storage Object Viewer Test service accout permission \u00b6 SA = $( cat service-account.json | base64 ) docker run -it --rm --entrypoint bash gcr.io/cloud-builders/gsutil -c \" echo $SA | base64 -d > sa.json gcloud auth activate-service-account --key-file=sa.json bash \" gsutil ls gs://<replace_this_with_your_bucket> gsutil - Verify a google service account with docker and a environment variable \u00b6 docker run -it --rm --entrypoint bash gcr.io/cloud-builders/gsutil sa = '{key.json,....}' gcloud auth activate-service-account --key-file = < ( echo $sa ) gsutil ls gs://rammus.dev GCR(Container Registry) \u00b6 Use service account json to login GCR \u00b6 gcloud auth activate-service-account --key-file=gcloud.json # https://cloud.google.com/container-registry/docs/advanced-authentication cat gcloud.json | docker login -u _json_key --password-stdin https://asia.gcr.io Projects \u00b6 Switch projects \u00b6 gcloud projects list gcloud config set project my-project Use GCP service account \u00b6 gcloud auth activate-service-account sa-devops@rammus-xu.iam.gserviceaccount.com --key-file = $GOOGLE_APPLICATION_CREDENTIALS","title":"GCP"},{"location":"snippets/gcp/#gcp","text":"","title":"GCP"},{"location":"snippets/gcp/#gkegoogle-kubernetes-engine","text":"gcloud components update gcloud container clusters list gcloud container clusters get-credentials staging --region = asia-east1 kubectl config get-contexts kubectl config use-context production kubectl config set-context --current --namespace = dev kubectl create clusterrolebinding cluster-admin-binding \\ --clusterrole cluster-admin \\ --user user-account gcloud container operations list Create a regional GKE CLUSTER_NAME = old REGION = asia-east2 # Choose a static version or a release channel CLUSTER_VERSION = \"--cluster-version=1.14.10-gke.50\" # CLUSTER_VERSION=\"--release-channel regular\" gcloud beta container clusters create ${ CLUSTER_NAME } --region ${ REGION } \\ ${ CLUSTER_VERSION } \\ --machine-type \"n2-highcpu-2\" --image-type \"COS\" --disk-size \"100\" --disk-type \"pd-ssd\" \\ --scopes \"https://www.googleapis.com/auth/compute\" , \"https://www.googleapis.com/auth/devstorage.read_only\" , \\ \"https://www.googleapis.com/auth/logging.write\" , \"https://www.googleapis.com/auth/monitoring\" , \\ \"https://www.googleapis.com/auth/servicecontrol\" , \"https://www.googleapis.com/auth/service.management.readonly\" , \\ \"https://www.googleapis.com/auth/trace.append\" , \"https://www.googleapis.com/auth/cloud-platform\" \\ --num-nodes \"1\" --preemptible --enable-autoscaling --min-nodes \"1\" --max-nodes \"3\" \\ --enable-stackdriver-kubernetes --enable-ip-alias --async","title":"GKE(Google Kubernetes Engine)"},{"location":"snippets/gcp/#create-static-ip-address","text":"ref: https://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip gcloud compute addresses create dnsmasq-ip-2 --region asia-east1 gcloud compute addresses describe dnsmasq-ip-2 --region asia-east1","title":"Create static ip address"},{"location":"snippets/gcp/#use-google-service-account-key-as-kubernetes-secret","text":"Import google service account key to Kubernetes secret kubectl create secret generic my-sa-key --from-file = key.json = my-sa-key.json spec : volumes : - name : google-cloud-key secret : secretName : my-sa-key containers : - name : subscriber image : gcr.io/google-samples/pubsub-sample:v1 volumeMounts : - name : google-cloud-key mountPath : /var/secrets/google env : - name : GOOGLE_APPLICATION_CREDENTIALS value : /var/secrets/google/key.json","title":"Use google service account key as Kubernetes secret"},{"location":"snippets/gcp/#gcsgoogle-cloud-stroge","text":"","title":"GCS(Google Cloud Stroge)"},{"location":"snippets/gcp/#public-to-internet","text":"Edit bucket permissions -> Add member -> allUsers: Storage Object Viewer","title":"Public to internet"},{"location":"snippets/gcp/#test-service-accout-permission","text":"SA = $( cat service-account.json | base64 ) docker run -it --rm --entrypoint bash gcr.io/cloud-builders/gsutil -c \" echo $SA | base64 -d > sa.json gcloud auth activate-service-account --key-file=sa.json bash \" gsutil ls gs://<replace_this_with_your_bucket>","title":"Test service accout permission"},{"location":"snippets/gcp/#gsutil-verify-a-google-service-account-with-docker-and-a-environment-variable","text":"docker run -it --rm --entrypoint bash gcr.io/cloud-builders/gsutil sa = '{key.json,....}' gcloud auth activate-service-account --key-file = < ( echo $sa ) gsutil ls gs://rammus.dev","title":"gsutil - Verify a google service account with docker and a environment variable"},{"location":"snippets/gcp/#gcrcontainer-registry","text":"","title":"GCR(Container Registry)"},{"location":"snippets/gcp/#use-service-account-json-to-login-gcr","text":"gcloud auth activate-service-account --key-file=gcloud.json # https://cloud.google.com/container-registry/docs/advanced-authentication cat gcloud.json | docker login -u _json_key --password-stdin https://asia.gcr.io","title":"Use service account json to login GCR"},{"location":"snippets/gcp/#projects","text":"","title":"Projects"},{"location":"snippets/gcp/#switch-projects","text":"gcloud projects list gcloud config set project my-project","title":"Switch projects"},{"location":"snippets/gcp/#use-gcp-service-account","text":"gcloud auth activate-service-account sa-devops@rammus-xu.iam.gserviceaccount.com --key-file = $GOOGLE_APPLICATION_CREDENTIALS","title":"Use GCP service account"},{"location":"snippets/git/","text":"Git examples, template, snippet Git \u00b6 git branch -D 20190320_for_ssl git branch -avv git remote -v git pull --rebase git checkout -t origin/20190320_for_ssl git checkout master git push -u origin feature_branch_name git push -u origin HEAD:20190401_add_k8s_stage git remote prune origin --dry-run git remote prune origin # Get current commit sha git rev-parse --short=7 HEAD Submodule \u00b6 git submodule update --init Clean submodule \u00b6 rm -rf .gitmodules ## .git/config [ submodule \"themes/landscape\" ] rm -rf .git/modules","title":"Git"},{"location":"snippets/git/#git","text":"git branch -D 20190320_for_ssl git branch -avv git remote -v git pull --rebase git checkout -t origin/20190320_for_ssl git checkout master git push -u origin feature_branch_name git push -u origin HEAD:20190401_add_k8s_stage git remote prune origin --dry-run git remote prune origin # Get current commit sha git rev-parse --short=7 HEAD","title":"Git"},{"location":"snippets/git/#submodule","text":"git submodule update --init","title":"Submodule"},{"location":"snippets/git/#clean-submodule","text":"rm -rf .gitmodules ## .git/config [ submodule \"themes/landscape\" ] rm -rf .git/modules","title":"Clean submodule"},{"location":"snippets/github-action/","text":"Github Action \u00b6 Github Actions(CI/CD) tricks that official documents didn't mention. This post including hints, tips, snippet, cheatsheet, troubleshooting, notes, how-to. Starter \u00b6 on : push : jobs : test : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Run tests run : | echo hi On trigger event \u00b6 on : push : branches : - \"master\" - \"**\" tags : - \"**\" paths : - src/** - Dockerfile pull_request : branches : - master repository_dispatch : types : [ rammus_post ] Important pull_request.branches is base on ref , not head_ref Environments and variables \u00b6 Pass variables \u00b6 echo ::set-output name = message:: $output_message echo \"action_state=yellow\" >> $GITHUB_ENV # Deprecated. ref: https://github.blog/changelog/2020-10-01-github-actions-deprecating-set-env-and-add-path-commands/ echo ::set-env name = action_state::yellow Use variables \u00b6 GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} GITHUB_TOKEN : ${{ env.ACTION_STATE }} PR_COMMENT : ${{ steps.message.outputs.message }} PR_COMMENT_URL : ${{ github.event.pull_request.comments_url }} PAYLOAD_ACTOR : ${{ github.event.client_payload.actor }} Use GITHUB_ACTOR as git commit author and using github avator \u00b6 https://help.github.com/en/github/setting-up-and-managing-your-github-user-account/setting-your-commit-email-address git config --global user.name \"${GITHUB_ACTOR}\" git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" remote_repo=\"https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${GITHUB_REPOSITORY}.git\" git remote add origin \"${remote_repo}\" Get commit author information \u00b6 This is only for push event AUTHOR_NAME : ${{ github.event.head_commit.author.name }} AUTHOR_EMAIL : ${{ github.event.head_commit.author.email }} Customize docker action \u00b6 name : 'Update Status' description : 'Update status' inputs : state : description : 'Option: success, failure' required : false default : 'success' auth_token : description : 'Auth token used to API' required : true default : \"${{ github.token }}\" pull_sha : description : 'Commit SHA' default : \"${{ github.event.pull_request.head.sha}}\" required : false push_sha : description : 'Commit SHA' required : false default : \"${{ github.sha }}\" if [[ $GITHUB_EVENT_NAME == 'pull_request' ]] ; then COMMIT_SHA = $INPUT_PULL_SHA else COMMIT_SHA = $INPUT_PUSH_SHA if condition \u00b6 if : contains(github.ref, 'refs/tags') if : contains(github.event.issue.title, 'Update APK') if : steps.git-diff.outputs.is-diff if : steps.set-env.outputs.message == 'hello' if : github.ref != 'refs/heads/master' if : github.event.action == 'dispatch_rammus_customize_action_type' if : github.event.issue.pull_request if : github.event_name == 'pull_request' && contains(github.head_ref, 'update-app') pull_request \u00b6 when specific event type \u00b6 if : github.event_name == 'pull_request' && github.event.action == 'unassigned' when branch name is \u00b6 if : github.event_name == 'pull_request' && contains(github.head_ref, 'my-feature-branch') when merged \u00b6 on : pull_request : types : [ closed ] jobs : merged : if : github.event.pull_request.merged == true Job syntax \u00b6 Wait other jobs finish \u00b6 jobs: job1: job2: needs: job1 job3: needs: [job1, job2] Setting \u00b6 ACTIONS_RUNNER_DEBUG : true Build an action \u00b6 Docker Action Example \u00b6 # action.yml name : 'Hello World' description : 'Greet someone and record the time' inputs : who-to-greet : # id of input description : 'Who to greet' required : true default : 'World' outputs : time : # id of output description : 'The time we greeted you' runs : using : 'docker' image : 'Dockerfile' args : - ${{ inputs.who-to-greet }} Composite (Multiple steps) Action Example \u00b6 name : 'Hello World' description : 'Greet someone' inputs : who-to-greet : # id of input description : 'Who to greet' required : true default : 'World' outputs : random-number : description : \"Random number\" value : ${{ steps.random-number-generator.outputs.random-id }} runs : using : \"composite\" steps : - run : echo Hello ${{ inputs.who-to-greet }}. shell : bash - id : random-number-generator run : echo \"::set-output name=random-id::$(echo $RANDOM)\" shell : bash - run : ${{ github.action_path }}/goodbye.sh shell : bash Get input as environemnt in Docker \u00b6 # action.yaml inputs : who-to-greet : # workflow.yaml - uses : ./actions/my-action with : who-to-greet : rammus # entrypoint.sh echo INPUTS_WHO_TO_GREET ENTRYPOINT need to be abolute path \u00b6 Warning When uses: ./actions/my-action Workflow will mount workspace --workdir /github/workspace COPY ./app.py / ENTRYPOINT python /app.py Awesome Actions \u00b6 Manually/Customize trigger a workflow \u00b6 https://github.blog/changelog/2020-07-06-github-actions-manual-triggers-with-workflow_dispatch/ on : workflow_dispatch : inputs : logLevel : description : 'Log level' required : true default : 'warning' tags : description : 'Test scenario tags' jobs : printInputs : runs-on : ubuntu-latest steps : - run : | echo \"Log level: ${{ github.event.inputs.logLevel }}\" echo \"Tags: ${{ github.event.inputs.tags }}\" Customize action type with http post method \u00b6 on : repository_dispatch : types : [ rammus_post ] jobs : rammus_job : env : ACTOR : ${{ github.event.client_payload.actor }} if : github.event.action == 'rammus_post' And you can send a post request like: INPUT_GITHUB_TOKEN = INPUT_COMMENT_URL = \"https://api.github.com/repos/<owner>/<repo>/dispatches\" curl -H \"Authorization: token $INPUT_GITHUB_TOKEN \" \\ -H \"Accept: application/vnd.github.everest-preview+json\" \\ -d '{\"event_type\":\"rammus_post\",\"client_payload\":{\"new_version_image\":\"echo-server:96b2166\", \"new_version_sha\":\"96b2166\",\"actor\":\"Rammus Xu\"}}' \\ -XPOST $INPUT_COMMENT_URL Docekr build and push to ghcr.io when pushing a git tag \u00b6 name : Tag on : push : tags : - \"**\" jobs : build : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Set Env run : | echo \"BUILD_TAG=${GITHUB_REF/refs\\/tags\\//}\" >> $GITHUB_ENV echo \"BUILD_SHA=${GITHUB_SHA:0:7}\" >> $GITHUB_ENV - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Docker Login # uses: docker/login-action@f3364599c6aa293cdc2b8391b1b56d0c30e45c8a uses : docker/login-action@v1.8.0 with : registry : ghcr.io username : ${{ secrets.GHCR_USERNAME }} password : ${{ secrets.GHCR_PASSWORD }} - name : Build and push Docker images # uses: docker/build-push-action@4a531fa5a603bab87dfa56578bd82b28508c9547 uses : docker/build-push-action@v2.2.2 with : context : \".\" tags : | ghcr.io/${{ github.repository }}:${{ env.BUILD_TAG }} ghcr.io/${{ github.repository }}:${{ env.BUILD_SHA }} push : true Docker login \u00b6 - name : Docker Login - docker.pkg.github.com uses : swaglive/actions/docker/login@944b742 with : password : ${{ secrets.GHR_PASSWORD }} username : ${{ secrets.GHR_USERNAME }} url : docker.pkg.github.com - name : Docker Login - docker.pkg.github.com if : contains(github.ref, 'tags') env : DOCKER_PASSWORD : ${{ secrets.GITHUB_TOKEN }} run : echo $DOCKER_PASSWORD | docker login -u $GITHUB_ACTOR --password-stdin docker.pkg.github.com Docker login and copy config to default container's workspace \u00b6 Note github runner will mount /home/runner/work/_temp/_github_home\":\"/github/home when we use a docker action. That means we can't use the credential directly in next steps. Only if you use a docker contain step. Since id: generate-mirror-list need docker credentials and run on default container, credentials should be copied to default container's home. And a docker action must run as root. Therefore, it needs to be sudo in a default container. - name : Docker Login - docker.pkg.github.com uses : swaglive/actions/docker/login@944b742 with : password : ${{ secrets.GHR_PASSWORD }} username : ${{ secrets.GHR_USERNAME }} url : docker.pkg.github.com - name : Do something in default container's workspace run : | sudo cp -R /home/runner/work/_temp/_github_home/.docker ~ sudo chown -R $(whoami) ~/.docker docker pull docker.pkg.github.com/swaglive/dockerfiles/kubectl:1.17 Cache node_modules \u00b6 - name : Get yarn cache directory path id : yarn-cache-dir-path run : echo \"::set-output name=dir::$(yarn cache dir)\" - uses : actions/cache@v2 with : path : ${{ steps.yarn-cache-dir-path.outputs.dir }} key : ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }} restore-keys : | ${{ runner.os }}-yarn- Fetch private submodule \u00b6 PAT = personal access token actions/checkout@v2 fixed git@github.com problem jobs : deploy : runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 with : fetch-depth : 0 submodules : true token : ${{ secrets.PAT }} - name : Fix submodules run : echo -e '[url \"https://github.com/\"]\\n insteadOf = \"git@github.com:\"' >> ~/.gitconfig - name : Checkout uses : actions/checkout@v1 with : fetch-depth : 0 submodules : true token : ${{ secrets.PAT }} Create pull request \u00b6 - name : Create Pull Request if : steps.create-branch.outputs.branch_name uses : actions/github-script@v3 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.pulls.create({ owner: 'swaglive', repo: 'action-demo', title: '[Action] ${{ steps.create-branch.outputs.branch_name }}', head: '${{ steps.create-branch.outputs.branch_name }}', base: 'master' }) - name : Create Pull Request if : steps.create-branch.outputs.branch_name uses : actions/github-script@v3 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.pulls.create({ ...context.repo, title: '[Action] ${{ steps.create-branch.outputs.branch_name }}', body: `Created by \\`${ process.env.GITHUB_ACTOR }\\``, head: '${{ steps.create-branch.outputs.branch_name }}', base: 'master' }) Commit and push and create pull request \u00b6 - name : Set environments run : echo \"NEW_BRANCH=update-config-$(date +%Y-%m-%d_%H%M%S-utc)\" >> $GITHUB_ENV - name : Configure git run : | git config --global user.name \"${GITHUB_ACTOR}\" git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" - name : Commit run : git commit -a -m \"Update config.json by ${GITHUB_ACTOR}\" - name : Git push run : git push origin HEAD:${NEW_BRANCH} - name : Create Pull Request uses : actions/github-script@v3 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.pulls.create({ ...context.repo, title: '${{ env.NEW_BRANCH }}', body: `Created by \\`${ process.env.GITHUB_ACTOR }\\``, head: '${{ env.NEW_BRANCH }}', base: 'master' }) Close issue when title contains specific string \u00b6 name : issue-opened on : issues : types : [ opened ] jobs : debug : runs-on : ubuntu-latest if : contains(github.event.issue.title, 'Update APK') steps : - name : Close issue uses : actions/github-script@0.8.0 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.issues.update({ ...context.repo, issue_number: context.issue.number, state: 'closed' }) github.issues.createComment({ ...context.repo, issue_number: context.issue.number, body: 'Close this!' }); Create a comment in pull request \u00b6 - name : Notify Results in Pull Request if : steps.generate-mirror-list.outputs.images uses : actions/github-script@0.3.0 with : github-token : ${{ secrets.GITHUB_TOKEN }} images : ${{ steps.generate-mirror-list.outputs.images }} script : | var body = \"## I mirrored something for you\" process.env.INPUT_IMAGES.split(' ').forEach(function(image){ let [source, target] = image.split('@') body = `${body}\\r\\n- \\`${source}\\` -> \\`${target}\\`` }) github.issues.createComment({ ...context.repo, issue_number: context.payload.number, body: body, }) Deploy mkdocs to gh-pages \u00b6 name : Publish on : push : branches : - master jobs : deploy : name : Deploy docs runs-on : ubuntu-latest steps : - name : Checkout master uses : actions/checkout@v1 - name : Deploy docs uses : mhausenblas/mkdocs-deploy-gh-pages@1.11 env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} Get other step output as enviroment in github-script \u00b6 jobs : debug : runs-on : ubuntu-latest steps : - id : update run : echo ::set-output name=message::okok - name : js uses : actions/github-script@0.8.0 env : MESSAGE : ${{ steps.update.outputs.message }} with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | var message = process.env.MESSAGE if (message !== undefined){ message == 'in' } else { message == 'else' } console.log(message) Docker build and push action \u00b6 name : docker-publish on : push : jobs : docker-publish : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 # Build base image - uses : docker/build-push-action@v1 with : username : _json_key password : ${{ secrets.GOOGLE_SA_GCR_JSON }} registry : asia.gcr.io repository : rammusxu/${{ github.event.repository.name }} tags : base target : base cache_froms : rammusxu/${{ github.event.repository.name }}:base # Build app image - uses : docker/build-push-action@v1 with : username : _json_key password : ${{ secrets.GOOGLE_SA_GCR_JSON }} registry : asia.gcr.io repository : rammusxu/${{ github.event.repository.name }} tags : ${{ github.sha }} cache_froms : rammusxu/${{ github.event.repository.name }}:${{ github.sha }} tag_with_ref : true FAQ \u00b6 What's logic used in push.branches and push.paths \u00b6 It's AND logic. It needs meet both conditions. Push to branch: dev** Something under echo-box folder changed on: push: branches: - \"dev**\" paths: - 'echo-box/**' How to activate google service account in action \u00b6 Should be echo '${{ secrets.GOOGLE_SA_JSON }}' \u2705 debug2 : runs-on : ubuntu-latest steps : - run : echo '${{ secrets.GOOGLE_SA_JSON }}' > sa.json - run : gcloud auth activate-service-account --key-file=sa.json - run : gsutil ls gs://rammus.dev \u274c debug : runs-on : ubuntu-latest steps : - run : echo \"${{ secrets.GOOGLE_SA_JSON }}\" > sa.json - run : gcloud auth activate-service-account --key-file=sa.json - run : gsutil ls gs://rammus.dev Can't load secrets in action.yaml \u00b6 \u274c # action.yaml inputs : kube_config : description : 'kubernetes config file' default : ${{ secrets.KUBE_CONFIG }} description : 'kubernetes config file. ex. ${{ secrets.KUBE_CONFIG }}' But ${{ github.token }} can be get in action.yaml \u00b6 \u2705 # action.yaml inputs : auth_token : description : 'Auth token used to API' required : true default : \"${{ github.token }}\" Misc \u00b6 iOS App Build \u00b6 Bitrise Standard: Available in Developer, Org Standard, Velocity plan 2vCPU @ 2.7 GHz, 4 GB RAM pricing $90 / Month Elite: Available in Org Elite, Velocity plan 4vCPU @ 3.5 GHz, 8 GB RAM pricing $270 / Month Github Action 2 vCPU @ 2.60GHz, 7 GB RAM princing $0.08 / minute Build status \u00b6 Clickable [ ![Publish](https://github.com/RammusXu/toolkit/workflows/Publish/badge.svg)](https://github.com/RammusXu/toolkit) Unclickable ![Publish](https://github.com/RammusXu/toolkit/workflows/Publish/badge.svg) Clickable: Unclickable: Env Sample \u00b6 Get environments in action \u00b6 jobs : show-env : runs-on : ubuntu-latest steps : - run : cat $GITHUB_EVENT_PATH - run : echo ${{ github.event_name }} - run : echo ${{ github.event.action }} - run : env - name : Dump GitHub context env : GITHUB_CONTEXT : ${{ toJson(github) }} run : echo \"$GITHUB_CONTEXT\" 2020-09-01 github context on push branch event \u00b6 ${{ toJson(github) }} { \"token\" : \"***\" , \"job\" : \"show-env\" , \"ref\" : \"refs/heads/github-pkg\" , \"sha\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"repository\" : \"rammusxu/action-demo\" , \"repository_owner\" : \"rammusxu\" , \"repositoryUrl\" : \"git://github.com/rammusxu/action-demo.git\" , \"run_id\" : \"221813086\" , \"run_number\" : \"166\" , \"actor\" : \"RammusXu\" , \"workflow\" : \"show-env\" , \"head_ref\" : \"\" , \"base_ref\" : \"\" , \"event_name\" : \"push\" , \"event\" : { \"after\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"base_ref\" : null , \"before\" : \"1c8b86a50a7bfb2d04984d5a67b414836aa04f22\" , \"commits\" : [ { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" } ], \"compare\" : \"https://github.com/rammusxu/action-demo/compare/1c8b86a50a7b...044271eda133\" , \"created\" : false , \"deleted\" : false , \"forced\" : false , \"head_commit\" : { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" }, \"organization\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"description\" : \"The SWAG Life\" , \"events_url\" : \"https://api.github.com/orgs/rammusxu/events\" , \"hooks_url\" : \"https://api.github.com/orgs/rammusxu/hooks\" , \"id\" : 36289044 , \"issues_url\" : \"https://api.github.com/orgs/rammusxu/issues\" , \"login\" : \"rammusxu\" , \"members_url\" : \"https://api.github.com/orgs/rammusxu/members{/member}\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"public_members_url\" : \"https://api.github.com/orgs/rammusxu/public_members{/member}\" , \"repos_url\" : \"https://api.github.com/orgs/rammusxu/repos\" , \"url\" : \"https://api.github.com/orgs/rammusxu\" }, \"pusher\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"RammusXu\" }, \"ref\" : \"refs/heads/github-pkg\" , \"repository\" : { \"archive_url\" : \"https://api.github.com/repos/rammusxu/action-demo/{archive_format}{/ref}\" , \"archived\" : false , \"assignees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/assignees{/user}\" , \"blobs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/blobs{/sha}\" , \"branches_url\" : \"https://api.github.com/repos/rammusxu/action-demo/branches{/branch}\" , \"clone_url\" : \"https://github.com/rammusxu/action-demo.git\" , \"collaborators_url\" : \"https://api.github.com/repos/rammusxu/action-demo/collaborators{/collaborator}\" , \"comments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/comments{/number}\" , \"commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/commits{/sha}\" , \"compare_url\" : \"https://api.github.com/repos/rammusxu/action-demo/compare/{base}...{head}\" , \"contents_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contents/{+path}\" , \"contributors_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contributors\" , \"created_at\" : 1564547431 , \"default_branch\" : \"master\" , \"deployments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/deployments\" , \"description\" : null , \"disabled\" : false , \"downloads_url\" : \"https://api.github.com/repos/rammusxu/action-demo/downloads\" , \"events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/events\" , \"fork\" : false , \"forks\" : 0 , \"forks_count\" : 0 , \"forks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/forks\" , \"full_name\" : \"rammusxu/action-demo\" , \"git_commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/commits{/sha}\" , \"git_refs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/refs{/sha}\" , \"git_tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/tags{/sha}\" , \"git_url\" : \"git://github.com/rammusxu/action-demo.git\" , \"has_downloads\" : true , \"has_issues\" : true , \"has_pages\" : true , \"has_projects\" : true , \"has_wiki\" : true , \"homepage\" : null , \"hooks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/hooks\" , \"html_url\" : \"https://github.com/rammusxu/action-demo\" , \"id\" : 199778774 , \"issue_comment_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/comments{/number}\" , \"issue_events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/events{/number}\" , \"issues_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues{/number}\" , \"keys_url\" : \"https://api.github.com/repos/rammusxu/action-demo/keys{/key_id}\" , \"labels_url\" : \"https://api.github.com/repos/rammusxu/action-demo/labels{/name}\" , \"language\" : \"Dockerfile\" , \"languages_url\" : \"https://api.github.com/repos/rammusxu/action-demo/languages\" , \"license\" : null , \"master_branch\" : \"master\" , \"merges_url\" : \"https://api.github.com/repos/rammusxu/action-demo/merges\" , \"milestones_url\" : \"https://api.github.com/repos/rammusxu/action-demo/milestones{/number}\" , \"mirror_url\" : null , \"name\" : \"action-demo\" , \"node_id\" : \"MDEwOlJlcG9zaXRvcnkxOTk3Nzg3NzQ=\" , \"notifications_url\" : \"https://api.github.com/repos/rammusxu/action-demo/notifications{?since,all,participating}\" , \"open_issues\" : 1 , \"open_issues_count\" : 1 , \"organization\" : \"rammusxu\" , \"owner\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"email\" : \"engineering@swag.live\" , \"events_url\" : \"https://api.github.com/users/rammusxu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/rammusxu/followers\" , \"following_url\" : \"https://api.github.com/users/rammusxu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/rammusxu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/rammusxu\" , \"id\" : 36289044 , \"login\" : \"rammusxu\" , \"name\" : \"rammusxu\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"organizations_url\" : \"https://api.github.com/users/rammusxu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/rammusxu/received_events\" , \"repos_url\" : \"https://api.github.com/users/rammusxu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/rammusxu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/rammusxu/subscriptions\" , \"type\" : \"Organization\" , \"url\" : \"https://api.github.com/users/rammusxu\" }, \"private\" : true , \"pulls_url\" : \"https://api.github.com/repos/rammusxu/action-demo/pulls{/number}\" , \"pushed_at\" : 1598262984 , \"releases_url\" : \"https://api.github.com/repos/rammusxu/action-demo/releases{/id}\" , \"size\" : 245 , \"ssh_url\" : \"git@github.com:rammusxu/action-demo.git\" , \"stargazers\" : 0 , \"stargazers_count\" : 0 , \"stargazers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/stargazers\" , \"statuses_url\" : \"https://api.github.com/repos/rammusxu/action-demo/statuses/{sha}\" , \"subscribers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscribers\" , \"subscription_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscription\" , \"svn_url\" : \"https://github.com/rammusxu/action-demo\" , \"tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/tags\" , \"teams_url\" : \"https://api.github.com/repos/rammusxu/action-demo/teams\" , \"trees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/trees{/sha}\" , \"updated_at\" : \"2020-08-24T06:36:17Z\" , \"url\" : \"https://github.com/rammusxu/action-demo\" , \"watchers\" : 0 , \"watchers_count\" : 0 }, \"sender\" : { \"avatar_url\" : \"https://avatars1.githubusercontent.com/u/4367069?v=4\" , \"events_url\" : \"https://api.github.com/users/RammusXu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/RammusXu/followers\" , \"following_url\" : \"https://api.github.com/users/RammusXu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/RammusXu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/RammusXu\" , \"id\" : 4367069 , \"login\" : \"RammusXu\" , \"node_id\" : \"MDQ6VXNlcjQzNjcwNjk=\" , \"organizations_url\" : \"https://api.github.com/users/RammusXu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/RammusXu/received_events\" , \"repos_url\" : \"https://api.github.com/users/RammusXu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/RammusXu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/RammusXu/subscriptions\" , \"type\" : \"User\" , \"url\" : \"https://api.github.com/users/RammusXu\" } }, \"server_url\" : \"https://github.com\" , \"api_url\" : \"https://api.github.com\" , \"graphql_url\" : \"https://api.github.com/graphql\" , \"workspace\" : \"/home/runner/work/action-demo/action-demo\" , \"action\" : \"run3\" , \"event_path\" : \"/home/runner/work/_temp/_github_workflow/event.json\" } cat $GITHUB_EVENT_PATH { \"after\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"base_ref\" : null , \"before\" : \"1c8b86a50a7bfb2d04984d5a67b414836aa04f22\" , \"commits\" : [ { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" } ], \"compare\" : \"https://github.com/rammusxu/action-demo/compare/1c8b86a50a7b...044271eda133\" , \"created\" : false , \"deleted\" : false , \"forced\" : false , \"head_commit\" : { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" }, \"organization\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"description\" : \"The SWAG Life\" , \"events_url\" : \"https://api.github.com/orgs/rammusxu/events\" , \"hooks_url\" : \"https://api.github.com/orgs/rammusxu/hooks\" , \"id\" : 36289044 , \"issues_url\" : \"https://api.github.com/orgs/rammusxu/issues\" , \"login\" : \"rammusxu\" , \"members_url\" : \"https://api.github.com/orgs/rammusxu/members{/member}\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"public_members_url\" : \"https://api.github.com/orgs/rammusxu/public_members{/member}\" , \"repos_url\" : \"https://api.github.com/orgs/rammusxu/repos\" , \"url\" : \"https://api.github.com/orgs/rammusxu\" }, \"pusher\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"RammusXu\" }, \"ref\" : \"refs/heads/github-pkg\" , \"repository\" : { \"archive_url\" : \"https://api.github.com/repos/rammusxu/action-demo/{archive_format}{/ref}\" , \"archived\" : false , \"assignees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/assignees{/user}\" , \"blobs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/blobs{/sha}\" , \"branches_url\" : \"https://api.github.com/repos/rammusxu/action-demo/branches{/branch}\" , \"clone_url\" : \"https://github.com/rammusxu/action-demo.git\" , \"collaborators_url\" : \"https://api.github.com/repos/rammusxu/action-demo/collaborators{/collaborator}\" , \"comments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/comments{/number}\" , \"commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/commits{/sha}\" , \"compare_url\" : \"https://api.github.com/repos/rammusxu/action-demo/compare/{base}...{head}\" , \"contents_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contents/{+path}\" , \"contributors_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contributors\" , \"created_at\" : 1564547431 , \"default_branch\" : \"master\" , \"deployments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/deployments\" , \"description\" : null , \"disabled\" : false , \"downloads_url\" : \"https://api.github.com/repos/rammusxu/action-demo/downloads\" , \"events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/events\" , \"fork\" : false , \"forks\" : 0 , \"forks_count\" : 0 , \"forks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/forks\" , \"full_name\" : \"rammusxu/action-demo\" , \"git_commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/commits{/sha}\" , \"git_refs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/refs{/sha}\" , \"git_tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/tags{/sha}\" , \"git_url\" : \"git://github.com/rammusxu/action-demo.git\" , \"has_downloads\" : true , \"has_issues\" : true , \"has_pages\" : true , \"has_projects\" : true , \"has_wiki\" : true , \"homepage\" : null , \"hooks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/hooks\" , \"html_url\" : \"https://github.com/rammusxu/action-demo\" , \"id\" : 199778774 , \"issue_comment_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/comments{/number}\" , \"issue_events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/events{/number}\" , \"issues_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues{/number}\" , \"keys_url\" : \"https://api.github.com/repos/rammusxu/action-demo/keys{/key_id}\" , \"labels_url\" : \"https://api.github.com/repos/rammusxu/action-demo/labels{/name}\" , \"language\" : \"Dockerfile\" , \"languages_url\" : \"https://api.github.com/repos/rammusxu/action-demo/languages\" , \"license\" : null , \"master_branch\" : \"master\" , \"merges_url\" : \"https://api.github.com/repos/rammusxu/action-demo/merges\" , \"milestones_url\" : \"https://api.github.com/repos/rammusxu/action-demo/milestones{/number}\" , \"mirror_url\" : null , \"name\" : \"action-demo\" , \"node_id\" : \"MDEwOlJlcG9zaXRvcnkxOTk3Nzg3NzQ=\" , \"notifications_url\" : \"https://api.github.com/repos/rammusxu/action-demo/notifications{?since,all,participating}\" , \"open_issues\" : 1 , \"open_issues_count\" : 1 , \"organization\" : \"rammusxu\" , \"owner\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"email\" : \"engineering@swag.live\" , \"events_url\" : \"https://api.github.com/users/rammusxu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/rammusxu/followers\" , \"following_url\" : \"https://api.github.com/users/rammusxu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/rammusxu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/rammusxu\" , \"id\" : 36289044 , \"login\" : \"rammusxu\" , \"name\" : \"rammusxu\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"organizations_url\" : \"https://api.github.com/users/rammusxu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/rammusxu/received_events\" , \"repos_url\" : \"https://api.github.com/users/rammusxu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/rammusxu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/rammusxu/subscriptions\" , \"type\" : \"Organization\" , \"url\" : \"https://api.github.com/users/rammusxu\" }, \"private\" : true , \"pulls_url\" : \"https://api.github.com/repos/rammusxu/action-demo/pulls{/number}\" , \"pushed_at\" : 1598262984 , \"releases_url\" : \"https://api.github.com/repos/rammusxu/action-demo/releases{/id}\" , \"size\" : 245 , \"ssh_url\" : \"git@github.com:rammusxu/action-demo.git\" , \"stargazers\" : 0 , \"stargazers_count\" : 0 , \"stargazers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/stargazers\" , \"statuses_url\" : \"https://api.github.com/repos/rammusxu/action-demo/statuses/{sha}\" , \"subscribers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscribers\" , \"subscription_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscription\" , \"svn_url\" : \"https://github.com/rammusxu/action-demo\" , \"tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/tags\" , \"teams_url\" : \"https://api.github.com/repos/rammusxu/action-demo/teams\" , \"trees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/trees{/sha}\" , \"updated_at\" : \"2020-08-24T06:36:17Z\" , \"url\" : \"https://github.com/rammusxu/action-demo\" , \"watchers\" : 0 , \"watchers_count\" : 0 }, \"sender\" : { \"avatar_url\" : \"https://avatars1.githubusercontent.com/u/4367069?v=4\" , \"events_url\" : \"https://api.github.com/users/RammusXu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/RammusXu/followers\" , \"following_url\" : \"https://api.github.com/users/RammusXu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/RammusXu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/RammusXu\" , \"id\" : 4367069 , \"login\" : \"RammusXu\" , \"node_id\" : \"MDQ6VXNlcjQzNjcwNjk=\" , \"organizations_url\" : \"https://api.github.com/users/RammusXu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/RammusXu/received_events\" , \"repos_url\" : \"https://api.github.com/users/RammusXu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/RammusXu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/RammusXu/subscriptions\" , \"type\" : \"User\" , \"url\" : \"https://api.github.com/users/RammusXu\" } } env LEIN_HOME = /usr/local/lib/lein M2_HOME = /usr/share/apache-maven-3.6.3 GOROOT_1_11_X64 = /opt/hostedtoolcache/go/1.11.13/x64 ANDROID_HOME = /usr/local/lib/android/sdk JAVA_HOME_11_X64 = /usr/lib/jvm/adoptopenjdk-11-hotspot-amd64 ImageVersion = 20200817 .1 AGENT_TOOLSDIRECTORY = /opt/hostedtoolcache LANG = C.UTF-8 AZURE_EXTENSION_DIR = /opt/az/azcliextensions POWERSHELL_DISTRIBUTION_CHANNEL = GitHub-Actions-ubuntu18 GITHUB_API_URL = https://api.github.com INVOCATION_ID = dcb35bf82e314cdb9caa479c88a6c37e BOOST_ROOT_1_72_0 = /opt/hostedtoolcache/boost/1.72.0/x64 JAVA_HOME_12_X64 = /usr/lib/jvm/adoptopenjdk-12-hotspot-amd64 ANDROID_SDK_ROOT = /usr/local/lib/android/sdk RUNNER_TOOL_CACHE = /opt/hostedtoolcache SWIFT_PATH = /usr/share/swift/usr/bin JAVA_HOME = /usr/lib/jvm/adoptopenjdk-8-hotspot-amd64 JAVA_TOOL_OPTIONS = -Dfile.encoding = UTF8 RUNNER_TRACKING_ID = github_0e3e53f2-73ff-4e23-8e4f-52cb37f62b82 DOTNET_MULTILEVEL_LOOKUP = \"0\" GITHUB_REPOSITORY_OWNER = rammusxu GITHUB_ACTIONS = true DOTNET_SKIP_FIRST_TIME_EXPERIENCE = \"1\" CI = true DOTNET_NOLOGO = \"1\" USER = runner GITHUB_HEAD_REF = GITHUB_ACTOR = RammusXu GITHUB_ACTION = run2 GRADLE_HOME = /usr/share/gradle PWD = /home/runner/work/action-demo/action-demo ImageOS = ubuntu18 HOME = /home/runner GOROOT = /opt/hostedtoolcache/go/1.14.7/x64 JOURNAL_STREAM = 9 :31545 GOROOT_1_14_X64 = /opt/hostedtoolcache/go/1.14.7/x64 JAVA_HOME_8_X64 = /usr/lib/jvm/adoptopenjdk-8-hotspot-amd64 RUNNER_TEMP = /home/runner/work/_temp GOROOT_1_15_X64 = /opt/hostedtoolcache/go/1.15.0/x64 CONDA = /usr/share/miniconda GOROOT_1_13_X64 = /opt/hostedtoolcache/go/1.13.15/x64 BOOST_ROOT_1_69_0 = /opt/hostedtoolcache/boost/1.69.0/x64 DEBIAN_FRONTEND = noninteractive RUNNER_WORKSPACE = /home/runner/work/action-demo GITHUB_REF = refs/heads/github-pkg GITHUB_SHA = 044271eda133bb9944f4aa7119bc661a8c1e9900 GITHUB_RUN_ID = 221813086 GITHUB_SERVER_URL = https://github.com GOROOT_1_12_X64 = /opt/hostedtoolcache/go/1.12.17/x64 GECKOWEBDRIVER = /usr/local/share/gecko_driver DEPLOYMENT_BASEPATH = /opt/runner GITHUB_EVENT_PATH = /home/runner/work/_temp/_github_workflow/event.json CHROMEWEBDRIVER = /usr/local/share/chrome_driver HOMEBREW_REPOSITORY = \"/home/linuxbrew/.linuxbrew/Homebrew\" GITHUB_GRAPHQL_URL = https://api.github.com/graphql RUNNER_OS = Linux GITHUB_BASE_REF = VCPKG_INSTALLATION_ROOT = /usr/local/share/vcpkg GITHUB_JOB = show-env PERFLOG_LOCATION_SETTING = RUNNER_PERFLOG JAVA_HOME_7_X64 = /usr/lib/jvm/zulu-7-azure-amd64 RUNNER_USER = runner SHLVL = 1 HOMEBREW_PREFIX = \"/home/linuxbrew/.linuxbrew\" GITHUB_REPOSITORY = rammusxu/action-demo GITHUB_EVENT_NAME = push LEIN_JAR = /usr/local/lib/lein/self-installs/leiningen-2.9.4-standalone.jar GITHUB_RUN_NUMBER = 166 RUNNER_PERFLOG = /home/runner/perflog GITHUB_WORKFLOW = show-env ANT_HOME = /usr/share/ant PATH = /home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/usr/share/rust/.cargo/bin:/home/runner/.config/composer/vendor/bin:/home/runner/.dotnet/tools:/snap/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games SELENIUM_JAR_PATH = /usr/share/java/selenium-server-standalone.jar GITHUB_WORKSPACE = /home/runner/work/action-demo/action-demo CHROME_BIN = /usr/bin/google-chrome HOMEBREW_CELLAR = \"/home/linuxbrew/.linuxbrew/Cellar\" _ = /usr/bin/env 2020-05-18 Github workflow env on pull request \u00b6 LEIN_HOME = /usr/local/lib/lein M2_HOME = /usr/share/apache-maven-3.6.3 GOROOT_1_11_X64 = /usr/local/go1.11 ANDROID_HOME = /usr/local/lib/android/sdk JAVA_HOME_11_X64 = /usr/lib/jvm/zulu-11-azure-amd64 ImageVersion = 20200430 .1 AGENT_TOOLSDIRECTORY = /opt/hostedtoolcache LANG = C.UTF-8 AZURE_EXTENSION_DIR = /opt/az/azcliextensions POWERSHELL_DISTRIBUTION_CHANNEL = GitHub-Actions-ubuntu18 INVOCATION_ID = 68f93b53277249cc8519235cea6396c9 BOOST_ROOT_1_72_0 = /usr/local/share/boost/1.72.0 JAVA_HOME_12_X64 = /usr/lib/jvm/zulu-12-azure-amd64 ANDROID_SDK_ROOT = /usr/local/lib/android/sdk RUNNER_TOOL_CACHE = /opt/hostedtoolcache SWIFT_PATH = /usr/share/swift/usr/bin JAVA_HOME = /usr/lib/jvm/zulu-8-azure-amd64 RUNNER_TRACKING_ID = github_884bb8e2-7879-4810-9c99-0192e58487e7 GITHUB_REPOSITORY_OWNER = rammusxu GITHUB_ACTIONS = true DOTNET_SKIP_FIRST_TIME_EXPERIENCE = \"1\" CI = true USER = runner GITHUB_HEAD_REF = try-deploy GITHUB_ACTOR = RammusXu GITHUB_ACTION = run GRADLE_HOME = /usr/share/gradle PWD = /home/runner/work/action-demo/action-demo ImageOS = ubuntu18 HOME = /home/runner GOROOT = /usr/local/go1.14 JOURNAL_STREAM = 9 :31391 GOROOT_1_14_X64 = /usr/local/go1.14 JAVA_HOME_8_X64 = /usr/lib/jvm/zulu-8-azure-amd64 RUNNER_TEMP = /home/runner/work/_temp CONDA = /usr/share/miniconda GOROOT_1_13_X64 = /usr/local/go1.13 BOOST_ROOT_1_69_0 = /usr/local/share/boost/1.69.0 DEBIAN_FRONTEND = noninteractive RUNNER_WORKSPACE = /home/runner/work/action-demo GITHUB_REF = refs/pull/37/merge GITHUB_SHA = aadf39660fb8c0f87565bc08db9403f5197a8de6 GITHUB_RUN_ID = 107752396 GOROOT_1_12_X64 = /usr/local/go1.12 GECKOWEBDRIVER = /usr/local/share/gecko_driver DEPLOYMENT_BASEPATH = /opt/runner GITHUB_EVENT_PATH = /home/runner/work/_temp/_github_workflow/event.json CHROMEWEBDRIVER = /usr/local/share/chrome_driver HOMEBREW_REPOSITORY = \"/home/linuxbrew/.linuxbrew/Homebrew\" RUNNER_OS = Linux GITHUB_BASE_REF = master VCPKG_INSTALLATION_ROOT = /usr/local/share/vcpkg GITHUB_JOB = test PERFLOG_LOCATION_SETTING = RUNNER_PERFLOG JAVA_HOME_7_X64 = /usr/lib/jvm/zulu-7-azure-amd64 RUNNER_USER = runner SHLVL = 1 HOMEBREW_PREFIX = \"/home/linuxbrew/.linuxbrew\" GITHUB_REPOSITORY = rammusxu/action-demo GITHUB_EVENT_NAME = pull_request LEIN_JAR = /usr/local/lib/lein/self-installs/leiningen-2.9.3-standalone.jar GITHUB_RUN_NUMBER = 5 RUNNER_PERFLOG = /home/runner/perflog GITHUB_WORKFLOW = .github/workflows/update-status.yaml ANT_HOME = /usr/share/ant PATH = /usr/share/rust/.cargo/bin:/home/runner/.config/composer/vendor/bin:/home/runner/.dotnet/tools:/snap/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin SELENIUM_JAR_PATH = /usr/share/java/selenium-server-standalone.jar GITHUB_WORKSPACE = /home/runner/work/action-demo/action-demo CHROME_BIN = /usr/bin/google-chrome HOMEBREW_CELLAR = \"/home/linuxbrew/.linuxbrew/Cellar\" 2Z _ = /usr/bin/env 2020-03-11 Use a self build action \u00b6 /usr/bin/docker run --name e87b528978e939d04c5cabae17f516da08bb2a_79b912 --label e87b52 --workdir /github/workspace --rm -e INPUT_ARGS -e INPUT_MY_VAR -e INPUT_LOWER_VAR -e INPUT_WHO-TO-GREET -e INPUT_NAME -e HOME -e GITHUB_REF -e GITHUB_SHA -e GITHUB_REPOSITORY -e GITHUB_RUN_ID -e GITHUB_RUN_NUMBER -e GITHUB_ACTOR -e GITHUB_WORKFLOW -e GITHUB_HEAD_REF -e GITHUB_BASE_REF -e GITHUB_EVENT_NAME -e GITHUB_WORKSPACE -e GITHUB_ACTION -e GITHUB_EVENT_PATH -e RUNNER_OS -e RUNNER_TOOL_CACHE -e RUNNER_TEMP -e RUNNER_WORKSPACE -e ACTIONS_RUNTIME_URL -e ACTIONS_RUNTIME_TOKEN -e ACTIONS_CACHE_URL -e GITHUB_ACTIONS = true -v \"/var/run/docker.sock\" : \"/var/run/docker.sock\" -v \"/home/runner/work/_temp/_github_home\" : \"/github/home\" -v \"/home/runner/work/_temp/_github_workflow\" : \"/github/workflow\" -v \"/home/runner/work/action-demo/action-demo\" : \"/github/workspace\" e87b52:8978e939d04c5cabae17f516da08bb2a env Reference \u00b6 https://help.github.com/en/actions/reference https://github.com/actions/toolkit/tree/master/packages/github https://github.com/actions/github-script https://octokit.github.io/rest.js/#usage bin in Ubuntu 18.04 https://github.com/actions/virtual-environments/blob/master/images/linux/Ubuntu1804-README.md","title":"Github Action"},{"location":"snippets/github-action/#github-action","text":"Github Actions(CI/CD) tricks that official documents didn't mention. This post including hints, tips, snippet, cheatsheet, troubleshooting, notes, how-to.","title":"Github Action"},{"location":"snippets/github-action/#starter","text":"on : push : jobs : test : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Run tests run : | echo hi","title":"Starter"},{"location":"snippets/github-action/#on-trigger-event","text":"on : push : branches : - \"master\" - \"**\" tags : - \"**\" paths : - src/** - Dockerfile pull_request : branches : - master repository_dispatch : types : [ rammus_post ] Important pull_request.branches is base on ref , not head_ref","title":"On trigger event"},{"location":"snippets/github-action/#environments-and-variables","text":"","title":"Environments and variables"},{"location":"snippets/github-action/#pass-variables","text":"echo ::set-output name = message:: $output_message echo \"action_state=yellow\" >> $GITHUB_ENV # Deprecated. ref: https://github.blog/changelog/2020-10-01-github-actions-deprecating-set-env-and-add-path-commands/ echo ::set-env name = action_state::yellow","title":"Pass variables"},{"location":"snippets/github-action/#use-variables","text":"GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} GITHUB_TOKEN : ${{ env.ACTION_STATE }} PR_COMMENT : ${{ steps.message.outputs.message }} PR_COMMENT_URL : ${{ github.event.pull_request.comments_url }} PAYLOAD_ACTOR : ${{ github.event.client_payload.actor }}","title":"Use variables"},{"location":"snippets/github-action/#use-github_actor-as-git-commit-author-and-using-github-avator","text":"https://help.github.com/en/github/setting-up-and-managing-your-github-user-account/setting-your-commit-email-address git config --global user.name \"${GITHUB_ACTOR}\" git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" remote_repo=\"https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${GITHUB_REPOSITORY}.git\" git remote add origin \"${remote_repo}\"","title":"Use GITHUB_ACTOR as git commit author and using github avator"},{"location":"snippets/github-action/#get-commit-author-information","text":"This is only for push event AUTHOR_NAME : ${{ github.event.head_commit.author.name }} AUTHOR_EMAIL : ${{ github.event.head_commit.author.email }}","title":"Get commit author information"},{"location":"snippets/github-action/#customize-docker-action","text":"name : 'Update Status' description : 'Update status' inputs : state : description : 'Option: success, failure' required : false default : 'success' auth_token : description : 'Auth token used to API' required : true default : \"${{ github.token }}\" pull_sha : description : 'Commit SHA' default : \"${{ github.event.pull_request.head.sha}}\" required : false push_sha : description : 'Commit SHA' required : false default : \"${{ github.sha }}\" if [[ $GITHUB_EVENT_NAME == 'pull_request' ]] ; then COMMIT_SHA = $INPUT_PULL_SHA else COMMIT_SHA = $INPUT_PUSH_SHA","title":"Customize docker action"},{"location":"snippets/github-action/#if-condition","text":"if : contains(github.ref, 'refs/tags') if : contains(github.event.issue.title, 'Update APK') if : steps.git-diff.outputs.is-diff if : steps.set-env.outputs.message == 'hello' if : github.ref != 'refs/heads/master' if : github.event.action == 'dispatch_rammus_customize_action_type' if : github.event.issue.pull_request if : github.event_name == 'pull_request' && contains(github.head_ref, 'update-app')","title":"if condition"},{"location":"snippets/github-action/#pull_request","text":"","title":"pull_request"},{"location":"snippets/github-action/#when-specific-event-type","text":"if : github.event_name == 'pull_request' && github.event.action == 'unassigned'","title":"when specific event type"},{"location":"snippets/github-action/#when-branch-name-is","text":"if : github.event_name == 'pull_request' && contains(github.head_ref, 'my-feature-branch')","title":"when branch name is"},{"location":"snippets/github-action/#when-merged","text":"on : pull_request : types : [ closed ] jobs : merged : if : github.event.pull_request.merged == true","title":"when merged"},{"location":"snippets/github-action/#job-syntax","text":"","title":"Job syntax"},{"location":"snippets/github-action/#wait-other-jobs-finish","text":"jobs: job1: job2: needs: job1 job3: needs: [job1, job2]","title":"Wait other jobs finish"},{"location":"snippets/github-action/#setting","text":"ACTIONS_RUNNER_DEBUG : true","title":"Setting"},{"location":"snippets/github-action/#build-an-action","text":"","title":"Build an action"},{"location":"snippets/github-action/#docker-action-example","text":"# action.yml name : 'Hello World' description : 'Greet someone and record the time' inputs : who-to-greet : # id of input description : 'Who to greet' required : true default : 'World' outputs : time : # id of output description : 'The time we greeted you' runs : using : 'docker' image : 'Dockerfile' args : - ${{ inputs.who-to-greet }}","title":"Docker Action Example"},{"location":"snippets/github-action/#composite-multiple-steps-action-example","text":"name : 'Hello World' description : 'Greet someone' inputs : who-to-greet : # id of input description : 'Who to greet' required : true default : 'World' outputs : random-number : description : \"Random number\" value : ${{ steps.random-number-generator.outputs.random-id }} runs : using : \"composite\" steps : - run : echo Hello ${{ inputs.who-to-greet }}. shell : bash - id : random-number-generator run : echo \"::set-output name=random-id::$(echo $RANDOM)\" shell : bash - run : ${{ github.action_path }}/goodbye.sh shell : bash","title":"Composite (Multiple steps) Action Example"},{"location":"snippets/github-action/#get-input-as-environemnt-in-docker","text":"# action.yaml inputs : who-to-greet : # workflow.yaml - uses : ./actions/my-action with : who-to-greet : rammus # entrypoint.sh echo INPUTS_WHO_TO_GREET","title":"Get input as environemnt in Docker"},{"location":"snippets/github-action/#entrypoint-need-to-be-abolute-path","text":"Warning When uses: ./actions/my-action Workflow will mount workspace --workdir /github/workspace COPY ./app.py / ENTRYPOINT python /app.py","title":"ENTRYPOINT need to be abolute path"},{"location":"snippets/github-action/#awesome-actions","text":"","title":"Awesome Actions"},{"location":"snippets/github-action/#manuallycustomize-trigger-a-workflow","text":"https://github.blog/changelog/2020-07-06-github-actions-manual-triggers-with-workflow_dispatch/ on : workflow_dispatch : inputs : logLevel : description : 'Log level' required : true default : 'warning' tags : description : 'Test scenario tags' jobs : printInputs : runs-on : ubuntu-latest steps : - run : | echo \"Log level: ${{ github.event.inputs.logLevel }}\" echo \"Tags: ${{ github.event.inputs.tags }}\"","title":"Manually/Customize trigger a workflow"},{"location":"snippets/github-action/#customize-action-type-with-http-post-method","text":"on : repository_dispatch : types : [ rammus_post ] jobs : rammus_job : env : ACTOR : ${{ github.event.client_payload.actor }} if : github.event.action == 'rammus_post' And you can send a post request like: INPUT_GITHUB_TOKEN = INPUT_COMMENT_URL = \"https://api.github.com/repos/<owner>/<repo>/dispatches\" curl -H \"Authorization: token $INPUT_GITHUB_TOKEN \" \\ -H \"Accept: application/vnd.github.everest-preview+json\" \\ -d '{\"event_type\":\"rammus_post\",\"client_payload\":{\"new_version_image\":\"echo-server:96b2166\", \"new_version_sha\":\"96b2166\",\"actor\":\"Rammus Xu\"}}' \\ -XPOST $INPUT_COMMENT_URL","title":"Customize action type with http post method"},{"location":"snippets/github-action/#docekr-build-and-push-to-ghcrio-when-pushing-a-git-tag","text":"name : Tag on : push : tags : - \"**\" jobs : build : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Set Env run : | echo \"BUILD_TAG=${GITHUB_REF/refs\\/tags\\//}\" >> $GITHUB_ENV echo \"BUILD_SHA=${GITHUB_SHA:0:7}\" >> $GITHUB_ENV - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Docker Login # uses: docker/login-action@f3364599c6aa293cdc2b8391b1b56d0c30e45c8a uses : docker/login-action@v1.8.0 with : registry : ghcr.io username : ${{ secrets.GHCR_USERNAME }} password : ${{ secrets.GHCR_PASSWORD }} - name : Build and push Docker images # uses: docker/build-push-action@4a531fa5a603bab87dfa56578bd82b28508c9547 uses : docker/build-push-action@v2.2.2 with : context : \".\" tags : | ghcr.io/${{ github.repository }}:${{ env.BUILD_TAG }} ghcr.io/${{ github.repository }}:${{ env.BUILD_SHA }} push : true","title":"Docekr build and push to ghcr.io when pushing a git tag"},{"location":"snippets/github-action/#docker-login","text":"- name : Docker Login - docker.pkg.github.com uses : swaglive/actions/docker/login@944b742 with : password : ${{ secrets.GHR_PASSWORD }} username : ${{ secrets.GHR_USERNAME }} url : docker.pkg.github.com - name : Docker Login - docker.pkg.github.com if : contains(github.ref, 'tags') env : DOCKER_PASSWORD : ${{ secrets.GITHUB_TOKEN }} run : echo $DOCKER_PASSWORD | docker login -u $GITHUB_ACTOR --password-stdin docker.pkg.github.com","title":"Docker login"},{"location":"snippets/github-action/#docker-login-and-copy-config-to-default-containers-workspace","text":"Note github runner will mount /home/runner/work/_temp/_github_home\":\"/github/home when we use a docker action. That means we can't use the credential directly in next steps. Only if you use a docker contain step. Since id: generate-mirror-list need docker credentials and run on default container, credentials should be copied to default container's home. And a docker action must run as root. Therefore, it needs to be sudo in a default container. - name : Docker Login - docker.pkg.github.com uses : swaglive/actions/docker/login@944b742 with : password : ${{ secrets.GHR_PASSWORD }} username : ${{ secrets.GHR_USERNAME }} url : docker.pkg.github.com - name : Do something in default container's workspace run : | sudo cp -R /home/runner/work/_temp/_github_home/.docker ~ sudo chown -R $(whoami) ~/.docker docker pull docker.pkg.github.com/swaglive/dockerfiles/kubectl:1.17","title":"Docker login and copy config to default container's workspace"},{"location":"snippets/github-action/#cache-node_modules","text":"- name : Get yarn cache directory path id : yarn-cache-dir-path run : echo \"::set-output name=dir::$(yarn cache dir)\" - uses : actions/cache@v2 with : path : ${{ steps.yarn-cache-dir-path.outputs.dir }} key : ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }} restore-keys : | ${{ runner.os }}-yarn-","title":"Cache node_modules"},{"location":"snippets/github-action/#fetch-private-submodule","text":"PAT = personal access token actions/checkout@v2 fixed git@github.com problem jobs : deploy : runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 with : fetch-depth : 0 submodules : true token : ${{ secrets.PAT }} - name : Fix submodules run : echo -e '[url \"https://github.com/\"]\\n insteadOf = \"git@github.com:\"' >> ~/.gitconfig - name : Checkout uses : actions/checkout@v1 with : fetch-depth : 0 submodules : true token : ${{ secrets.PAT }}","title":"Fetch private submodule"},{"location":"snippets/github-action/#create-pull-request","text":"- name : Create Pull Request if : steps.create-branch.outputs.branch_name uses : actions/github-script@v3 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.pulls.create({ owner: 'swaglive', repo: 'action-demo', title: '[Action] ${{ steps.create-branch.outputs.branch_name }}', head: '${{ steps.create-branch.outputs.branch_name }}', base: 'master' }) - name : Create Pull Request if : steps.create-branch.outputs.branch_name uses : actions/github-script@v3 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.pulls.create({ ...context.repo, title: '[Action] ${{ steps.create-branch.outputs.branch_name }}', body: `Created by \\`${ process.env.GITHUB_ACTOR }\\``, head: '${{ steps.create-branch.outputs.branch_name }}', base: 'master' })","title":"Create pull request"},{"location":"snippets/github-action/#commit-and-push-and-create-pull-request","text":"- name : Set environments run : echo \"NEW_BRANCH=update-config-$(date +%Y-%m-%d_%H%M%S-utc)\" >> $GITHUB_ENV - name : Configure git run : | git config --global user.name \"${GITHUB_ACTOR}\" git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" - name : Commit run : git commit -a -m \"Update config.json by ${GITHUB_ACTOR}\" - name : Git push run : git push origin HEAD:${NEW_BRANCH} - name : Create Pull Request uses : actions/github-script@v3 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.pulls.create({ ...context.repo, title: '${{ env.NEW_BRANCH }}', body: `Created by \\`${ process.env.GITHUB_ACTOR }\\``, head: '${{ env.NEW_BRANCH }}', base: 'master' })","title":"Commit and push and create pull request"},{"location":"snippets/github-action/#close-issue-when-title-contains-specific-string","text":"name : issue-opened on : issues : types : [ opened ] jobs : debug : runs-on : ubuntu-latest if : contains(github.event.issue.title, 'Update APK') steps : - name : Close issue uses : actions/github-script@0.8.0 with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | github.issues.update({ ...context.repo, issue_number: context.issue.number, state: 'closed' }) github.issues.createComment({ ...context.repo, issue_number: context.issue.number, body: 'Close this!' });","title":"Close issue when title contains specific string"},{"location":"snippets/github-action/#create-a-comment-in-pull-request","text":"- name : Notify Results in Pull Request if : steps.generate-mirror-list.outputs.images uses : actions/github-script@0.3.0 with : github-token : ${{ secrets.GITHUB_TOKEN }} images : ${{ steps.generate-mirror-list.outputs.images }} script : | var body = \"## I mirrored something for you\" process.env.INPUT_IMAGES.split(' ').forEach(function(image){ let [source, target] = image.split('@') body = `${body}\\r\\n- \\`${source}\\` -> \\`${target}\\`` }) github.issues.createComment({ ...context.repo, issue_number: context.payload.number, body: body, })","title":"Create a comment in pull request"},{"location":"snippets/github-action/#deploy-mkdocs-to-gh-pages","text":"name : Publish on : push : branches : - master jobs : deploy : name : Deploy docs runs-on : ubuntu-latest steps : - name : Checkout master uses : actions/checkout@v1 - name : Deploy docs uses : mhausenblas/mkdocs-deploy-gh-pages@1.11 env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }}","title":"Deploy mkdocs to gh-pages"},{"location":"snippets/github-action/#get-other-step-output-as-enviroment-in-github-script","text":"jobs : debug : runs-on : ubuntu-latest steps : - id : update run : echo ::set-output name=message::okok - name : js uses : actions/github-script@0.8.0 env : MESSAGE : ${{ steps.update.outputs.message }} with : github-token : ${{ secrets.GITHUB_TOKEN }} script : | var message = process.env.MESSAGE if (message !== undefined){ message == 'in' } else { message == 'else' } console.log(message)","title":"Get other step output as enviroment in github-script"},{"location":"snippets/github-action/#docker-build-and-push-action","text":"name : docker-publish on : push : jobs : docker-publish : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 # Build base image - uses : docker/build-push-action@v1 with : username : _json_key password : ${{ secrets.GOOGLE_SA_GCR_JSON }} registry : asia.gcr.io repository : rammusxu/${{ github.event.repository.name }} tags : base target : base cache_froms : rammusxu/${{ github.event.repository.name }}:base # Build app image - uses : docker/build-push-action@v1 with : username : _json_key password : ${{ secrets.GOOGLE_SA_GCR_JSON }} registry : asia.gcr.io repository : rammusxu/${{ github.event.repository.name }} tags : ${{ github.sha }} cache_froms : rammusxu/${{ github.event.repository.name }}:${{ github.sha }} tag_with_ref : true","title":"Docker build and push action"},{"location":"snippets/github-action/#faq","text":"","title":"FAQ"},{"location":"snippets/github-action/#whats-logic-used-in-pushbranches-and-pushpaths","text":"It's AND logic. It needs meet both conditions. Push to branch: dev** Something under echo-box folder changed on: push: branches: - \"dev**\" paths: - 'echo-box/**'","title":"What's logic used in push.branches and push.paths"},{"location":"snippets/github-action/#how-to-activate-google-service-account-in-action","text":"Should be echo '${{ secrets.GOOGLE_SA_JSON }}' \u2705 debug2 : runs-on : ubuntu-latest steps : - run : echo '${{ secrets.GOOGLE_SA_JSON }}' > sa.json - run : gcloud auth activate-service-account --key-file=sa.json - run : gsutil ls gs://rammus.dev \u274c debug : runs-on : ubuntu-latest steps : - run : echo \"${{ secrets.GOOGLE_SA_JSON }}\" > sa.json - run : gcloud auth activate-service-account --key-file=sa.json - run : gsutil ls gs://rammus.dev","title":"How to activate google service account in action"},{"location":"snippets/github-action/#cant-load-secrets-in-actionyaml","text":"\u274c # action.yaml inputs : kube_config : description : 'kubernetes config file' default : ${{ secrets.KUBE_CONFIG }} description : 'kubernetes config file. ex. ${{ secrets.KUBE_CONFIG }}'","title":"Can't load secrets in action.yaml"},{"location":"snippets/github-action/#but-githubtoken-can-be-get-in-actionyaml","text":"\u2705 # action.yaml inputs : auth_token : description : 'Auth token used to API' required : true default : \"${{ github.token }}\"","title":"But ${{ github.token }} can be get in action.yaml"},{"location":"snippets/github-action/#misc","text":"","title":"Misc"},{"location":"snippets/github-action/#ios-app-build","text":"Bitrise Standard: Available in Developer, Org Standard, Velocity plan 2vCPU @ 2.7 GHz, 4 GB RAM pricing $90 / Month Elite: Available in Org Elite, Velocity plan 4vCPU @ 3.5 GHz, 8 GB RAM pricing $270 / Month Github Action 2 vCPU @ 2.60GHz, 7 GB RAM princing $0.08 / minute","title":"iOS App Build"},{"location":"snippets/github-action/#build-status","text":"Clickable [ ![Publish](https://github.com/RammusXu/toolkit/workflows/Publish/badge.svg)](https://github.com/RammusXu/toolkit) Unclickable ![Publish](https://github.com/RammusXu/toolkit/workflows/Publish/badge.svg) Clickable: Unclickable:","title":"Build status"},{"location":"snippets/github-action/#env-sample","text":"","title":"Env Sample"},{"location":"snippets/github-action/#get-environments-in-action","text":"jobs : show-env : runs-on : ubuntu-latest steps : - run : cat $GITHUB_EVENT_PATH - run : echo ${{ github.event_name }} - run : echo ${{ github.event.action }} - run : env - name : Dump GitHub context env : GITHUB_CONTEXT : ${{ toJson(github) }} run : echo \"$GITHUB_CONTEXT\"","title":"Get environments in action"},{"location":"snippets/github-action/#2020-09-01-github-context-on-push-branch-event","text":"${{ toJson(github) }} { \"token\" : \"***\" , \"job\" : \"show-env\" , \"ref\" : \"refs/heads/github-pkg\" , \"sha\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"repository\" : \"rammusxu/action-demo\" , \"repository_owner\" : \"rammusxu\" , \"repositoryUrl\" : \"git://github.com/rammusxu/action-demo.git\" , \"run_id\" : \"221813086\" , \"run_number\" : \"166\" , \"actor\" : \"RammusXu\" , \"workflow\" : \"show-env\" , \"head_ref\" : \"\" , \"base_ref\" : \"\" , \"event_name\" : \"push\" , \"event\" : { \"after\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"base_ref\" : null , \"before\" : \"1c8b86a50a7bfb2d04984d5a67b414836aa04f22\" , \"commits\" : [ { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" } ], \"compare\" : \"https://github.com/rammusxu/action-demo/compare/1c8b86a50a7b...044271eda133\" , \"created\" : false , \"deleted\" : false , \"forced\" : false , \"head_commit\" : { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" }, \"organization\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"description\" : \"The SWAG Life\" , \"events_url\" : \"https://api.github.com/orgs/rammusxu/events\" , \"hooks_url\" : \"https://api.github.com/orgs/rammusxu/hooks\" , \"id\" : 36289044 , \"issues_url\" : \"https://api.github.com/orgs/rammusxu/issues\" , \"login\" : \"rammusxu\" , \"members_url\" : \"https://api.github.com/orgs/rammusxu/members{/member}\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"public_members_url\" : \"https://api.github.com/orgs/rammusxu/public_members{/member}\" , \"repos_url\" : \"https://api.github.com/orgs/rammusxu/repos\" , \"url\" : \"https://api.github.com/orgs/rammusxu\" }, \"pusher\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"RammusXu\" }, \"ref\" : \"refs/heads/github-pkg\" , \"repository\" : { \"archive_url\" : \"https://api.github.com/repos/rammusxu/action-demo/{archive_format}{/ref}\" , \"archived\" : false , \"assignees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/assignees{/user}\" , \"blobs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/blobs{/sha}\" , \"branches_url\" : \"https://api.github.com/repos/rammusxu/action-demo/branches{/branch}\" , \"clone_url\" : \"https://github.com/rammusxu/action-demo.git\" , \"collaborators_url\" : \"https://api.github.com/repos/rammusxu/action-demo/collaborators{/collaborator}\" , \"comments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/comments{/number}\" , \"commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/commits{/sha}\" , \"compare_url\" : \"https://api.github.com/repos/rammusxu/action-demo/compare/{base}...{head}\" , \"contents_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contents/{+path}\" , \"contributors_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contributors\" , \"created_at\" : 1564547431 , \"default_branch\" : \"master\" , \"deployments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/deployments\" , \"description\" : null , \"disabled\" : false , \"downloads_url\" : \"https://api.github.com/repos/rammusxu/action-demo/downloads\" , \"events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/events\" , \"fork\" : false , \"forks\" : 0 , \"forks_count\" : 0 , \"forks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/forks\" , \"full_name\" : \"rammusxu/action-demo\" , \"git_commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/commits{/sha}\" , \"git_refs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/refs{/sha}\" , \"git_tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/tags{/sha}\" , \"git_url\" : \"git://github.com/rammusxu/action-demo.git\" , \"has_downloads\" : true , \"has_issues\" : true , \"has_pages\" : true , \"has_projects\" : true , \"has_wiki\" : true , \"homepage\" : null , \"hooks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/hooks\" , \"html_url\" : \"https://github.com/rammusxu/action-demo\" , \"id\" : 199778774 , \"issue_comment_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/comments{/number}\" , \"issue_events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/events{/number}\" , \"issues_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues{/number}\" , \"keys_url\" : \"https://api.github.com/repos/rammusxu/action-demo/keys{/key_id}\" , \"labels_url\" : \"https://api.github.com/repos/rammusxu/action-demo/labels{/name}\" , \"language\" : \"Dockerfile\" , \"languages_url\" : \"https://api.github.com/repos/rammusxu/action-demo/languages\" , \"license\" : null , \"master_branch\" : \"master\" , \"merges_url\" : \"https://api.github.com/repos/rammusxu/action-demo/merges\" , \"milestones_url\" : \"https://api.github.com/repos/rammusxu/action-demo/milestones{/number}\" , \"mirror_url\" : null , \"name\" : \"action-demo\" , \"node_id\" : \"MDEwOlJlcG9zaXRvcnkxOTk3Nzg3NzQ=\" , \"notifications_url\" : \"https://api.github.com/repos/rammusxu/action-demo/notifications{?since,all,participating}\" , \"open_issues\" : 1 , \"open_issues_count\" : 1 , \"organization\" : \"rammusxu\" , \"owner\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"email\" : \"engineering@swag.live\" , \"events_url\" : \"https://api.github.com/users/rammusxu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/rammusxu/followers\" , \"following_url\" : \"https://api.github.com/users/rammusxu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/rammusxu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/rammusxu\" , \"id\" : 36289044 , \"login\" : \"rammusxu\" , \"name\" : \"rammusxu\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"organizations_url\" : \"https://api.github.com/users/rammusxu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/rammusxu/received_events\" , \"repos_url\" : \"https://api.github.com/users/rammusxu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/rammusxu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/rammusxu/subscriptions\" , \"type\" : \"Organization\" , \"url\" : \"https://api.github.com/users/rammusxu\" }, \"private\" : true , \"pulls_url\" : \"https://api.github.com/repos/rammusxu/action-demo/pulls{/number}\" , \"pushed_at\" : 1598262984 , \"releases_url\" : \"https://api.github.com/repos/rammusxu/action-demo/releases{/id}\" , \"size\" : 245 , \"ssh_url\" : \"git@github.com:rammusxu/action-demo.git\" , \"stargazers\" : 0 , \"stargazers_count\" : 0 , \"stargazers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/stargazers\" , \"statuses_url\" : \"https://api.github.com/repos/rammusxu/action-demo/statuses/{sha}\" , \"subscribers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscribers\" , \"subscription_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscription\" , \"svn_url\" : \"https://github.com/rammusxu/action-demo\" , \"tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/tags\" , \"teams_url\" : \"https://api.github.com/repos/rammusxu/action-demo/teams\" , \"trees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/trees{/sha}\" , \"updated_at\" : \"2020-08-24T06:36:17Z\" , \"url\" : \"https://github.com/rammusxu/action-demo\" , \"watchers\" : 0 , \"watchers_count\" : 0 }, \"sender\" : { \"avatar_url\" : \"https://avatars1.githubusercontent.com/u/4367069?v=4\" , \"events_url\" : \"https://api.github.com/users/RammusXu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/RammusXu/followers\" , \"following_url\" : \"https://api.github.com/users/RammusXu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/RammusXu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/RammusXu\" , \"id\" : 4367069 , \"login\" : \"RammusXu\" , \"node_id\" : \"MDQ6VXNlcjQzNjcwNjk=\" , \"organizations_url\" : \"https://api.github.com/users/RammusXu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/RammusXu/received_events\" , \"repos_url\" : \"https://api.github.com/users/RammusXu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/RammusXu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/RammusXu/subscriptions\" , \"type\" : \"User\" , \"url\" : \"https://api.github.com/users/RammusXu\" } }, \"server_url\" : \"https://github.com\" , \"api_url\" : \"https://api.github.com\" , \"graphql_url\" : \"https://api.github.com/graphql\" , \"workspace\" : \"/home/runner/work/action-demo/action-demo\" , \"action\" : \"run3\" , \"event_path\" : \"/home/runner/work/_temp/_github_workflow/event.json\" } cat $GITHUB_EVENT_PATH { \"after\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"base_ref\" : null , \"before\" : \"1c8b86a50a7bfb2d04984d5a67b414836aa04f22\" , \"commits\" : [ { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" } ], \"compare\" : \"https://github.com/rammusxu/action-demo/compare/1c8b86a50a7b...044271eda133\" , \"created\" : false , \"deleted\" : false , \"forced\" : false , \"head_commit\" : { \"author\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"committer\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"Rammus Xu\" , \"username\" : \"RammusXu\" }, \"distinct\" : true , \"id\" : \"044271eda133bb9944f4aa7119bc661a8c1e9900\" , \"message\" : \"Update docker login\" , \"timestamp\" : \"2020-08-24T17:56:16+08:00\" , \"tree_id\" : \"bf214120ff82ade624e0c2584c6e945c55ade8e3\" , \"url\" : \"https://github.com/rammusxu/action-demo/commit/044271eda133bb9944f4aa7119bc661a8c1e9900\" }, \"organization\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"description\" : \"The SWAG Life\" , \"events_url\" : \"https://api.github.com/orgs/rammusxu/events\" , \"hooks_url\" : \"https://api.github.com/orgs/rammusxu/hooks\" , \"id\" : 36289044 , \"issues_url\" : \"https://api.github.com/orgs/rammusxu/issues\" , \"login\" : \"rammusxu\" , \"members_url\" : \"https://api.github.com/orgs/rammusxu/members{/member}\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"public_members_url\" : \"https://api.github.com/orgs/rammusxu/public_members{/member}\" , \"repos_url\" : \"https://api.github.com/orgs/rammusxu/repos\" , \"url\" : \"https://api.github.com/orgs/rammusxu\" }, \"pusher\" : { \"email\" : \"comte_ken@hotmail.com\" , \"name\" : \"RammusXu\" }, \"ref\" : \"refs/heads/github-pkg\" , \"repository\" : { \"archive_url\" : \"https://api.github.com/repos/rammusxu/action-demo/{archive_format}{/ref}\" , \"archived\" : false , \"assignees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/assignees{/user}\" , \"blobs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/blobs{/sha}\" , \"branches_url\" : \"https://api.github.com/repos/rammusxu/action-demo/branches{/branch}\" , \"clone_url\" : \"https://github.com/rammusxu/action-demo.git\" , \"collaborators_url\" : \"https://api.github.com/repos/rammusxu/action-demo/collaborators{/collaborator}\" , \"comments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/comments{/number}\" , \"commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/commits{/sha}\" , \"compare_url\" : \"https://api.github.com/repos/rammusxu/action-demo/compare/{base}...{head}\" , \"contents_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contents/{+path}\" , \"contributors_url\" : \"https://api.github.com/repos/rammusxu/action-demo/contributors\" , \"created_at\" : 1564547431 , \"default_branch\" : \"master\" , \"deployments_url\" : \"https://api.github.com/repos/rammusxu/action-demo/deployments\" , \"description\" : null , \"disabled\" : false , \"downloads_url\" : \"https://api.github.com/repos/rammusxu/action-demo/downloads\" , \"events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/events\" , \"fork\" : false , \"forks\" : 0 , \"forks_count\" : 0 , \"forks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/forks\" , \"full_name\" : \"rammusxu/action-demo\" , \"git_commits_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/commits{/sha}\" , \"git_refs_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/refs{/sha}\" , \"git_tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/tags{/sha}\" , \"git_url\" : \"git://github.com/rammusxu/action-demo.git\" , \"has_downloads\" : true , \"has_issues\" : true , \"has_pages\" : true , \"has_projects\" : true , \"has_wiki\" : true , \"homepage\" : null , \"hooks_url\" : \"https://api.github.com/repos/rammusxu/action-demo/hooks\" , \"html_url\" : \"https://github.com/rammusxu/action-demo\" , \"id\" : 199778774 , \"issue_comment_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/comments{/number}\" , \"issue_events_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues/events{/number}\" , \"issues_url\" : \"https://api.github.com/repos/rammusxu/action-demo/issues{/number}\" , \"keys_url\" : \"https://api.github.com/repos/rammusxu/action-demo/keys{/key_id}\" , \"labels_url\" : \"https://api.github.com/repos/rammusxu/action-demo/labels{/name}\" , \"language\" : \"Dockerfile\" , \"languages_url\" : \"https://api.github.com/repos/rammusxu/action-demo/languages\" , \"license\" : null , \"master_branch\" : \"master\" , \"merges_url\" : \"https://api.github.com/repos/rammusxu/action-demo/merges\" , \"milestones_url\" : \"https://api.github.com/repos/rammusxu/action-demo/milestones{/number}\" , \"mirror_url\" : null , \"name\" : \"action-demo\" , \"node_id\" : \"MDEwOlJlcG9zaXRvcnkxOTk3Nzg3NzQ=\" , \"notifications_url\" : \"https://api.github.com/repos/rammusxu/action-demo/notifications{?since,all,participating}\" , \"open_issues\" : 1 , \"open_issues_count\" : 1 , \"organization\" : \"rammusxu\" , \"owner\" : { \"avatar_url\" : \"https://avatars3.githubusercontent.com/u/36289044?v=4\" , \"email\" : \"engineering@swag.live\" , \"events_url\" : \"https://api.github.com/users/rammusxu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/rammusxu/followers\" , \"following_url\" : \"https://api.github.com/users/rammusxu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/rammusxu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/rammusxu\" , \"id\" : 36289044 , \"login\" : \"rammusxu\" , \"name\" : \"rammusxu\" , \"node_id\" : \"MDEyOk9yZ2FuaXphdGlvbjM2Mjg5MDQ0\" , \"organizations_url\" : \"https://api.github.com/users/rammusxu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/rammusxu/received_events\" , \"repos_url\" : \"https://api.github.com/users/rammusxu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/rammusxu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/rammusxu/subscriptions\" , \"type\" : \"Organization\" , \"url\" : \"https://api.github.com/users/rammusxu\" }, \"private\" : true , \"pulls_url\" : \"https://api.github.com/repos/rammusxu/action-demo/pulls{/number}\" , \"pushed_at\" : 1598262984 , \"releases_url\" : \"https://api.github.com/repos/rammusxu/action-demo/releases{/id}\" , \"size\" : 245 , \"ssh_url\" : \"git@github.com:rammusxu/action-demo.git\" , \"stargazers\" : 0 , \"stargazers_count\" : 0 , \"stargazers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/stargazers\" , \"statuses_url\" : \"https://api.github.com/repos/rammusxu/action-demo/statuses/{sha}\" , \"subscribers_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscribers\" , \"subscription_url\" : \"https://api.github.com/repos/rammusxu/action-demo/subscription\" , \"svn_url\" : \"https://github.com/rammusxu/action-demo\" , \"tags_url\" : \"https://api.github.com/repos/rammusxu/action-demo/tags\" , \"teams_url\" : \"https://api.github.com/repos/rammusxu/action-demo/teams\" , \"trees_url\" : \"https://api.github.com/repos/rammusxu/action-demo/git/trees{/sha}\" , \"updated_at\" : \"2020-08-24T06:36:17Z\" , \"url\" : \"https://github.com/rammusxu/action-demo\" , \"watchers\" : 0 , \"watchers_count\" : 0 }, \"sender\" : { \"avatar_url\" : \"https://avatars1.githubusercontent.com/u/4367069?v=4\" , \"events_url\" : \"https://api.github.com/users/RammusXu/events{/privacy}\" , \"followers_url\" : \"https://api.github.com/users/RammusXu/followers\" , \"following_url\" : \"https://api.github.com/users/RammusXu/following{/other_user}\" , \"gists_url\" : \"https://api.github.com/users/RammusXu/gists{/gist_id}\" , \"gravatar_id\" : \"\" , \"html_url\" : \"https://github.com/RammusXu\" , \"id\" : 4367069 , \"login\" : \"RammusXu\" , \"node_id\" : \"MDQ6VXNlcjQzNjcwNjk=\" , \"organizations_url\" : \"https://api.github.com/users/RammusXu/orgs\" , \"received_events_url\" : \"https://api.github.com/users/RammusXu/received_events\" , \"repos_url\" : \"https://api.github.com/users/RammusXu/repos\" , \"site_admin\" : false , \"starred_url\" : \"https://api.github.com/users/RammusXu/starred{/owner}{/repo}\" , \"subscriptions_url\" : \"https://api.github.com/users/RammusXu/subscriptions\" , \"type\" : \"User\" , \"url\" : \"https://api.github.com/users/RammusXu\" } } env LEIN_HOME = /usr/local/lib/lein M2_HOME = /usr/share/apache-maven-3.6.3 GOROOT_1_11_X64 = /opt/hostedtoolcache/go/1.11.13/x64 ANDROID_HOME = /usr/local/lib/android/sdk JAVA_HOME_11_X64 = /usr/lib/jvm/adoptopenjdk-11-hotspot-amd64 ImageVersion = 20200817 .1 AGENT_TOOLSDIRECTORY = /opt/hostedtoolcache LANG = C.UTF-8 AZURE_EXTENSION_DIR = /opt/az/azcliextensions POWERSHELL_DISTRIBUTION_CHANNEL = GitHub-Actions-ubuntu18 GITHUB_API_URL = https://api.github.com INVOCATION_ID = dcb35bf82e314cdb9caa479c88a6c37e BOOST_ROOT_1_72_0 = /opt/hostedtoolcache/boost/1.72.0/x64 JAVA_HOME_12_X64 = /usr/lib/jvm/adoptopenjdk-12-hotspot-amd64 ANDROID_SDK_ROOT = /usr/local/lib/android/sdk RUNNER_TOOL_CACHE = /opt/hostedtoolcache SWIFT_PATH = /usr/share/swift/usr/bin JAVA_HOME = /usr/lib/jvm/adoptopenjdk-8-hotspot-amd64 JAVA_TOOL_OPTIONS = -Dfile.encoding = UTF8 RUNNER_TRACKING_ID = github_0e3e53f2-73ff-4e23-8e4f-52cb37f62b82 DOTNET_MULTILEVEL_LOOKUP = \"0\" GITHUB_REPOSITORY_OWNER = rammusxu GITHUB_ACTIONS = true DOTNET_SKIP_FIRST_TIME_EXPERIENCE = \"1\" CI = true DOTNET_NOLOGO = \"1\" USER = runner GITHUB_HEAD_REF = GITHUB_ACTOR = RammusXu GITHUB_ACTION = run2 GRADLE_HOME = /usr/share/gradle PWD = /home/runner/work/action-demo/action-demo ImageOS = ubuntu18 HOME = /home/runner GOROOT = /opt/hostedtoolcache/go/1.14.7/x64 JOURNAL_STREAM = 9 :31545 GOROOT_1_14_X64 = /opt/hostedtoolcache/go/1.14.7/x64 JAVA_HOME_8_X64 = /usr/lib/jvm/adoptopenjdk-8-hotspot-amd64 RUNNER_TEMP = /home/runner/work/_temp GOROOT_1_15_X64 = /opt/hostedtoolcache/go/1.15.0/x64 CONDA = /usr/share/miniconda GOROOT_1_13_X64 = /opt/hostedtoolcache/go/1.13.15/x64 BOOST_ROOT_1_69_0 = /opt/hostedtoolcache/boost/1.69.0/x64 DEBIAN_FRONTEND = noninteractive RUNNER_WORKSPACE = /home/runner/work/action-demo GITHUB_REF = refs/heads/github-pkg GITHUB_SHA = 044271eda133bb9944f4aa7119bc661a8c1e9900 GITHUB_RUN_ID = 221813086 GITHUB_SERVER_URL = https://github.com GOROOT_1_12_X64 = /opt/hostedtoolcache/go/1.12.17/x64 GECKOWEBDRIVER = /usr/local/share/gecko_driver DEPLOYMENT_BASEPATH = /opt/runner GITHUB_EVENT_PATH = /home/runner/work/_temp/_github_workflow/event.json CHROMEWEBDRIVER = /usr/local/share/chrome_driver HOMEBREW_REPOSITORY = \"/home/linuxbrew/.linuxbrew/Homebrew\" GITHUB_GRAPHQL_URL = https://api.github.com/graphql RUNNER_OS = Linux GITHUB_BASE_REF = VCPKG_INSTALLATION_ROOT = /usr/local/share/vcpkg GITHUB_JOB = show-env PERFLOG_LOCATION_SETTING = RUNNER_PERFLOG JAVA_HOME_7_X64 = /usr/lib/jvm/zulu-7-azure-amd64 RUNNER_USER = runner SHLVL = 1 HOMEBREW_PREFIX = \"/home/linuxbrew/.linuxbrew\" GITHUB_REPOSITORY = rammusxu/action-demo GITHUB_EVENT_NAME = push LEIN_JAR = /usr/local/lib/lein/self-installs/leiningen-2.9.4-standalone.jar GITHUB_RUN_NUMBER = 166 RUNNER_PERFLOG = /home/runner/perflog GITHUB_WORKFLOW = show-env ANT_HOME = /usr/share/ant PATH = /home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/usr/share/rust/.cargo/bin:/home/runner/.config/composer/vendor/bin:/home/runner/.dotnet/tools:/snap/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games SELENIUM_JAR_PATH = /usr/share/java/selenium-server-standalone.jar GITHUB_WORKSPACE = /home/runner/work/action-demo/action-demo CHROME_BIN = /usr/bin/google-chrome HOMEBREW_CELLAR = \"/home/linuxbrew/.linuxbrew/Cellar\" _ = /usr/bin/env","title":"2020-09-01 github context on push branch event"},{"location":"snippets/github-action/#2020-05-18-github-workflow-env-on-pull-request","text":"LEIN_HOME = /usr/local/lib/lein M2_HOME = /usr/share/apache-maven-3.6.3 GOROOT_1_11_X64 = /usr/local/go1.11 ANDROID_HOME = /usr/local/lib/android/sdk JAVA_HOME_11_X64 = /usr/lib/jvm/zulu-11-azure-amd64 ImageVersion = 20200430 .1 AGENT_TOOLSDIRECTORY = /opt/hostedtoolcache LANG = C.UTF-8 AZURE_EXTENSION_DIR = /opt/az/azcliextensions POWERSHELL_DISTRIBUTION_CHANNEL = GitHub-Actions-ubuntu18 INVOCATION_ID = 68f93b53277249cc8519235cea6396c9 BOOST_ROOT_1_72_0 = /usr/local/share/boost/1.72.0 JAVA_HOME_12_X64 = /usr/lib/jvm/zulu-12-azure-amd64 ANDROID_SDK_ROOT = /usr/local/lib/android/sdk RUNNER_TOOL_CACHE = /opt/hostedtoolcache SWIFT_PATH = /usr/share/swift/usr/bin JAVA_HOME = /usr/lib/jvm/zulu-8-azure-amd64 RUNNER_TRACKING_ID = github_884bb8e2-7879-4810-9c99-0192e58487e7 GITHUB_REPOSITORY_OWNER = rammusxu GITHUB_ACTIONS = true DOTNET_SKIP_FIRST_TIME_EXPERIENCE = \"1\" CI = true USER = runner GITHUB_HEAD_REF = try-deploy GITHUB_ACTOR = RammusXu GITHUB_ACTION = run GRADLE_HOME = /usr/share/gradle PWD = /home/runner/work/action-demo/action-demo ImageOS = ubuntu18 HOME = /home/runner GOROOT = /usr/local/go1.14 JOURNAL_STREAM = 9 :31391 GOROOT_1_14_X64 = /usr/local/go1.14 JAVA_HOME_8_X64 = /usr/lib/jvm/zulu-8-azure-amd64 RUNNER_TEMP = /home/runner/work/_temp CONDA = /usr/share/miniconda GOROOT_1_13_X64 = /usr/local/go1.13 BOOST_ROOT_1_69_0 = /usr/local/share/boost/1.69.0 DEBIAN_FRONTEND = noninteractive RUNNER_WORKSPACE = /home/runner/work/action-demo GITHUB_REF = refs/pull/37/merge GITHUB_SHA = aadf39660fb8c0f87565bc08db9403f5197a8de6 GITHUB_RUN_ID = 107752396 GOROOT_1_12_X64 = /usr/local/go1.12 GECKOWEBDRIVER = /usr/local/share/gecko_driver DEPLOYMENT_BASEPATH = /opt/runner GITHUB_EVENT_PATH = /home/runner/work/_temp/_github_workflow/event.json CHROMEWEBDRIVER = /usr/local/share/chrome_driver HOMEBREW_REPOSITORY = \"/home/linuxbrew/.linuxbrew/Homebrew\" RUNNER_OS = Linux GITHUB_BASE_REF = master VCPKG_INSTALLATION_ROOT = /usr/local/share/vcpkg GITHUB_JOB = test PERFLOG_LOCATION_SETTING = RUNNER_PERFLOG JAVA_HOME_7_X64 = /usr/lib/jvm/zulu-7-azure-amd64 RUNNER_USER = runner SHLVL = 1 HOMEBREW_PREFIX = \"/home/linuxbrew/.linuxbrew\" GITHUB_REPOSITORY = rammusxu/action-demo GITHUB_EVENT_NAME = pull_request LEIN_JAR = /usr/local/lib/lein/self-installs/leiningen-2.9.3-standalone.jar GITHUB_RUN_NUMBER = 5 RUNNER_PERFLOG = /home/runner/perflog GITHUB_WORKFLOW = .github/workflows/update-status.yaml ANT_HOME = /usr/share/ant PATH = /usr/share/rust/.cargo/bin:/home/runner/.config/composer/vendor/bin:/home/runner/.dotnet/tools:/snap/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin SELENIUM_JAR_PATH = /usr/share/java/selenium-server-standalone.jar GITHUB_WORKSPACE = /home/runner/work/action-demo/action-demo CHROME_BIN = /usr/bin/google-chrome HOMEBREW_CELLAR = \"/home/linuxbrew/.linuxbrew/Cellar\" 2Z _ = /usr/bin/env","title":"2020-05-18 Github workflow env on pull request"},{"location":"snippets/github-action/#2020-03-11-use-a-self-build-action","text":"/usr/bin/docker run --name e87b528978e939d04c5cabae17f516da08bb2a_79b912 --label e87b52 --workdir /github/workspace --rm -e INPUT_ARGS -e INPUT_MY_VAR -e INPUT_LOWER_VAR -e INPUT_WHO-TO-GREET -e INPUT_NAME -e HOME -e GITHUB_REF -e GITHUB_SHA -e GITHUB_REPOSITORY -e GITHUB_RUN_ID -e GITHUB_RUN_NUMBER -e GITHUB_ACTOR -e GITHUB_WORKFLOW -e GITHUB_HEAD_REF -e GITHUB_BASE_REF -e GITHUB_EVENT_NAME -e GITHUB_WORKSPACE -e GITHUB_ACTION -e GITHUB_EVENT_PATH -e RUNNER_OS -e RUNNER_TOOL_CACHE -e RUNNER_TEMP -e RUNNER_WORKSPACE -e ACTIONS_RUNTIME_URL -e ACTIONS_RUNTIME_TOKEN -e ACTIONS_CACHE_URL -e GITHUB_ACTIONS = true -v \"/var/run/docker.sock\" : \"/var/run/docker.sock\" -v \"/home/runner/work/_temp/_github_home\" : \"/github/home\" -v \"/home/runner/work/_temp/_github_workflow\" : \"/github/workflow\" -v \"/home/runner/work/action-demo/action-demo\" : \"/github/workspace\" e87b52:8978e939d04c5cabae17f516da08bb2a env","title":"2020-03-11 Use a self build action"},{"location":"snippets/github-action/#reference","text":"https://help.github.com/en/actions/reference https://github.com/actions/toolkit/tree/master/packages/github https://github.com/actions/github-script https://octokit.github.io/rest.js/#usage bin in Ubuntu 18.04 https://github.com/actions/virtual-environments/blob/master/images/linux/Ubuntu1804-README.md","title":"Reference"},{"location":"snippets/gitlabci/","text":"Gitlab CI \u00b6 Debugging Containers \u00b6 For Gitlab CI docker run -it --rm -v $PWD :/app docker:18.09-git sh rammusxu/docker-box:python rammusxu/docker-box : Build docker image and push to gitlab registry \u00b6 ref: https://gitlab.com/gableroux/gitlab-ci-example-docker image : docker:latest services : - docker:dind before_script : - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" $CI_REGISTRY build-master : stage : build script : - docker build --pull -t \"$CI_REGISTRY_IMAGE\" . - docker push \"$CI_REGISTRY_IMAGE\" only : - master build : stage : build script : - docker build --pull -t \"$CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG\" . - docker push \"$CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG\" except : - master References \u00b6 CI \u74b0\u5883\u8b8a\u6578 https://docs.gitlab.com/ee/ci/variables/predefined_variables.html","title":"Gitlab CI"},{"location":"snippets/gitlabci/#gitlab-ci","text":"","title":"Gitlab CI"},{"location":"snippets/gitlabci/#debugging-containers","text":"For Gitlab CI docker run -it --rm -v $PWD :/app docker:18.09-git sh rammusxu/docker-box:python rammusxu/docker-box :","title":"Debugging Containers"},{"location":"snippets/gitlabci/#build-docker-image-and-push-to-gitlab-registry","text":"ref: https://gitlab.com/gableroux/gitlab-ci-example-docker image : docker:latest services : - docker:dind before_script : - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" $CI_REGISTRY build-master : stage : build script : - docker build --pull -t \"$CI_REGISTRY_IMAGE\" . - docker push \"$CI_REGISTRY_IMAGE\" only : - master build : stage : build script : - docker build --pull -t \"$CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG\" . - docker push \"$CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG\" except : - master","title":"Build docker image and push to gitlab registry"},{"location":"snippets/gitlabci/#references","text":"CI \u74b0\u5883\u8b8a\u6578 https://docs.gitlab.com/ee/ci/variables/predefined_variables.html","title":"References"},{"location":"snippets/http/","text":"http \u00b6 HTTPS \u00b6 HTTP Strict Transport Security (HSTS) \u00b6 \u78ba\u4fdd\u700f\u89bd\u5668\u4f7f\u7528 HTTPS \u958b\u555f\u7db2\u7ad9 Strict-Transport-Security: max-age=31536000; includeSubDomains \u5982\u679c\u7b2c\u4e00\u6b21\u4f7f\u7528 http \u6216\u662f HSTS \u904e\u671f\uff0c\u5c31\u6c92\u6709\u4f5c\u7528\u4e86\u3002","title":"http"},{"location":"snippets/http/#http","text":"","title":"http"},{"location":"snippets/http/#https","text":"","title":"HTTPS"},{"location":"snippets/http/#http-strict-transport-security-hsts","text":"\u78ba\u4fdd\u700f\u89bd\u5668\u4f7f\u7528 HTTPS \u958b\u555f\u7db2\u7ad9 Strict-Transport-Security: max-age=31536000; includeSubDomains \u5982\u679c\u7b2c\u4e00\u6b21\u4f7f\u7528 http \u6216\u662f HSTS \u904e\u671f\uff0c\u5c31\u6c92\u6709\u4f5c\u7528\u4e86\u3002","title":"HTTP Strict Transport Security (HSTS)"},{"location":"snippets/jenkins/","text":"curl trigger build \u00b6 curl -i -d \"targetEnv=demo&myArg=helloWorld\" \\ -u admin:a_md5_context \\ -XPOST https://my_domain/job/my_job/buildWithParameters","title":"Jenkins"},{"location":"snippets/jenkins/#curl-trigger-build","text":"curl -i -d \"targetEnv=demo&myArg=helloWorld\" \\ -u admin:a_md5_context \\ -XPOST https://my_domain/job/my_job/buildWithParameters","title":"curl trigger build"},{"location":"snippets/kubernetes/","text":"Kubernetes cheatsheet, snippets, troubleshooting, tips, hints Table of Contents \u00b6 Installation Volumes StatefulSet Container Resources PVC Affinity Helm Installation \u00b6 kubectl \u00b6 ref: https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-with-curl-on-linux Get stable version curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt Install kubectl VERSION = 1 .18.0 wget -q https://storage.googleapis.com/kubernetes-release/release/v $VERSION /bin/linux/amd64/kubectl -O /usr/local/bin/kubectl chmod +x /usr/local/bin/kubectl Volumes \u00b6 spec : template : spec : volumes : - name : mongo-socket emptyDir : {} containers : - name : mongos image : mongo:4.0.2 volumeMounts : - name : mongo-socket mountPath : /tmp - name : myconfigmap configMap : name : myconfigmap - name : mysecret secret : secretName : mysecret apiVersion : v1 kind : Pod metadata : name : test-pod spec : containers : - name : test-container image : k8s.gcr.io/busybox command : [ \"/bin/sh\" , \"-c\" , \"ls /etc/config/\" ] volumeMounts : - name : config-volume mountPath : /etc/config volumes : - name : config-volume configMap : name : test-config restartPolicy : Never --- apiVersion : v1 kind : ConfigMap metadata : name : test-config data : domains.json : | [ \"google.com\", \"facebook.com\", \"amazon.com\", \"swag.live\" ] StatefulSet \u00b6 volumeClaimTemplates \u00b6 volumeClaimTemplates : - metadata : name : data spec : accessModes : [ \"ReadWriteOnce\" ] storageClassName : ssd resources : requests : storage : 50Gi Container \u00b6 Multiple line (commands) readinessProbe \u00b6 readinessProbe : exec : command : - sh - -c - | echo hi >> /one echo hi2 >> /one2 initialDelaySeconds : 0 periodSeconds : 2 timeoutSeconds : 5 successThreshold : 1 failureThreshold : 2 Resources \u00b6 resources : limits : cpu : 1 memory : 2G requests : cpu : 1 memory : 2G PVC \u00b6 apiVersion : v1 kind : PersistentVolumeClaim metadata : name : grafana labels : app : grafana spec : accessModes : - ReadWriteOnce resources : requests : storage : 10Gi storageClassName : standard --- apiVersion : apps/v1 kind : Deployment metadata : name : grafana labels : app : grafana spec : replicas : 1 selector : matchLabels : app : grafana strategy : type : RollingUpdate template : metadata : labels : app : grafana spec : volumes : - name : storage persistentVolumeClaim : claimName : standard # emptyDir: {} Affinity \u00b6 Keywords \u00b6 operators: In, NotIn, Exists, DoesNotExist, Gt, Lt Scheduling: preferredDuringSchedulingIgnoredDuringExecution requiredDuringSchedulingIgnoredDuringExecution Pod \u53ea\u80fd\u653e\u5728\u7b26\u5408\u4ee5\u4e0b\u689d\u4ef6\u7684 Node \u00b6 spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : cloud.google.com/gke-preemptible operator : NotIn values : - \"true\" - key : sysctl/vm.max_map_count operator : In values : - \"262144\" \u540c\u4e00\u500b Node \u4e0d\u653e\u4e00\u6a23\u7684 Pod \u00b6 spec : affinity : podAntiAffinity : requiredDuringSchedulingIgnoredDuringExecution : - topologyKey : \"kubernetes.io/hostname\" labelSelector : matchExpressions : - key : \"app\" operator : In values : - mongo-sh0 env \u00b6 Pod env \u00b6 spec : containers : - name : envar-demo-container image : gcr.io/google-samples/node-hello:1.0 env : - name : DEMO_GREETING value : \"Hello from the environment\" - name : DEMO_FAREWELL value : \"Such a sweet sorrow\" metadata.annotations \u00b6 template : metadata : annotations : version : abc4444 spec : containers : - name : cronjob env : - name : MY_VERSION valueFrom : fieldRef : fieldPath : metadata.annotations['version'] metadata.name metadata.namespace \u00b6 ref: https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#capabilities-of-the-downward-api env : - name : POD_NAMESPACE valueFrom : fieldRef : fieldPath : metadata.namespace - name : POD_NAME valueFrom : fieldRef : fieldPath : metadata.name Secret \u00b6 Encode/Decode echo -n 'mykey' | base64 echo -n 'bXlrZXk=' | base64 -D apiVersion : v1 kind : Secret metadata : name : mysecret type : Opaque data : mykey : bXlrZXk= spec : containers : - name : mycontainer image : redis env : - name : SECRET_USERNAME valueFrom : secretKeyRef : name : mysecret key : mykey kubectl get secret tls -o \"jsonpath={.data['tls\\.key']}\" envFrom \u00b6 spec : containers : - name : http image : asia.gcr.io/swag-2c052/swag:42ff66b1 envFrom : - configMapRef : name : myconfigmap - secretRef : name : mysecret volumeMounts from configmap \u00b6 Pod spec : volumes : - name : config configMap : name : nginx-config containers : - name : echoserver image : gcr.io/google_containers/echoserver:1.10 ports : - containerPort : 8080 # nginx.conf override volumeMounts : - name : config subPath : nginx.conf mountPath : /etc/nginx/nginx.conf # mountPath: /usr/local/openresty/nginx/conf/nginx.conf readOnly : true ConfigMap apiVersion : v1 kind : ConfigMap metadata : name : nginx-config namespace : ingress-nginx data : nginx.conf : |- events { worker_connections 1024; } Container Injection \u00b6 /etc/hosts and /etc/resolv.conf \u00b6 ref: https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/#adding-additional-entries-with-hostaliases https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-config This will append hostname and overwrite /etc/resolv.conf apiVersion : extensions/v1beta1 kind : Deployment metadata : name : dnsmasq labels : name : dnsmasq spec : strategy : rollingUpdate : maxSurge : 1 maxUnavailable : 1 type : RollingUpdate template : metadata : labels : name : dnsmasq spec : hostAliases : - ip : \"35.227.233.133\" hostnames : - \"swag.live\" dnsPolicy : \"None\" dnsConfig : nameservers : - 1.1.1.1 - 8.8.8.8 containers : - image : rammusxu/dnsmasq name : dnsmasq resources : requests : cpu : \"100m\" memory : \"100M\" ports : - containerPort : 53 name : dnsmasq - containerPort : 53 protocol : UDP name : dnsmasq-udp imagePullPolicy : Always Container with commands \u00b6 - name : imagemagick image : swaglive/imagemagick:lastest command : [ \"/bin/sh\" , \"-c\" ] args : - | magick montage -quality 90 -resize 211x292^ -gravity center -crop 211x292+0+0 -geometry +4+4 -tile 7x4 -background none +repage $(cat /tmp/covers.txt) /tmp/montage.jpg volumeMounts : - name : tmp mountPath : /tmp GKE \u00b6 Enable CDN in Service \u00b6 apiVersion : cloud.google.com/v1beta1 kind : BackendConfig metadata : namespace : default name : gclb-cdn-hpq spec : cdn : enabled : true cachePolicy : includeHost : true includeProtocol : true includeQueryString : true --- apiVersion : v1 kind : Service metadata : namespace : default name : webapp annotations : beta.cloud.google.com/backend-config : '{\"ports\": {\"http\":\"gclb-cdn-hpq\"}}' spec : type : NodePort selector : app : webapp ports : - name : http port : 80 targetPort : http Helm \u00b6 Install a 3rd party chart \u00b6 ref: https://artifacthub.io/packages/helm/kvaps/nfs-server-provisioner?modal=install helm repo add kvaps https://kvaps.github.io/charts helm install nfs-server-provisioner kvaps/nfs-server-provisioner --version 1.2.1 helm show values kvaps/nfs-server-provisioner --version 1.2.1 helm show values kvaps/nfs-server-provisioner --version 1.2.1 > values.yaml Uninstall \u00b6 helm uninstall nfs-server-provisioner -n nfs-server Render a chart to a yaml file \u00b6 helm template nfs-server-provisioner \\ kvaps/nfs-server-provisioner \\ --version 1.2.1 \\ -f values.yaml \\ -n nfs-server > nfs-server.yaml Helmfile \u00b6 helmfile apply --skip-deps Frequent Commands \u00b6 Gracefully rolling restart deployment. \u00b6 kubectl rollout restart deployment/my-sites --namespace = default Wait another deployment restart then do something \u00b6 kubectl rollout restart deployment/storage --namespace=google-cloud kubectl rollout status deployment/storage --namespace=google-cloud kubectl rollout restart deployment/sites --namespace=default kubectl rollout status deployment/sites --namespace=default log: deployment.apps/storage restarted Waiting for deployment \"storage\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 1 old replicas are pending termination... Waiting for deployment \"storage\" rollout to finish: 1 old replicas are pending termination... deployment \"storage\" successfully rolled out deployment.apps/sites restarted Waiting for deployment \"sites\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 1 old replicas are pending termination... Waiting for deployment \"sites\" rollout to finish: 1 old replicas are pending termination... deployment \"sites\" successfully rolled out Create new job from cronjob \u00b6 kubectl create job --from = cronjob/my-daily-task manual-20200101 Reference \u00b6 feiskyer Handbook feiskyer Examples","title":"Kubernetes"},{"location":"snippets/kubernetes/#table-of-contents","text":"Installation Volumes StatefulSet Container Resources PVC Affinity Helm","title":"Table of Contents"},{"location":"snippets/kubernetes/#installation","text":"","title":"Installation"},{"location":"snippets/kubernetes/#kubectl","text":"ref: https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-with-curl-on-linux Get stable version curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt Install kubectl VERSION = 1 .18.0 wget -q https://storage.googleapis.com/kubernetes-release/release/v $VERSION /bin/linux/amd64/kubectl -O /usr/local/bin/kubectl chmod +x /usr/local/bin/kubectl","title":"kubectl"},{"location":"snippets/kubernetes/#volumes","text":"spec : template : spec : volumes : - name : mongo-socket emptyDir : {} containers : - name : mongos image : mongo:4.0.2 volumeMounts : - name : mongo-socket mountPath : /tmp - name : myconfigmap configMap : name : myconfigmap - name : mysecret secret : secretName : mysecret apiVersion : v1 kind : Pod metadata : name : test-pod spec : containers : - name : test-container image : k8s.gcr.io/busybox command : [ \"/bin/sh\" , \"-c\" , \"ls /etc/config/\" ] volumeMounts : - name : config-volume mountPath : /etc/config volumes : - name : config-volume configMap : name : test-config restartPolicy : Never --- apiVersion : v1 kind : ConfigMap metadata : name : test-config data : domains.json : | [ \"google.com\", \"facebook.com\", \"amazon.com\", \"swag.live\" ]","title":"Volumes"},{"location":"snippets/kubernetes/#statefulset","text":"","title":"StatefulSet"},{"location":"snippets/kubernetes/#volumeclaimtemplates","text":"volumeClaimTemplates : - metadata : name : data spec : accessModes : [ \"ReadWriteOnce\" ] storageClassName : ssd resources : requests : storage : 50Gi","title":"volumeClaimTemplates"},{"location":"snippets/kubernetes/#container","text":"","title":"Container"},{"location":"snippets/kubernetes/#multiple-line-commands-readinessprobe","text":"readinessProbe : exec : command : - sh - -c - | echo hi >> /one echo hi2 >> /one2 initialDelaySeconds : 0 periodSeconds : 2 timeoutSeconds : 5 successThreshold : 1 failureThreshold : 2","title":"Multiple line (commands) readinessProbe"},{"location":"snippets/kubernetes/#resources","text":"resources : limits : cpu : 1 memory : 2G requests : cpu : 1 memory : 2G","title":"Resources"},{"location":"snippets/kubernetes/#pvc","text":"apiVersion : v1 kind : PersistentVolumeClaim metadata : name : grafana labels : app : grafana spec : accessModes : - ReadWriteOnce resources : requests : storage : 10Gi storageClassName : standard --- apiVersion : apps/v1 kind : Deployment metadata : name : grafana labels : app : grafana spec : replicas : 1 selector : matchLabels : app : grafana strategy : type : RollingUpdate template : metadata : labels : app : grafana spec : volumes : - name : storage persistentVolumeClaim : claimName : standard # emptyDir: {}","title":"PVC"},{"location":"snippets/kubernetes/#affinity","text":"","title":"Affinity"},{"location":"snippets/kubernetes/#keywords","text":"operators: In, NotIn, Exists, DoesNotExist, Gt, Lt Scheduling: preferredDuringSchedulingIgnoredDuringExecution requiredDuringSchedulingIgnoredDuringExecution","title":"Keywords"},{"location":"snippets/kubernetes/#pod-node","text":"spec : affinity : nodeAffinity : requiredDuringSchedulingIgnoredDuringExecution : nodeSelectorTerms : - matchExpressions : - key : cloud.google.com/gke-preemptible operator : NotIn values : - \"true\" - key : sysctl/vm.max_map_count operator : In values : - \"262144\"","title":"Pod \u53ea\u80fd\u653e\u5728\u7b26\u5408\u4ee5\u4e0b\u689d\u4ef6\u7684 Node"},{"location":"snippets/kubernetes/#node-pod","text":"spec : affinity : podAntiAffinity : requiredDuringSchedulingIgnoredDuringExecution : - topologyKey : \"kubernetes.io/hostname\" labelSelector : matchExpressions : - key : \"app\" operator : In values : - mongo-sh0","title":"\u540c\u4e00\u500b Node \u4e0d\u653e\u4e00\u6a23\u7684 Pod"},{"location":"snippets/kubernetes/#env","text":"","title":"env"},{"location":"snippets/kubernetes/#pod-env","text":"spec : containers : - name : envar-demo-container image : gcr.io/google-samples/node-hello:1.0 env : - name : DEMO_GREETING value : \"Hello from the environment\" - name : DEMO_FAREWELL value : \"Such a sweet sorrow\"","title":"Pod env"},{"location":"snippets/kubernetes/#metadataannotations","text":"template : metadata : annotations : version : abc4444 spec : containers : - name : cronjob env : - name : MY_VERSION valueFrom : fieldRef : fieldPath : metadata.annotations['version']","title":"metadata.annotations"},{"location":"snippets/kubernetes/#metadataname-metadatanamespace","text":"ref: https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#capabilities-of-the-downward-api env : - name : POD_NAMESPACE valueFrom : fieldRef : fieldPath : metadata.namespace - name : POD_NAME valueFrom : fieldRef : fieldPath : metadata.name","title":"metadata.name metadata.namespace"},{"location":"snippets/kubernetes/#secret","text":"Encode/Decode echo -n 'mykey' | base64 echo -n 'bXlrZXk=' | base64 -D apiVersion : v1 kind : Secret metadata : name : mysecret type : Opaque data : mykey : bXlrZXk= spec : containers : - name : mycontainer image : redis env : - name : SECRET_USERNAME valueFrom : secretKeyRef : name : mysecret key : mykey kubectl get secret tls -o \"jsonpath={.data['tls\\.key']}\"","title":"Secret"},{"location":"snippets/kubernetes/#envfrom","text":"spec : containers : - name : http image : asia.gcr.io/swag-2c052/swag:42ff66b1 envFrom : - configMapRef : name : myconfigmap - secretRef : name : mysecret","title":"envFrom"},{"location":"snippets/kubernetes/#volumemounts-from-configmap","text":"Pod spec : volumes : - name : config configMap : name : nginx-config containers : - name : echoserver image : gcr.io/google_containers/echoserver:1.10 ports : - containerPort : 8080 # nginx.conf override volumeMounts : - name : config subPath : nginx.conf mountPath : /etc/nginx/nginx.conf # mountPath: /usr/local/openresty/nginx/conf/nginx.conf readOnly : true ConfigMap apiVersion : v1 kind : ConfigMap metadata : name : nginx-config namespace : ingress-nginx data : nginx.conf : |- events { worker_connections 1024; }","title":"volumeMounts from configmap"},{"location":"snippets/kubernetes/#container-injection","text":"","title":"Container Injection"},{"location":"snippets/kubernetes/#etchosts-and-etcresolvconf","text":"ref: https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/#adding-additional-entries-with-hostaliases https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-config This will append hostname and overwrite /etc/resolv.conf apiVersion : extensions/v1beta1 kind : Deployment metadata : name : dnsmasq labels : name : dnsmasq spec : strategy : rollingUpdate : maxSurge : 1 maxUnavailable : 1 type : RollingUpdate template : metadata : labels : name : dnsmasq spec : hostAliases : - ip : \"35.227.233.133\" hostnames : - \"swag.live\" dnsPolicy : \"None\" dnsConfig : nameservers : - 1.1.1.1 - 8.8.8.8 containers : - image : rammusxu/dnsmasq name : dnsmasq resources : requests : cpu : \"100m\" memory : \"100M\" ports : - containerPort : 53 name : dnsmasq - containerPort : 53 protocol : UDP name : dnsmasq-udp imagePullPolicy : Always","title":"/etc/hosts and /etc/resolv.conf"},{"location":"snippets/kubernetes/#container-with-commands","text":"- name : imagemagick image : swaglive/imagemagick:lastest command : [ \"/bin/sh\" , \"-c\" ] args : - | magick montage -quality 90 -resize 211x292^ -gravity center -crop 211x292+0+0 -geometry +4+4 -tile 7x4 -background none +repage $(cat /tmp/covers.txt) /tmp/montage.jpg volumeMounts : - name : tmp mountPath : /tmp","title":"Container with commands"},{"location":"snippets/kubernetes/#gke","text":"","title":"GKE"},{"location":"snippets/kubernetes/#enable-cdn-in-service","text":"apiVersion : cloud.google.com/v1beta1 kind : BackendConfig metadata : namespace : default name : gclb-cdn-hpq spec : cdn : enabled : true cachePolicy : includeHost : true includeProtocol : true includeQueryString : true --- apiVersion : v1 kind : Service metadata : namespace : default name : webapp annotations : beta.cloud.google.com/backend-config : '{\"ports\": {\"http\":\"gclb-cdn-hpq\"}}' spec : type : NodePort selector : app : webapp ports : - name : http port : 80 targetPort : http","title":"Enable CDN in Service"},{"location":"snippets/kubernetes/#helm","text":"","title":"Helm"},{"location":"snippets/kubernetes/#install-a-3rd-party-chart","text":"ref: https://artifacthub.io/packages/helm/kvaps/nfs-server-provisioner?modal=install helm repo add kvaps https://kvaps.github.io/charts helm install nfs-server-provisioner kvaps/nfs-server-provisioner --version 1.2.1 helm show values kvaps/nfs-server-provisioner --version 1.2.1 helm show values kvaps/nfs-server-provisioner --version 1.2.1 > values.yaml","title":"Install a 3rd party chart"},{"location":"snippets/kubernetes/#uninstall","text":"helm uninstall nfs-server-provisioner -n nfs-server","title":"Uninstall"},{"location":"snippets/kubernetes/#render-a-chart-to-a-yaml-file","text":"helm template nfs-server-provisioner \\ kvaps/nfs-server-provisioner \\ --version 1.2.1 \\ -f values.yaml \\ -n nfs-server > nfs-server.yaml","title":"Render a chart to a yaml file"},{"location":"snippets/kubernetes/#helmfile","text":"helmfile apply --skip-deps","title":"Helmfile"},{"location":"snippets/kubernetes/#frequent-commands","text":"","title":"Frequent Commands"},{"location":"snippets/kubernetes/#gracefully-rolling-restart-deployment","text":"kubectl rollout restart deployment/my-sites --namespace = default","title":"Gracefully rolling restart deployment."},{"location":"snippets/kubernetes/#wait-another-deployment-restart-then-do-something","text":"kubectl rollout restart deployment/storage --namespace=google-cloud kubectl rollout status deployment/storage --namespace=google-cloud kubectl rollout restart deployment/sites --namespace=default kubectl rollout status deployment/sites --namespace=default log: deployment.apps/storage restarted Waiting for deployment \"storage\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"storage\" rollout to finish: 1 old replicas are pending termination... Waiting for deployment \"storage\" rollout to finish: 1 old replicas are pending termination... deployment \"storage\" successfully rolled out deployment.apps/sites restarted Waiting for deployment \"sites\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 1 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 2 out of 3 new replicas have been updated... Waiting for deployment \"sites\" rollout to finish: 1 old replicas are pending termination... Waiting for deployment \"sites\" rollout to finish: 1 old replicas are pending termination... deployment \"sites\" successfully rolled out","title":"Wait another deployment restart then do something"},{"location":"snippets/kubernetes/#create-new-job-from-cronjob","text":"kubectl create job --from = cronjob/my-daily-task manual-20200101","title":"Create new job from cronjob"},{"location":"snippets/kubernetes/#reference","text":"feiskyer Handbook feiskyer Examples","title":"Reference"},{"location":"snippets/linux/","text":"Linux commands \u00b6 \u5e38\u7528\u7684 linux \u6307\u4ee4\u96c6\u8207\u7bc4\u4f8b Table of Contents \u00b6 Process: ps - \u76ee\u524d\u7684\u6240\u6709 process\u3002 lsof - \u5217\u51fa open files\u3002 screen - \u5728\u80cc\u666f\u57f7\u884c\u7a0b\u5e8f\u3002 Linux Kernel: sysctl - \u4fee\u6539 Linux Kernel \u53c3\u6578\u3002 Disk, File system: ls - \u5217\u51fa\u8cc7\u6599\u593e\u5167\u5bb9\u3002 du - \u8a08\u7b97\u6a94\u6848\u4f7f\u7528\u7a7a\u9593\u3002 lsblk - \u5217\u51fa block devices\u3002 dd - \u8f49\u63db\u3001\u8907\u88fd\u3001\u7522\u751f\u6a94\u6848\u3002 tail - \u5370\u51fa\u6a94\u6848\u7684\u6700\u5f8c\u5e7e\u884c\u3002 untar - \b\u58d3\u7e2e\u3001\u89e3\u58d3\u7e2e\u6a94\u6848\u3002 fio - disk i/o \u58d3\u529b\u6e2c\u8a66\u3002 Network: wget - \u4e0b\u8f09\u7db2\u8def\u8cc7\u6e90\u3002 curl - \u4e0b\u8f09\u7db2\u8def\u8cc7\u6e90\u3002 httpie - \u4e0b\u8f09\u7db2\u8def\u8cc7\u6e90\u3002RESTful like CLI\u3002 netstat Miscellaneous: parallel - \u4e26\u884c\u57f7\u884c\u6307\u4ee4\u3002 Process \u00b6 ps \u00b6 ps aux | grep \"java -jar build/libs/Hello-1.0.jar\" pgrep -f \"java -jar build/libs/Hello-1.0.jar\" pkill -f \"java -jar build/libs/Hello-1.0.jar\" pgrep -f \"java -jar build/libs/Hello-1.0.jar\" | xargs kill pkill -f \"java -jar build/libs/Hello-1.0.jar\" || true ps aux | grep node kill -9 PID killall node lsof \u00b6 \u5217\u51fa\u4f54\u7528\u4e2d\u7684 port # lsof -i -P -n | grep LISTEN systemd-r 645 systemd-resolve 13u IPv4 16633 0t0 TCP 127 .0.0.53:53 ( LISTEN ) sshd 882 root 3u IPv4 19952 0t0 TCP *:22 ( LISTEN ) sshd 882 root 4u IPv6 19969 0t0 TCP *:22 ( LISTEN ) \u78ba\u5b9a port \u6709\u6c92\u6709\u88ab\u4f54\u7528 lsof -i :22 screen \u00b6 \u5728\u80cc\u666f\u57f7\u884c\u7a0b\u5e8f\u3002 screen screen -ls screen -r 69262 .ttys001.mac-mini \u71b1\u9375 ctrl+a d Detach \u73fe\u5728\u7684 screen Linux Kernel \u00b6 sysctl \u00b6 \u53c3\u6578\u6703\u5728 /proc/sys \u8cc7\u6599\u593e\u4e0b\u3002 sysctl vm.max_map_count sysctl -w vm.max_map_count=262144 sysctl -a | grep vm sysctl -a | grep vm.max_map_count Disk, Storage \u00b6 ls \u00b6 ls -lh file du \u00b6 du -sh . lsblk \u00b6 lsblk lsblk -a dd \u00b6 Generate random binary file # 1 count = 512 Bytes # of = output file name dd if = /dev/urandom of = dd10 count = 20 tail \u00b6 \u5370\u51fa\u6a94\u6848\u7684\u6700\u5f8c\u5e7e\u884c tail -f buxybox-1 \u6703\u8ddf\u96a8\u539f\u59cb\u6a94\u6848 # tail -f busybox-1 hi hi3 # echo hi >> busybox-1 # mv busybox-1 busybox-2 # echo hi2 >> busybox-1 # echo hi3 >> busybox-2 tail -F buxybox-1 \u6703\u91cd\u8907\u5617\u8a66\u540c\u4e00\u500b\u6a94\u6848 # tail -F busybox-1 hi tail: busybox-1 has become inaccessible: No such file or directory tail: busybox-1 has appeared ; following end of new file hi # echo hi >> busybox-1 # mv busybox-1 busybox-3 # echo hi >> busybox-1 untar \u00b6 \u58d3\u7e2e\u3001\u89e3\u58d3\u7e2e\u6a94\u6848\u3002 wget https://github.com/openresty/headers-more-nginx-module/archive/refs/tags/v0.33.tar.gz tar -xf v0.33.tar.gz # . # \u251c\u2500\u2500 headers-more-nginx-module-0.33 # \u2502 \u251c\u2500\u2500 README.markdown # \u2502 \u251c\u2500\u2500 config # \u2502 \u251c\u2500\u2500 src # \u2502 \u251c\u2500\u2500 t # \u2502 \u251c\u2500\u2500 util # \u2502 \u2514\u2500\u2500 valgrind.suppress # \u2514\u2500\u2500 v0.33.tar.gz Monitoring \u00b6 Login log \u00b6 last lastlog Keep tracking a command \u00b6 watch -n 1 -d http http://localhost/ Linux User \u00b6 /etc/ssh/sshd_config /etc/passwd /etc/sudoers userdel ashish userdel -r ashish # and Home Directory Linux - adduser without prompts \u00b6 adduser runner --disabled-password --gecos \"\" Linux - Add sudoer group to user \u00b6 echo \"runner ALL=(ALL) NOPASSWD: ALL\" >> /etc/sudoers && \\ usermod -aG sudo runner cp \u00b6 Copy folder content to another folder cp -ar plugins/. share-plugins apt-get \u00b6 # ping apt-get install iputils-ping # dig, nslookup apt-get install dnsutils -y # ps apt-get install procps # mysql apt-get install mysql-client Network \u00b6 wget \u00b6 # wget -qO- https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-240.0.0-darwin-x86_64.tar.gz | tar xvz - wget -qO- your_link_here | tar xvz - wget -O- https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-240.0.0-darwin-x86_64.tar.gz | tar xvz -C . # wget -O- https://github.com/sing1ee/elasticsearch-jieba-plugin/archive/v7.0.0.tar.gz | tar -xzv -C . --strip 1 wget -O- your_link_here | tar -xzv -C . --strip 1 wget -c https://github.com/moby/buildkit/releases/download/v0.7.2/buildkit-v0.7.2.linux-amd64.tar.gz -O - | tar -xz wget -q -O tmp.zip http://downloads.wordpress.org/plugin/akismet.2.5.3.zip && unzip tmp.zip && rm tmp.zip curl \u00b6 curl -X GET \"https://httpbin.org/ip\" -H \"accept: application/json\" curl https://httpbin.org/ip curl https://sdk.cloud.google.com | bash -s -- --disable-prompts Get response time \u00b6 TARGET = google.com curl -s -o /dev/null -w \"target= ${ TARGET } time_namelookup=%{time_namelookup} time_connect=%{time_connect} time_appconnect=%{time_appconnect} time_starttransfer=%{time_starttransfer} time_total=%{time_total} size_download=%{size_download} speed_download=%{speed_download} remote_ip=%{remote_ip}\\n\" \" ${ TARGET } \" curl -o /dev/null -s -w 'Total: %{time_total}s\\n' https://www.google.com httpie \u00b6 ## Print request infomations: header, payload http localhost:3000 'Accept-Encoding: br, gzip, deflate' -v ## Print response header only http localhost:3000 'Accept-Encoding: br, gzip, deflate' -h netstat \u00b6 Show ports in use netstat -plnt nc \u00b6 ## Check if a port is opened /workspace # nc -vz localhost 3000 localhost ( 127 .0.0.1:3000 ) open String(Text) Processing \u00b6 # -P: Perl regex # -o: Only match # \\K: Only match Perl regex will show grep -oP 'foobar \\K\\w+' test.txt # -F: multi delimiter awk -F ' |\\r' '{print $2 \"/cover.jpg\"}' Using variable in xargs \u00b6 # curl is wired. https://stackoverflow.com/questions/37014430/awk-how-to-concat-number-with-strings # -P: multi process # -I: input stream as a variable xargs -P 10 -I username curl -sI https://xxxxxxxxxxx/username | grep 'Location: ' | awk '{print $2 \"/a_string\"}' Get nth line of stdout on linux \u00b6 ref: https://stackoverflow.com/questions/1429556/command-to-get-nth-line-of-stdout ls -l | sed -n 2p ls -l | head -2 | tail -1 Parsing xml in bash \u00b6 apk add libxml2-utils curl curl -s https://data.iana.org/root-anchors/root-anchors.xml | xmllint --format --xpath 'TrustAnchor/KeyDigest/KeyTag' - Load Testing \u00b6 Generate High CPU Usage \u00b6 while true ; do echo \"hi\" ; done ; while true ; do curl localhost ; done ; Generate High memory usage \u00b6 ref: https://stackoverflow.com/questions/20200982/how-to-generate-a-memory-shortage-using-bash-script yes | tr \\\\ n x | head -c $BYTES | grep n yes | tr \\\\ n x | head -c 100m | grep n jq \u00b6 $(msg=$(cat $(grep -E \"(mirror to|replace by)\" *.txt -l)) jq -nc '{\"body\":env.msg}') Miscellaneous \u00b6 parallel \u00b6 \u958b\u591a\u500b thread \u540c\u6642\u57f7\u884c\u591a\u500b\u6307\u4ee4 parallel docker push ::: \\ $DOCKER_REGISTRY_URL / $DOCKER_REPOSITORY_NAME : $DOCKER_REF_TAG -builder \\ $DOCKER_REGISTRY_URL / $DOCKER_REPOSITORY_NAME : $DOCKER_REF_TAG \\ $DOCKER_REGISTRY_URL / $DOCKER_REPOSITORY_NAME : $DOCKER_TAG","title":"Linux commands"},{"location":"snippets/linux/#linux-commands","text":"\u5e38\u7528\u7684 linux \u6307\u4ee4\u96c6\u8207\u7bc4\u4f8b","title":"Linux commands"},{"location":"snippets/linux/#table-of-contents","text":"Process: ps - \u76ee\u524d\u7684\u6240\u6709 process\u3002 lsof - \u5217\u51fa open files\u3002 screen - \u5728\u80cc\u666f\u57f7\u884c\u7a0b\u5e8f\u3002 Linux Kernel: sysctl - \u4fee\u6539 Linux Kernel \u53c3\u6578\u3002 Disk, File system: ls - \u5217\u51fa\u8cc7\u6599\u593e\u5167\u5bb9\u3002 du - \u8a08\u7b97\u6a94\u6848\u4f7f\u7528\u7a7a\u9593\u3002 lsblk - \u5217\u51fa block devices\u3002 dd - \u8f49\u63db\u3001\u8907\u88fd\u3001\u7522\u751f\u6a94\u6848\u3002 tail - \u5370\u51fa\u6a94\u6848\u7684\u6700\u5f8c\u5e7e\u884c\u3002 untar - \b\u58d3\u7e2e\u3001\u89e3\u58d3\u7e2e\u6a94\u6848\u3002 fio - disk i/o \u58d3\u529b\u6e2c\u8a66\u3002 Network: wget - \u4e0b\u8f09\u7db2\u8def\u8cc7\u6e90\u3002 curl - \u4e0b\u8f09\u7db2\u8def\u8cc7\u6e90\u3002 httpie - \u4e0b\u8f09\u7db2\u8def\u8cc7\u6e90\u3002RESTful like CLI\u3002 netstat Miscellaneous: parallel - \u4e26\u884c\u57f7\u884c\u6307\u4ee4\u3002","title":"Table of Contents"},{"location":"snippets/linux/#process","text":"","title":"Process"},{"location":"snippets/linux/#ps","text":"ps aux | grep \"java -jar build/libs/Hello-1.0.jar\" pgrep -f \"java -jar build/libs/Hello-1.0.jar\" pkill -f \"java -jar build/libs/Hello-1.0.jar\" pgrep -f \"java -jar build/libs/Hello-1.0.jar\" | xargs kill pkill -f \"java -jar build/libs/Hello-1.0.jar\" || true ps aux | grep node kill -9 PID killall node","title":"ps"},{"location":"snippets/linux/#lsof","text":"\u5217\u51fa\u4f54\u7528\u4e2d\u7684 port # lsof -i -P -n | grep LISTEN systemd-r 645 systemd-resolve 13u IPv4 16633 0t0 TCP 127 .0.0.53:53 ( LISTEN ) sshd 882 root 3u IPv4 19952 0t0 TCP *:22 ( LISTEN ) sshd 882 root 4u IPv6 19969 0t0 TCP *:22 ( LISTEN ) \u78ba\u5b9a port \u6709\u6c92\u6709\u88ab\u4f54\u7528 lsof -i :22","title":"lsof"},{"location":"snippets/linux/#screen","text":"\u5728\u80cc\u666f\u57f7\u884c\u7a0b\u5e8f\u3002 screen screen -ls screen -r 69262 .ttys001.mac-mini \u71b1\u9375 ctrl+a d Detach \u73fe\u5728\u7684 screen","title":"screen"},{"location":"snippets/linux/#linux-kernel","text":"","title":"Linux Kernel"},{"location":"snippets/linux/#sysctl","text":"\u53c3\u6578\u6703\u5728 /proc/sys \u8cc7\u6599\u593e\u4e0b\u3002 sysctl vm.max_map_count sysctl -w vm.max_map_count=262144 sysctl -a | grep vm sysctl -a | grep vm.max_map_count","title":"sysctl"},{"location":"snippets/linux/#disk-storage","text":"","title":"Disk, Storage"},{"location":"snippets/linux/#ls","text":"ls -lh file","title":"ls"},{"location":"snippets/linux/#du","text":"du -sh .","title":"du"},{"location":"snippets/linux/#lsblk","text":"lsblk lsblk -a","title":"lsblk"},{"location":"snippets/linux/#dd","text":"Generate random binary file # 1 count = 512 Bytes # of = output file name dd if = /dev/urandom of = dd10 count = 20","title":"dd"},{"location":"snippets/linux/#tail","text":"\u5370\u51fa\u6a94\u6848\u7684\u6700\u5f8c\u5e7e\u884c tail -f buxybox-1 \u6703\u8ddf\u96a8\u539f\u59cb\u6a94\u6848 # tail -f busybox-1 hi hi3 # echo hi >> busybox-1 # mv busybox-1 busybox-2 # echo hi2 >> busybox-1 # echo hi3 >> busybox-2 tail -F buxybox-1 \u6703\u91cd\u8907\u5617\u8a66\u540c\u4e00\u500b\u6a94\u6848 # tail -F busybox-1 hi tail: busybox-1 has become inaccessible: No such file or directory tail: busybox-1 has appeared ; following end of new file hi # echo hi >> busybox-1 # mv busybox-1 busybox-3 # echo hi >> busybox-1","title":"tail"},{"location":"snippets/linux/#untar","text":"\u58d3\u7e2e\u3001\u89e3\u58d3\u7e2e\u6a94\u6848\u3002 wget https://github.com/openresty/headers-more-nginx-module/archive/refs/tags/v0.33.tar.gz tar -xf v0.33.tar.gz # . # \u251c\u2500\u2500 headers-more-nginx-module-0.33 # \u2502 \u251c\u2500\u2500 README.markdown # \u2502 \u251c\u2500\u2500 config # \u2502 \u251c\u2500\u2500 src # \u2502 \u251c\u2500\u2500 t # \u2502 \u251c\u2500\u2500 util # \u2502 \u2514\u2500\u2500 valgrind.suppress # \u2514\u2500\u2500 v0.33.tar.gz","title":"untar"},{"location":"snippets/linux/#monitoring","text":"","title":"Monitoring"},{"location":"snippets/linux/#login-log","text":"last lastlog","title":"Login log"},{"location":"snippets/linux/#keep-tracking-a-command","text":"watch -n 1 -d http http://localhost/","title":"Keep tracking a command"},{"location":"snippets/linux/#linux-user","text":"/etc/ssh/sshd_config /etc/passwd /etc/sudoers userdel ashish userdel -r ashish # and Home Directory","title":"Linux User"},{"location":"snippets/linux/#linux-adduser-without-prompts","text":"adduser runner --disabled-password --gecos \"\"","title":"Linux - adduser without prompts"},{"location":"snippets/linux/#linux-add-sudoer-group-to-user","text":"echo \"runner ALL=(ALL) NOPASSWD: ALL\" >> /etc/sudoers && \\ usermod -aG sudo runner","title":"Linux - Add sudoer group to user"},{"location":"snippets/linux/#cp","text":"Copy folder content to another folder cp -ar plugins/. share-plugins","title":"cp"},{"location":"snippets/linux/#apt-get","text":"# ping apt-get install iputils-ping # dig, nslookup apt-get install dnsutils -y # ps apt-get install procps # mysql apt-get install mysql-client","title":"apt-get"},{"location":"snippets/linux/#network","text":"","title":"Network"},{"location":"snippets/linux/#wget","text":"# wget -qO- https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-240.0.0-darwin-x86_64.tar.gz | tar xvz - wget -qO- your_link_here | tar xvz - wget -O- https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-240.0.0-darwin-x86_64.tar.gz | tar xvz -C . # wget -O- https://github.com/sing1ee/elasticsearch-jieba-plugin/archive/v7.0.0.tar.gz | tar -xzv -C . --strip 1 wget -O- your_link_here | tar -xzv -C . --strip 1 wget -c https://github.com/moby/buildkit/releases/download/v0.7.2/buildkit-v0.7.2.linux-amd64.tar.gz -O - | tar -xz wget -q -O tmp.zip http://downloads.wordpress.org/plugin/akismet.2.5.3.zip && unzip tmp.zip && rm tmp.zip","title":"wget"},{"location":"snippets/linux/#curl","text":"curl -X GET \"https://httpbin.org/ip\" -H \"accept: application/json\" curl https://httpbin.org/ip curl https://sdk.cloud.google.com | bash -s -- --disable-prompts","title":"curl"},{"location":"snippets/linux/#get-response-time","text":"TARGET = google.com curl -s -o /dev/null -w \"target= ${ TARGET } time_namelookup=%{time_namelookup} time_connect=%{time_connect} time_appconnect=%{time_appconnect} time_starttransfer=%{time_starttransfer} time_total=%{time_total} size_download=%{size_download} speed_download=%{speed_download} remote_ip=%{remote_ip}\\n\" \" ${ TARGET } \" curl -o /dev/null -s -w 'Total: %{time_total}s\\n' https://www.google.com","title":"Get response time"},{"location":"snippets/linux/#httpie","text":"## Print request infomations: header, payload http localhost:3000 'Accept-Encoding: br, gzip, deflate' -v ## Print response header only http localhost:3000 'Accept-Encoding: br, gzip, deflate' -h","title":"httpie"},{"location":"snippets/linux/#netstat","text":"Show ports in use netstat -plnt","title":"netstat"},{"location":"snippets/linux/#nc","text":"## Check if a port is opened /workspace # nc -vz localhost 3000 localhost ( 127 .0.0.1:3000 ) open","title":"nc"},{"location":"snippets/linux/#stringtext-processing","text":"# -P: Perl regex # -o: Only match # \\K: Only match Perl regex will show grep -oP 'foobar \\K\\w+' test.txt # -F: multi delimiter awk -F ' |\\r' '{print $2 \"/cover.jpg\"}'","title":"String(Text) Processing"},{"location":"snippets/linux/#using-variable-in-xargs","text":"# curl is wired. https://stackoverflow.com/questions/37014430/awk-how-to-concat-number-with-strings # -P: multi process # -I: input stream as a variable xargs -P 10 -I username curl -sI https://xxxxxxxxxxx/username | grep 'Location: ' | awk '{print $2 \"/a_string\"}'","title":"Using variable in xargs"},{"location":"snippets/linux/#get-nth-line-of-stdout-on-linux","text":"ref: https://stackoverflow.com/questions/1429556/command-to-get-nth-line-of-stdout ls -l | sed -n 2p ls -l | head -2 | tail -1","title":"Get nth line of stdout on linux"},{"location":"snippets/linux/#parsing-xml-in-bash","text":"apk add libxml2-utils curl curl -s https://data.iana.org/root-anchors/root-anchors.xml | xmllint --format --xpath 'TrustAnchor/KeyDigest/KeyTag' -","title":"Parsing xml in bash"},{"location":"snippets/linux/#load-testing","text":"","title":"Load Testing"},{"location":"snippets/linux/#generate-high-cpu-usage","text":"while true ; do echo \"hi\" ; done ; while true ; do curl localhost ; done ;","title":"Generate High CPU Usage"},{"location":"snippets/linux/#generate-high-memory-usage","text":"ref: https://stackoverflow.com/questions/20200982/how-to-generate-a-memory-shortage-using-bash-script yes | tr \\\\ n x | head -c $BYTES | grep n yes | tr \\\\ n x | head -c 100m | grep n","title":"Generate High memory usage"},{"location":"snippets/linux/#jq","text":"$(msg=$(cat $(grep -E \"(mirror to|replace by)\" *.txt -l)) jq -nc '{\"body\":env.msg}')","title":"jq"},{"location":"snippets/linux/#miscellaneous","text":"","title":"Miscellaneous"},{"location":"snippets/linux/#parallel","text":"\u958b\u591a\u500b thread \u540c\u6642\u57f7\u884c\u591a\u500b\u6307\u4ee4 parallel docker push ::: \\ $DOCKER_REGISTRY_URL / $DOCKER_REPOSITORY_NAME : $DOCKER_REF_TAG -builder \\ $DOCKER_REGISTRY_URL / $DOCKER_REPOSITORY_NAME : $DOCKER_REF_TAG \\ $DOCKER_REGISTRY_URL / $DOCKER_REPOSITORY_NAME : $DOCKER_TAG","title":"parallel"},{"location":"snippets/lua/","text":"for k,v in pairs(resp_user.header) do -- ngx.header[k] = v ngx.say(k .. ' ' .. v) end","title":"Lua"},{"location":"snippets/mac-setup/","text":"Mac Setup \u00b6 Tool \u00b6 brew \u00b6 Install: /usr/bin/ruby -e \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install ) \" brew install bash-completion # Then add the following line to your ~/.bash_profile: [ -f /usr/local/etc/bash_completion ] && . /usr/local/etc/bash_completion Must have: brew install python3 brew install pyenv brew upgrade pyenv install 3 .6.8 Terminal \u00b6 brew cask install iterm2 brew install zsh zsh-completions iTerm2 > Preferences > Profiles > Keys https://medium.com/@jonnyhaynes/jump-forwards-backwards-and-delete-a-word-in-iterm2-on-mac-os-43821511f0a \u2325+\u2190 \u2325+\u2192 escape zsh \u00b6 https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins plugins=(git z httpie zsh-autosuggestions) What I use: - https://github.com/zsh-users/zsh-autosuggestions - git z httpie Software \u00b6 source tree vs code docker for desktop Setting \u00b6 Touchpad \u9ede\u4e00\u4e0b\u4f86\u9078\u6309 Sharing Computer name \u8f14\u52a9\u4f7f\u7528 Touchpad touchpad option > \u62d6\u79fb > \u4e09\u6307\u62d6\u79fb Keyboard \u6309\u9375\u91cd\u8907 > \u5feb \u91cd\u8907\u524d\u66ab\u5ef6 > \u77ed \u4f7f\u7528 F1, F2 \u6307\u63ee\u4e2d\u5fc3 \u6839\u64da\u6700\u8fd1\u7684\u4f7f\u7528\u60c5\u6cc1\u91cd\u65b0\u6392\u5217\u7a7a\u9593 > uncheck","title":"Mac Setup"},{"location":"snippets/mac-setup/#mac-setup","text":"","title":"Mac Setup"},{"location":"snippets/mac-setup/#tool","text":"","title":"Tool"},{"location":"snippets/mac-setup/#brew","text":"Install: /usr/bin/ruby -e \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install ) \" brew install bash-completion # Then add the following line to your ~/.bash_profile: [ -f /usr/local/etc/bash_completion ] && . /usr/local/etc/bash_completion Must have: brew install python3 brew install pyenv brew upgrade pyenv install 3 .6.8","title":"brew"},{"location":"snippets/mac-setup/#terminal","text":"brew cask install iterm2 brew install zsh zsh-completions iTerm2 > Preferences > Profiles > Keys https://medium.com/@jonnyhaynes/jump-forwards-backwards-and-delete-a-word-in-iterm2-on-mac-os-43821511f0a \u2325+\u2190 \u2325+\u2192 escape","title":"Terminal"},{"location":"snippets/mac-setup/#zsh","text":"https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins plugins=(git z httpie zsh-autosuggestions) What I use: - https://github.com/zsh-users/zsh-autosuggestions - git z httpie","title":"zsh"},{"location":"snippets/mac-setup/#software","text":"source tree vs code docker for desktop","title":"Software"},{"location":"snippets/mac-setup/#setting","text":"Touchpad \u9ede\u4e00\u4e0b\u4f86\u9078\u6309 Sharing Computer name \u8f14\u52a9\u4f7f\u7528 Touchpad touchpad option > \u62d6\u79fb > \u4e09\u6307\u62d6\u79fb Keyboard \u6309\u9375\u91cd\u8907 > \u5feb \u91cd\u8907\u524d\u66ab\u5ef6 > \u77ed \u4f7f\u7528 F1, F2 \u6307\u63ee\u4e2d\u5fc3 \u6839\u64da\u6700\u8fd1\u7684\u4f7f\u7528\u60c5\u6cc1\u91cd\u65b0\u6392\u5217\u7a7a\u9593 > uncheck","title":"Setting"},{"location":"snippets/make/","text":"\u4f7f\u7528\u53e6\u4e00\u500b target \u00b6 start: echo this is start use-start: echo this is use-start $(MAKE) start target \u4f9d\u8cf4\u53e6\u4e00\u500b target \u00b6 install: pip install -r requirements.txt start: install mkdocs serve Reference \u00b6 https://devhints.io/makefile","title":"Make"},{"location":"snippets/make/#target","text":"start: echo this is start use-start: echo this is use-start $(MAKE) start","title":"\u4f7f\u7528\u53e6\u4e00\u500b target"},{"location":"snippets/make/#target-target","text":"install: pip install -r requirements.txt start: install mkdocs serve","title":"target \u4f9d\u8cf4\u53e6\u4e00\u500b target"},{"location":"snippets/make/#reference","text":"https://devhints.io/makefile","title":"Reference"},{"location":"snippets/mongo/","text":"Cluster setup \u00b6 rs . initiate ( { _id : \"<replSetName>\" , configsvr : true , members : [ { _id : 0 , host : \"cfg1.example.net:27019\" }, { _id : 1 , host : \"cfg2.example.net:27019\" , priority : 0.5 }, { _id : 2 , host : \"cfg3.example.net:27019\" , priority : 0.5 } ] } ) rs . initiate ( { _id : \"configReplSet\" , configsvr : true , members : [ { _id : 0 , host : \"mongo-configsvr-0.mongo-configsvr:27019\" }, { _id : 1 , host : \"mongo-configsvr-1.mongo-configsvr:27019\" , priority : 0.5 }, { _id : 2 , host : \"mongo-configsvr-2.mongo-configsvr:27019\" , priority : 0.5 } ] } ) rs . initiate ( { _id : \"rs0\" , members : [ { _id : 0 , host : \"mongo-sh0-0.mongo-sh0:27017\" }, { _id : 1 , host : \"mongo-sh0-1.mongo-sh0:27017\" , priority : 0.5 }, { _id : 2 , host : \"mongo-sh0-2.mongo-sh0:27017\" , priority : 0.5 } ] } ) sh . addShard ( \"<replSetName>/s1-mongo1.example.net:27017\" ) sh . addShard ( \"rs0/mongo-sh0-0.mongo-sh0:27017\" ) rs . initiate () rs . status () rs . isMaster () rs . config () sh . status () rs . reconfig ( rs . config (),{ force : true }) mongo -- port 27019 -- eval \"rs.reconfig(rs.config(),{force:true})\" Config \u00b6 db . getMongo (). setReadPref ( 'secondaryPreferred' ) Auth \u00b6 mongo admin - u root - p 'password123' -- authenticationDatabase admin mongo localhost / rammus - u rammus - p 'rammus1234' -- authenticationDatabase admin mongo localhost / rammus db . auth ( 'rammus' , 'rammus1234' ) Usage \u00b6 use myNewDatabase db . myCollection . insertOne ( { x : 1 } ) db . myCollection . find () Connection pools db . serverStatus (). connections db . currentOp ( true ) db . runCommand ( { \"connPoolStats\" : 1 } ) Index db . demo . createIndex ({ name : 1 }) db . demo . createIndex ({ name : 1 },{ background : true }) db . demo . dropIndex ({ name : 1 }) db . demo . getIndexes () Array db . getCollection ( 'feat.rammus' ). insertOne ( { name : \"rammus\" } ) db . getCollection ( 'feat.rammus' ). update ( { name : \"rammus\" }, { $addToSet : { tags : { $each : [ \"ban\" , \"hid\" , \"3\" ]}} } ) db . getCollection ( 'feat.rammus' ). update ( { name : \"rammus\" }, { $pull : { tags : { $in : [ \"ban\" , \"3\" ]}} } ) Find db . getCollection ( 'feat.rammus' ). find ( { tags : /cover/i } ) Log db . getCollection ( 'oplog.rs' ). find ({}). sort ({ $natural : - 1 }) Test while true ; do kubectl exec - it mongo - mongos - 0 -- mongo mongo - mongos : 27017 / rammus -- eval \"db.serverStatus().connections;\" ; done ; while true ; do kubectl exec - it mongo - sh0 - 0 -- mongo mongo - sh0 - 0. mongo - sh0 : 27017 / rammus -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - sh0 - 0 -- mongo mongo - sh0 - 1. mongo - sh0 : 27017 / rammus -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - sh0 - 0 -- mongo mongo - sh0 - 2. mongo - sh0 : 27017 / rammus -- eval \"db.serverStatus().connections;\" done ; kubectl exec - it mongo - mongos - 0 -- mongo -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - mongos - 1 -- mongo -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - mongos - 2 -- mongo -- eval \"db.serverStatus().connections;\" mongo -- eval \"db.adminCommand('ping')\" localhost : 27017 Stats db . serverStatus () db . stats () sh . status () rs . status () db . runCommand ( \"isMaster\" ) Troubleshooting \u00b6 current \u90fd\u662f\u4e00\u6a23\u7684 mongos \u4e0d\u4e00\u5b9a\u9023\u5230\u9019\u500b replica\uff0c\u4e00\u500b replica set \u6709\u4e09\u500b node\uff0c\u6240\u4ee5\u4e09\u500b\u90fd\u8981\u6aa2\u67e5","title":"Mongo"},{"location":"snippets/mongo/#cluster-setup","text":"rs . initiate ( { _id : \"<replSetName>\" , configsvr : true , members : [ { _id : 0 , host : \"cfg1.example.net:27019\" }, { _id : 1 , host : \"cfg2.example.net:27019\" , priority : 0.5 }, { _id : 2 , host : \"cfg3.example.net:27019\" , priority : 0.5 } ] } ) rs . initiate ( { _id : \"configReplSet\" , configsvr : true , members : [ { _id : 0 , host : \"mongo-configsvr-0.mongo-configsvr:27019\" }, { _id : 1 , host : \"mongo-configsvr-1.mongo-configsvr:27019\" , priority : 0.5 }, { _id : 2 , host : \"mongo-configsvr-2.mongo-configsvr:27019\" , priority : 0.5 } ] } ) rs . initiate ( { _id : \"rs0\" , members : [ { _id : 0 , host : \"mongo-sh0-0.mongo-sh0:27017\" }, { _id : 1 , host : \"mongo-sh0-1.mongo-sh0:27017\" , priority : 0.5 }, { _id : 2 , host : \"mongo-sh0-2.mongo-sh0:27017\" , priority : 0.5 } ] } ) sh . addShard ( \"<replSetName>/s1-mongo1.example.net:27017\" ) sh . addShard ( \"rs0/mongo-sh0-0.mongo-sh0:27017\" ) rs . initiate () rs . status () rs . isMaster () rs . config () sh . status () rs . reconfig ( rs . config (),{ force : true }) mongo -- port 27019 -- eval \"rs.reconfig(rs.config(),{force:true})\"","title":"Cluster setup"},{"location":"snippets/mongo/#config","text":"db . getMongo (). setReadPref ( 'secondaryPreferred' )","title":"Config"},{"location":"snippets/mongo/#auth","text":"mongo admin - u root - p 'password123' -- authenticationDatabase admin mongo localhost / rammus - u rammus - p 'rammus1234' -- authenticationDatabase admin mongo localhost / rammus db . auth ( 'rammus' , 'rammus1234' )","title":"Auth"},{"location":"snippets/mongo/#usage","text":"use myNewDatabase db . myCollection . insertOne ( { x : 1 } ) db . myCollection . find () Connection pools db . serverStatus (). connections db . currentOp ( true ) db . runCommand ( { \"connPoolStats\" : 1 } ) Index db . demo . createIndex ({ name : 1 }) db . demo . createIndex ({ name : 1 },{ background : true }) db . demo . dropIndex ({ name : 1 }) db . demo . getIndexes () Array db . getCollection ( 'feat.rammus' ). insertOne ( { name : \"rammus\" } ) db . getCollection ( 'feat.rammus' ). update ( { name : \"rammus\" }, { $addToSet : { tags : { $each : [ \"ban\" , \"hid\" , \"3\" ]}} } ) db . getCollection ( 'feat.rammus' ). update ( { name : \"rammus\" }, { $pull : { tags : { $in : [ \"ban\" , \"3\" ]}} } ) Find db . getCollection ( 'feat.rammus' ). find ( { tags : /cover/i } ) Log db . getCollection ( 'oplog.rs' ). find ({}). sort ({ $natural : - 1 }) Test while true ; do kubectl exec - it mongo - mongos - 0 -- mongo mongo - mongos : 27017 / rammus -- eval \"db.serverStatus().connections;\" ; done ; while true ; do kubectl exec - it mongo - sh0 - 0 -- mongo mongo - sh0 - 0. mongo - sh0 : 27017 / rammus -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - sh0 - 0 -- mongo mongo - sh0 - 1. mongo - sh0 : 27017 / rammus -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - sh0 - 0 -- mongo mongo - sh0 - 2. mongo - sh0 : 27017 / rammus -- eval \"db.serverStatus().connections;\" done ; kubectl exec - it mongo - mongos - 0 -- mongo -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - mongos - 1 -- mongo -- eval \"db.serverStatus().connections;\" kubectl exec - it mongo - mongos - 2 -- mongo -- eval \"db.serverStatus().connections;\" mongo -- eval \"db.adminCommand('ping')\" localhost : 27017 Stats db . serverStatus () db . stats () sh . status () rs . status () db . runCommand ( \"isMaster\" )","title":"Usage"},{"location":"snippets/mongo/#troubleshooting","text":"current \u90fd\u662f\u4e00\u6a23\u7684 mongos \u4e0d\u4e00\u5b9a\u9023\u5230\u9019\u500b replica\uff0c\u4e00\u500b replica set \u6709\u4e09\u500b node\uff0c\u6240\u4ee5\u4e09\u500b\u90fd\u8981\u6aa2\u67e5","title":"Troubleshooting"},{"location":"snippets/nginx/","text":"Nginx \u5be6\u7528\u7b46\u8a18 Commands \u00b6 nginx -s reload proxy_cache \u00b6 Serve static files \u00b6 location ~ * \\.(jpg|png|css|js|js\\.map|svg|json) $ { expires max ; add_header Cache-Control \"public\" ; } upstream hash \u00b6 \u589e\u522a server \u6703\u91cd\u65b0\u7522\u751f hash\u3002 upstream proxy { hash $scheme$host$request_uri consistent ; server cache-server-0.cache-server ; server cache-server-1.cache-server ; } cache loader process \u00b6 / # ps PID USER TIME COMMAND 1 root 0 : 00 { openresty } nginx : master process / usr / local / openresty / bin / openresty - g daemon off ; 7 nobody 0 : 00 { openresty } nginx : worker process 8 nobody 0 : 00 { openresty } nginx : worker process 9 nobody 0 : 00 { openresty } nginx : cache manager process 10 nobody 0 : 00 { openresty } nginx : cache loader process Special Cases \u00b6 proxy_pass to a static direction (path) \u00b6 \"proxy_pass\" cannot have URI part in location given by regular expression location /go404 { rewrite ^ /404 $1 break ; proxy_pass http://bk $uri ; } Append a querystring to redirection \u00b6 If a replacement string includes the new request arguments, the previous request arguments are appended after them rewrite ^ http://test.example.com$uri?test=1 permanent; Reference \u00b6 \u5e38\u7528\u7684 linux \u6307\u4ee4\u96c6\u8207\u7bc4\u4f8b - https://www.nginx.com/blog/rate-limiting-nginx/","title":"Nginx"},{"location":"snippets/nginx/#commands","text":"nginx -s reload","title":"Commands"},{"location":"snippets/nginx/#proxy_cache","text":"","title":"proxy_cache"},{"location":"snippets/nginx/#serve-static-files","text":"location ~ * \\.(jpg|png|css|js|js\\.map|svg|json) $ { expires max ; add_header Cache-Control \"public\" ; }","title":"Serve static files"},{"location":"snippets/nginx/#upstream-hash","text":"\u589e\u522a server \u6703\u91cd\u65b0\u7522\u751f hash\u3002 upstream proxy { hash $scheme$host$request_uri consistent ; server cache-server-0.cache-server ; server cache-server-1.cache-server ; }","title":"upstream hash"},{"location":"snippets/nginx/#cache-loader-process","text":"/ # ps PID USER TIME COMMAND 1 root 0 : 00 { openresty } nginx : master process / usr / local / openresty / bin / openresty - g daemon off ; 7 nobody 0 : 00 { openresty } nginx : worker process 8 nobody 0 : 00 { openresty } nginx : worker process 9 nobody 0 : 00 { openresty } nginx : cache manager process 10 nobody 0 : 00 { openresty } nginx : cache loader process","title":"cache loader process"},{"location":"snippets/nginx/#special-cases","text":"","title":"Special Cases"},{"location":"snippets/nginx/#proxy_pass-to-a-static-direction-path","text":"\"proxy_pass\" cannot have URI part in location given by regular expression location /go404 { rewrite ^ /404 $1 break ; proxy_pass http://bk $uri ; }","title":"proxy_pass to a static direction (path)"},{"location":"snippets/nginx/#append-a-querystring-to-redirection","text":"If a replacement string includes the new request arguments, the previous request arguments are appended after them rewrite ^ http://test.example.com$uri?test=1 permanent;","title":"Append a querystring to redirection"},{"location":"snippets/nginx/#reference","text":"\u5e38\u7528\u7684 linux \u6307\u4ee4\u96c6\u8207\u7bc4\u4f8b - https://www.nginx.com/blog/rate-limiting-nginx/","title":"Reference"},{"location":"snippets/visual-studio/","text":"Visual Studio \u00b6 Python env \u00b6 https://code.visualstudio.com/docs/python/environments python3 -m venv .venv Note Command + Shift + P -> Python: Select Interpreter","title":"Visual Studio"},{"location":"snippets/visual-studio/#visual-studio","text":"","title":"Visual Studio"},{"location":"snippets/visual-studio/#python-env","text":"https://code.visualstudio.com/docs/python/environments python3 -m venv .venv Note Command + Shift + P -> Python: Select Interpreter","title":"Python env"}]}